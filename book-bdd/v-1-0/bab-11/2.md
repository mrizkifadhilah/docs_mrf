# ğŸ“˜ SUB-BAB 11.2: INTEGRASI MONGODB: CDC & TRANSACTIONAL OUTBOX

## ğŸ¯ Tujuan Pembelajaran
Setelah mempelajari sub-bab ini, kamu akan mampu:
1.  Mengidentifikasi masalah **Dual Write** (menulis ke database dan mengirim event ke Kafka secara terpisah) yang rentan inkonsistensi.
2.  Menerapkan mekanisme **Change Data Capture (CDC)** yang memanfaatkan Oplog MongoDB untuk streaming data otomatis.
3.  Merancang pola **Transactional Outbox** untuk menjamin atomisitas antara penyimpanan data bisnis dan penerbitan event.

---

## ğŸ”— Context & Hook
Bayangkan skenario ini: Aplikasi E-Commerce kamu menerima pesanan baru. Kode program melakukan dua hal:
1.  Simpan pesanan ke MongoDB.
2.  Kirim event "OrderMasuk" ke Kafka agar gudang memprosesnya.

Apa yang terjadi jika langkah 1 sukses (masuk database), tapi tiba-tiba listrik mati atau jaringan putus *sebelum* langkah 2 (kirim ke Kafka)?
Akibatnya: Pesanan tercatat di database, tapi gudang tidak pernah tahu. Barang tidak dikirim. Pelanggan marah.

Masalah ini disebut **Dual Write Problem**. Kamu tidak bisa menjamin dua sistem berbeda (Database & Broker) sukses bersamaan tanpa mekanisme khusus. Di sinilah **CDC** dan **Transactional Outbox** menjadi penyelamat integritas datamu.

---

## ğŸ’¡ Analogi: Fotografer vs. Kotak Surat
1.  **CDC (Change Data Capture) = Fotografer CCTV:**
    Kamu tidak perlu melapor apa pun. Ada kamera CCTV (Connector) yang terus menerus merekam apa yang kamu tulis di buku catatan (Database Oplog). Begitu kamu menulis, CCTV merekamnya dan menyiarkannya ke ruang monitor. Kamu pasif, sistem aktif memantau.
2.  **Transactional Outbox = Kotak Surat Kantor:**
    Saat kamu menyelesaikan tugas (transaksi), kamu juga menulis surat laporan dan meletakkannya di keranjang "Outbox" di mejamu sendiri. Tukang pos (Relay Process) nanti akan datang mengambil surat itu.
    * Kuncinya: Menyelesaikan tugas dan menaruh surat adalah satu paket kegiatan. Jika kamu pingsan sebelum menaruh surat, tugas dianggap belum selesai.

---

## ğŸ“š Inti Materi

### 1. Masalah Dual Write
Dalam Microservices, menulis ke database dan menerbitkan event ke Message Broker adalah dua operasi terpisah yang tidak berbagi transaksi yang sama. Jika salah satu gagal, sistem menjadi tidak konsisten.

### 2. Solusi 1: Change Data Capture (CDC)
Ini adalah pendekatan **Non-Intrusif**. Aplikasi tidak perlu menulis kode untuk kirim ke Kafka.
* **Mekanisme:** Tool CDC (seperti Kafka Connect) memantau **MongoDB Oplog** (Log Operasi).
* **Proses:** Setiap kali ada `insert`, `update`, atau `delete` di MongoDB, Oplog mencatatnya. CDC membaca log ini dan mengubahnya menjadi event Kafka.
* **Keunggulan:** Developer tidak perlu mengubah kode aplikasi. Jaminan *At-Least-Once delivery*.

### 3. Solusi 2: Transactional Outbox Pattern
Terkadang CDC terlalu "mentah" (hanya data fisik database). Kita butuh event bisnis yang bermakna (misal: "UserCreated" bukan sekadar "Insert Table User").
* **Cara Kerja:**
    1.  Aplikasi membuat dokumen `Order` (Data Bisnis).
    2.  Aplikasi membuat dokumen `Outbox` berisi event (Data Event).
    3.  Keduanya disimpan ke MongoDB dalam **Satu Transaksi ACID Multi-Dokumen** (Bab 6).
    4.  Jika commit sukses, maka Order dan Outbox pasti tersimpan. Jika gagal, keduanya batal.
* **Pengiriman:** Sebuah proses terpisah (Connector) membaca koleksi `Outbox` dan mengirimnya ke Kafka. Setelah terkirim, dokumen di `Outbox` dihapus.

---

## ğŸ“± Contoh Penerapan: Pembayaran
Service Pembayaran menerima request bayar Rp 50.000.
1.  **Mulai Transaksi MongoDB.**
2.  Update saldo user: `saldo = saldo - 50000`.
3.  Insert ke koleksi `outbox`: `{ event: "PaymentSuccess", amount: 50000, status: "pending_publish" }`.
4.  **Commit Transaksi.** (Dijamin atomik: Saldo terpotong JIKA DAN HANYA JIKA Outbox tersimpan).
5.  **Kafka Connector:** Membaca `outbox`, kirim ke Kafka, lalu hapus dokumen dari `outbox`.

---

## ğŸ“– Mini-Glossary
* **Dual Write:** Anti-pattern di mana aplikasi mencoba menulis ke dua sistem penyimpanan berbeda (DB & Broker) tanpa transaksi bersama, berisiko data tidak sinkron.
* **Transactional Outbox:** Pola desain yang menggunakan tabel/koleksi database sebagai antrian pesan sementara untuk menjamin atomisitas penyimpanan data dan event.
* **Oplog Tailing:** Teknik membaca log operasi MongoDB secara real-time, metode utama yang digunakan oleh alat CDC.

---

## ğŸ“ Evaluasi Singkat

### 5 Soal Pilihan Ganda (HOTS)

1.  **Analisis:** Apa risiko terbesar jika developer melakukan `db.collection.insertOne()` lalu diikuti `kafkaProducer.send()` tanpa menggunakan pola Transactional Outbox atau CDC?
    * a. Kafka akan menolak pesan.
    * b. Database menjadi lambat.
    * c. Terjadi inkonsistensi data jika aplikasi *crash* tepat setelah `insertOne` tetapi sebelum `send`; data ada di DB tapi event tidak terkirim.
    * d. MongoDB akan menghapus data otomatis.
    * e. Kafka akan membuat duplikat topic.

2.  **Konsep:** Dalam pola Transactional Outbox menggunakan MongoDB, mengapa kita perlu memanfaatkan fitur **Multi-Document Transaction** (Bab 6)?
    * a. Agar bisa menulis ke banyak database sekaligus.
    * b. Untuk menjamin bahwa penyimpanan data bisnis (misal: Order) dan penyimpanan data event (Outbox) terjadi secara atomik (sukses bersama atau gagal bersama).
    * c. Agar Kafka bisa membaca database.
    * d. Karena MongoDB tidak mendukung single document transaction.
    * e. Agar data terenkripsi.

3.  **Teknologi:** Komponen internal MongoDB apa yang memungkinkan alat CDC seperti Debezium untuk menangkap perubahan data tanpa membebani query ke koleksi utama?
    * a. WiredTiger Cache.
    * b. Indexes.
    * c. Oplog (Operation Log).
    * d. Sharding Config.
    * e. Journaling.

4.  **Perbandingan:** Kapan sebaiknya menggunakan **Transactional Outbox** dibandingkan **CDC Oplog** murni?
    * a. Saat butuh performa tercepat tanpa peduli format event.
    * b. Saat kita ingin event yang dikirim ke Kafka memiliki struktur/schema bisnis yang spesifik dan berbeda dari struktur tabel database fisik, atau butuh transformasi logika sebelum dikirim.
    * c. Saat database tidak memiliki Oplog.
    * d. Saat menggunakan database in-memory.
    * e. Saat tidak ada jaringan internet.

5.  **Skenario:** Sebuah konektor CDC membaca Oplog dan mengirim event ke Kafka. Tiba-tiba konektor mati. Saat hidup kembali, bagaimana ia tahu harus mulai membaca dari mana agar tidak ada data yang hilang?
    * a. Membaca dari awal Oplog (Full Sync).
    * b. Menggunakan "Offset" atau timestamp terakhir yang sukses diproses/disimpan (Checkpointing).
    * c. Menebak-nebak.
    * d. Menunggu data baru masuk.
    * e. Menghapus topic Kafka.

### Kunci Jawaban
1.  **c** (Ini adalah definisi masalah Dual Write).
2.  **b** (Atomisitas adalah tujuan utama Outbox).
3.  **c** (Oplog adalah sumber kebenaran untuk replikasi dan CDC).
4.  **b** (CDC mengekspos internal DB, Outbox mengekspos intent bisnis).
5.  **b** (Mekanisme resume token/offset standar dalam streaming).

---

## ğŸš€ Mini Challenge
**Desain Skema Outbox:**
Ambil secarik kertas. Rancang struktur dokumen untuk koleksi `outbox_events` di MongoDB.
Field apa saja yang wajib ada agar *Relay Process* bisa mengirimkannya ke Kafka dengan benar?
* *Clue:* Kamu butuh data payload, tujuan (topic), dan status.
* *Contoh Jawaban:*
    ```json
    {
      "_id": ObjectId("..."),
      "aggregate_id": "ORDER-123",
      "event_type": "OrderCreated",
      "payload": { "item": "Sepatu", "price": 50000 },
      "destination_topic": "orders",
      "created_at": ISODate("..."),
      "status": "PENDING"
    }
    ```

---
*Event sudah terkirim aman. Tapi, bagaimana jika Kafka mengirim event yang sama dua kali ke penerima? Ketik **"Lanjut"** untuk masuk ke **Sub-Bab 11.3: Menjamin Keandalan: Exactly-Once Processing**.*