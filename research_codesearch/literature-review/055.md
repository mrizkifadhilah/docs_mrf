---
title: Review Paper - MESN-CS untuk Peningkatan Akurasi Code Search
description: Rangkuman paper tentang Model Jaringan Self-Attention Mutual Embedded untuk Code Search (The Journal of Systems & Software, 2023).
head:
  - - meta
    - name: keywords
      content: Code search, Self-Attention, Mutual Embedded, MESN-CS, Structural Dependencies
---

# 055 - A mutual embedded self-attention network model for code search
Tautan (DOI) [https://doi.org/10.1016/j.jss.2022.111591]

**Penulis:** **Haize Hu** $^{1,2*}$, **Jianxun Liu** $^{1,2}$, **Xiangping Zhang** $^{1,2}$, **Ben Cao** $^{1,2}$, **Siqiang Cheng** $^{1,2}$, **Teng Long** $^{1,2}$

**Afiliasi:**
* $^{1}$ School of Computer Science and Technology, Hunan University of Science and Technology, Hunan 411100, China
* $^{2}$ Hunan Provincial Key Lab. for Services Computing and Novel Software Technology (Hunan University of Science and Technology), Hunan 411100, China

**Kronologi:** Received: 20 December 2021 • Revised: 2 December 2022 • Accepted: 18 December 2022 • Available Online: 7 January 2023

<a href="https://www.scimagojr.com/journalsearch.php?q=19309&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=19309" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** The Journal of Systems & Software 198 (2023)<br>• **Topik:** Peningkatan akurasi *code search* dengan memasukkan ketergantungan struktural antar unit komponen kode.<br><br>**Masalah & Solusi:**<br>• **Masalah 1 (Semantic Gap):** Metode *Information Retrieval* (IR) tidak mengatasi kesenjangan semantik antara bahasa alami dan kode sumber.<br>• **Masalah 2 (Abaikan Ketergantungan Struktural):** Model berbasis *Deep Learning* lanjutan seperti **SAN-CS** efektif dalam menangkap semantik kata (*word-level attention*) dan logika internal setiap urutan komponen kode (API, Method Name, Token) tetapi **gagal menangkap korelasi struktural dan logis di antara urutan-urutan tersebut**, yang mengorbankan integritas kode secara keseluruhan.<br>• **Solusi:** Mengusulkan model **MESN-CS** (*Mutual Embedded Self-Attention Network Code Search*). Model ini menggabungkan (1) mekanisme *Self-Attention* untuk bobot kata internal dan (2) teknik *Mutual Embedding* untuk menghitung bobot *embedding* berpasangan antara komponen kode (API, Method Name, Token).<br><br>**Contoh Penerapan:**<br>• Diuji pada dua dataset Java, termasuk dataset besar DeepCS ($\approx 18.2$ juta sampel) dan dataset CodesearchNet ($\approx 496$ ribu sampel).<br>• MESN-CS berhasil meningkatkan akurasi *code search* pada semua metrik dibandingkan *baseline* SOTA, memvalidasi pentingnya korelasi struktural antar-urutan kode.<br><br>**Metodologi:**<br>• **Preprocessing:** Kode diurai menjadi empat urutan: Method Name, API, Tokens, dan Description (Des).<br>• **Self-Attention Training:** Setiap urutan ($V_{API}, V_{Name}, V_{Token}, V_{Des}$) diolah melalui *Self-Attention* untuk mendapatkan bobot fitur internal ($A_{API}, A_{Name}, A_{Token}, A_{Des}$).<br>• **Mutual Embedding:** Menerapkan *embedding* berpasangan antara tiga komponen kode: (1) Method Name $\leftrightarrow$ API (MESN-NA), (2) Method Name $\leftrightarrow$ Token (MESN-NT), dan (3) API $\leftrightarrow$ Token (MESN-AT) untuk mengekstrak korelasi semantik antar-urutan.\\($V'_{n}=A\bullet V_{a}$, dengan $A=\text{SoftMax}(\frac{Q_{n}\bullet k_{a}^{T}}{\sqrt{d}})$\).<br>• **Residual Network:** Menggunakan **Jaringan Residual** untuk menambal kembali (*superimpose*) nilai awal vektor informasi fitur ke vektor ekstraksi fitur setelah pelatihan *mutual embedding* (meskipun tidak ditampilkan dalam diagram utama), untuk mengurangi hilangnya informasi selama pelatihan.<br>• **Similarity:** Vektor kode akhir ($V_{Code}$) dan vektor deskripsi ($V_{Des}$) dicocokkan menggunakan **Cosine Similarity** setelah *Average Pooling*. Pelatihan dioptimalkan menggunakan **Minimum Ranking Loss Degree** (Triplet Loss).<br><br>**Temuan Kunci:**<br>1. **Kinerja Superior:** MESN-CS melampaui semua *baseline* (DeepCS, CARLCS-CNN, CSDA, SAN-CS) di semua metrik pada dataset besar DeepCS. Peningkatan Recall@1 sebesar $\mathbf{1.07\%}$ dan MRR sebesar $\mathbf{1.40\%}$ dibandingkan model SOTA sebelumnya, SAN-CS.<br>2. **Dampak Struktural:** Eksperimen ablasi menunjukkan bahwa *mutual embedding* antara **Method Name dan Token** (MESN-NT) memberikan hasil yang paling akurat, mengkonfirmasi bahwa hubungan logis antara kedua urutan tersebut adalah informasi paling penting untuk karakterisasi kode.<br>3. **Efisiensi Kueri:** Meskipun memiliki parameter model yang lebih besar daripada SAN-CS (7.47M vs 6.64M), MESN-CS mencapai waktu kueri tercepat ($\mathbf{0.07\text{ s/query}}$), menunjukkan karakterisasi kode yang lebih baik.\\<br>**Kontribusi Utama:**<br>• Mengusulkan MESN-CS, model *Self-Attention* pertama yang secara eksplisit memasukkan korelasi semantik/struktural **antar-urutan** komponen kode (API, Method Name, Token) melalui teknik *Mutual Embedding*.<br>• Membuktikan bahwa integritas kode (*source code integrity*) yang hilang karena pemisahan urutan dapat secara efektif dipulihkan melalui *Mutual Embedding*.<br><br>**Dampak:**<br>• **Peningkatan Akurasi:** MESN-CS berhasil memecahkan *bottleneck* akurasi model *code search* SOTA sebelumnya, memberikan arah penelitian baru dalam mengoptimalkan model dengan fokus pada fitur struktural yang terabaikan. |

## 1. Pendahuluan & Masalah

Seiring pesatnya perkembangan rekayasa perangkat lunak, repositori kode sumber terbuka (seperti GitHub) telah meluas, mendorong penggunaan kembali kode (*code reuse*). Pengembang menghabiskan banyak waktu untuk mencari kode yang relevan. Oleh karena itu, akurasi *code search* menjadi fokus penelitian utama.

Pendekatan awal yang berbasis *Information Retrieval* (IR) terbatas karena mengabaikan **kesenjangan semantik** antara bahasa alami (kueri) dan bahasa pemrograman (kode). Munculnya *Deep Learning* (DL), dimulai dengan model **DeepCS** (Gu et al., 2018) berbasis LSTM, berhasil memetakan kedua bahasa ke ruang vektor yang sama.

Namun, DeepCS mengabaikan hubungan kata dalam kode. Model yang lebih baru, seperti **SAN-CS** (Fang et al., 2021) yang menggunakan mekanisme *Self-Attention*, secara signifikan meningkatkan akurasi dengan mempertimbangkan bobot kata-kata individual. Meskipun demikian, SAN-CS masih memiliki kekurangan fatal:

1.  **Pengabaian Korelasi Antar-Urutan:** SAN-CS mengurai kode menjadi tiga urutan komponen (Method Name, API, Tokens) tetapi **mengabaikan korelasi struktural dan logis di antara ketiga urutan ini**, meskipun mereka secara alami memiliki keterkaitan (misalnya, Method Name mewakili keseluruhan kode, API adalah panggilan fungsi di dalamnya, dan Token adalah semua kata kunci).
2.  **Hilangnya Integritas Kode:** Dengan mengabaikan hubungan antar-urutan, **integritas kode** sebagai satu kesatuan logis terabaikan, menghasilkan representasi kode yang kurang optimal.

::: tip Solusi yang Diusulkan
Untuk mengatasi kekurangan SAN-CS, kami mengusulkan **MESN-CS** (*Mutual Embedded Self-Attention Network Code Search*). Model ini menambahkan mekanisme **Mutual Embedding** untuk menghitung bobot ketergantungan semantik secara eksplisit **antar-urutan** komponen kode (API, Method Name, Token). Penambahan ini bertujuan untuk memulihkan korelasi struktural dan meningkatkan integritas representasi kode.
:::

## 2. Metodologi

MESN-CS adalah kerangka kerja dua bagian (pelatihan *offline* dan pencarian *online*) yang berfokus pada pelatihan *offline* untuk mendapatkan model pencocokan yang efisien.

### A. Alur Kerja MESN-CS
1.  **Input & Serialisasi:** Kode sumber dan *Code Comments* diurai menjadi empat urutan: API Sequence, Method Name Sequence (disingkat Name), Tokens Sequence, dan Description Sequence (Des).
2.  **Embedding:** Keempat urutan di-*embed* menjadi vektor awal ($V_{API}, V_{Name}, V_{Token}, V_{Des}$) ke dalam ruang vektor yang sama.
3.  **Self-Attention Training:** Vektor awal diolah melalui lapisan *Self-Attention* untuk mempertimbangkan bobot fitur internal pada tingkat kata.
4.  **Mutual Embedding:** Teknik *mutual embedding* diterapkan secara berpasangan pada tiga kombinasi komponen kode ($A_{API}, A_{Name}, A_{Token}$) untuk mendapatkan vektor yang diperkaya ketergantungan antar-urutan ($V_{n}, V_{a}, V_{t}$).
5.  **Full Connection:** Ketiga vektor komponen kode yang sudah diperkaya di-*splice* (*concat*) untuk mendapatkan vektor keseluruhan kode ($V_{Code}$).
6.  **Similarity Calculation:** $V_{Code}$ dan $V_{Des}$ diolah melalui *Mutual Embedded Attention* lagi, dan hasilnya dipulihkan menggunakan *Average Pooling* sebelum menghitung *Cosine Similarity*.

### B. Mutual Embedding Berpasangan
Mutual Embedding berpasangan diterapkan pada tiga kombinasi urutan. Sebagai contoh, *mutual embedding* antara Method Name ($V_{n}$) dan API ($V_{a}$):
1.  Mendapatkan Query ($Q_{n}$) dan Key ($k_{a}$) dari masing-masing urutan:
    $$Q_{n}=V_{n}\bullet W_{nq}^{T}$$
    $$k_{a}=V_{a}\bullet W_{ka}^{T}$$
2.  Menghitung matriks *attention* ($A$) berpasangan:
    $$A=\text{SoftMax}(\frac{Q_{n}\bullet k_{a}^{T}}{\sqrt{d}})$$
3.  Menghasilkan vektor tersemat bersama ($V'_{n}$ dan $V'_{a}$):
    $$V'_{n}=A\bullet V_{a}$$
    $$V'_{a}=A\bullet V_{n}$$
Proses serupa dilakukan untuk Method Name $\leftrightarrow$ Token dan API $\leftrightarrow$ Token.

### C. Pelatihan dan Fungsi Kerugian
Pelatihan menggunakan pasangan vektor deskripsi positif ($V_{Dav}^{+}$) dan negatif ($V_{Dav}^{-}$) terhadap vektor kode ($V_{Cav}$). Tujuannya adalah memaksimalkan kesamaan $V_{Cav}$ dengan $V_{Dav}^{+}$ dan meminimalkan kesamaan dengan $V_{Dav}^{-}$. Fungsi objektif yang digunakan adalah **Minimum Ranking Loss Degree (Triplet Loss)**:
$$\mathcal{L}(\theta)=\sum_{(c,d^{+},d^{-})}max(0,\xi-cos(c,d^{+})+cos(c,d^{-}))$$
Di mana $\xi$ adalah konstanta batas (*margin*).

## 3. Detail Pengujian

### Dataset
1.  **Dataset Utama (DeepCS-Based):** Java dari GitHub (Agustus 2008–Juni 2016).
    *   Train: $\mathbf{18.233.872}$
    *   Valid: $100.000$
    *   Test: $10.000$
2.  **Dataset Adaptabilitas (CodesearchNet-Java):**
    *   Total: $496.688$

### Baseline
Model dibandingkan dengan empat model utama:
*   **DeepCS** (LSTM): Model DL perintis.
*   **SAN-CS** (*Self-Attention*): Model SOTA sebelumnya.
*   **CARLCS-CNN** (CNN + Co-Attention): Mengganti LSTM dengan CNN.
*   **CSDA** (LSTM + Attention): Memfokuskan *attention* pada Token.

### Metrik Evaluasi
Tiga metrik standar *code search* digunakan, dengan nilai yang lebih tinggi menunjukkan kinerja yang lebih baik:
*   **Recall@k** ($k \in \{1, 5, 10\}$):
    $$\text{Recall}@k = \frac{1}{|Q|}\sum_{j=1}^{|Q|}\epsilon$$
*   **Mean Reciprocal Rank (MRR):**
    $$MRR=\frac{1}{|Q|}\sum_{j=1}^{|Q|}\frac{1}{Index_{Qj}}$$
*   **Normalized Discounted Cumulative Gain (NDCG):**
    $$\text{NDCG} = \frac{\sum_{j=1}^{k}\frac{2^{r_{j}}-1}{\log_{2}(1+j)}}{IDCG}$$

## 4. Hasil Eksperimen

### RQ1: Perbandingan Kinerja
Hasil eksperimen pada dataset utama (DeepCS-Based) menunjukkan keunggulan MESN-CS.

| Model | Recall@1 | Recall@5 | Recall@10 | MRR | NDCG |
| :--- | :--- | :--- | :--- | :--- | :--- |
| DeepCS | 0,4752 | 0.7610 | 0.8633 | 0,6169 | 0.6169 |
| SAN-CS | 0.9310 | 0.9560 | 0.9620 | 0.9080 | 0.9210 |
| **MESN-CS** | **0.9410** | **0.9642** | **0.9716** | **0.9207** | **0.9329** |

*   **Peningkatan Akurasi:** MESN-CS meningkatkan Recall@1 sebesar $\mathbf{1.07\%}$ dan MRR sebesar $\mathbf{1.40\%}$ dibandingkan dengan model SAN-CS, yang menunjukkan bahwa *mutual embedding* efektif dalam memperbaiki kelemahan struktural SAN-CS.

### RQ2: Dampak Mutual Embedding (Ablasi)
Eksperimen ablasi menunjukkan mana pasangan urutan yang paling penting.

| Model | Recall@1 | MRR | NDCG | Keterangan |
| :--- | :--- | :--- | :--- | :--- |
| SAN-CS | 0.9310 | 0.9080 | 0.9210 | Tanpa Mutual Embedding |
| MESN-NA | 0.9412 | 0.9209 | 0.9331 | Name $\leftrightarrow$ API |
| **MESN-NT** | **0.9419** | **0.9214** | **0.9338** | **Name $\leftrightarrow$ Token (Terbaik)** |
| MESN-AT | 0.9399 | 0.9197 | 0.9317 | API $\leftrightarrow$ Token |

*   **Temuan Kunci:** *Mutual embedding* antara **Method Name dan Token** (MESN-NT) menghasilkan skor tertinggi, menegaskan bahwa korelasi struktural antara nama fungsi dan semua token dalam kode adalah informasi yang paling kaya untuk karakterisasi kode.

### RQ3: Analisis Efisiensi
Model dibandingkan berdasarkan ukuran parameter dan waktu.

| Model | Parameters | Training time | Query time |
| :--- | :--- | :--- | :--- |
| DeepCS | 5.85M | 1.00 ms/sample | 0.60 s/query |
| SAN-CS | 6.64M | 0.30 ms/sample | 0.10 s/query |
| **MESN-CS** | **7.47M** | 0.57 ms/sample | **0.07 s/query** |

*   MESN-CS memiliki parameter yang lebih besar daripada *baseline*, tetapi mencapai **waktu kueri tercepat (0.07 s/query)**, menunjukkan efisiensi yang lebih tinggi dalam pencarian *online* berkat representasi kode yang lebih akurat.

## 5. Kesimpulan

MESN-CS berhasil mengimplementasikan jaringan *Self-Attention* yang diperkaya dengan teknik *Mutual Embedding* untuk secara eksplisit menangkap ketergantungan struktural dan semantik antar-urutan komponen kode. Dengan mengatasi kelemahan model sebelumnya yang mengabaikan integritas kode, MESN-CS mencapai peningkatan akurasi yang signifikan di semua metrik evaluasi. Temuan ablasi menyoroti bahwa korelasi antara Method Name dan Token adalah yang paling penting.

::: info Dampak Praktis
Model MESN-CS tidak hanya memecahkan *bottleneck* akurasi model SOTA dalam *code search* tetapi juga memberikan arahan penelitian baru: bahwa optimasi model harus bergeser dari hanya mengeksplorasi jaringan saraf baru ke **mengeksplorasi hubungan internal dan antar-komponen dalam data kode itu sendiri**. Model ini memberikan referensi penting untuk tugas-tugas berbasis kecocokan semantik lainnya antara bahasa pemrograman dan bahasa alami.
:::