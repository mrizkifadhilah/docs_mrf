---
title: Review Paper - SCodeSearcher Soft Contrastive Learning
description: Rangkuman paper tentang metode SCodeSearcher, pembelajaran kontrasif lunak untuk pencarian kode yang efisien (Empirical Software Engineering, 2025).
head:
  - - meta
    - name: keywords
      content: Code search, Contrastive learning, Deep neural network, Soft contrastive learning, Large language models (LLMs)
---

# 007 - SCodeSearcher: soft contrastive learning for code search
[https://doi.org/10.1007/s10664-024-10603-z]

**Penulis:** **Jia Li** ᵃ, **Zheng Fang** ᵃ, **Xianjie Shi** ᵃ, **Zhi Jin** ᵃ, **Fang Liu** ᵇ, **Jia Li** ᵃ, **Yunfei Zhao** ᵃ, **Ge Li** ᵃ

**Afiliasi:**
* ᵃ Key Lab of High Confidence Software Technology (Peking University), MoE, Beijing, China
* ᵇ State Key Laboratory of Complex & Critical Software Environment, Beihang University, Beijing, China

**Kronologi:** Accepted: 8 December 2024 • Published Online: 28 March 2025

<a href="https://www.scimagojr.com/journalsearch.php?q=18650&tip=sid&clean=0" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=18650" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Empirical Software Engineering, Vol 30, Isu 87 (2025)<br>• **Penerbit:** Springer Nature<br>• **Topik:** Pembelajaran Kontrasif Lunak (*Soft Contrastive Learning*) untuk Peningkatan Efisiensi dan Akurasi Pencarian Kode (*Code Search*).<br><br>**Masalah & Solusi:**<br>• **Masalah:** Model *contrastive learning* (*CL*) yang ada untuk *code search* mengabaikan dua skenario menantang: (1) Perlunya mengambil semua potongan kode yang setara secara fungsional meskipun diimplementasikan secara beragam (*diverse implementations*); dan (2) Perlunya membedakan kode yang diinginkan dari potongan kode *false positive* yang membingungkan (implementasi serupa tetapi fungsi berbeda).<br>• **Solusi:** Mengusulkan **SCodeSearcher**, metode *soft contrastive learning* yang menyoroti contoh-contoh menantang ini (*challenging examples*) dengan menetapkan **bobot tinggi yang berbeda** berdasarkan tingkat tantangan mereka dalam fungsi rugi *contrastive learning*.<br><br>**Contoh Penerapan:**<br>• **Challenging Positive:** Menggunakan **LLM** untuk menghasilkan program **$P$** dengan **implementasi beragam** namun fungsionalitas setara. Bobot ditentukan oleh kesamaan fungsional dengan kueri asli.<br>• **Challenging Negative (False Positive):** Menggunakan **LLM** untuk menghasilkan program **$F$** yang memiliki **implementasi serupa** tetapi fungsionalitas berbeda. Bobot ditentukan oleh **jarak pengeditan** (*editing distance*) kode asli dan kode *false positive*.<br><br>**Metodologi:**<br>• **Backbone:** Menggunakan **GraphCodeBERT** sebagai arsitektur *Transformer* multi-lapisan bimodal.<br>• **Augmentasi:** Menggunakan **LLMs** (misalnya, GPT-3.5) untuk secara otomatis membuat contoh **positif beragam** ($P$) dan **negatif *false positive*** ($F$).<br>• **Soft Contrastive Learning:** Mengoptimalkan model dengan *loss function* yang memiliki bobot berbeda untuk contoh positif dan negatif (berdasarkan tingkat tantangan). *Soft contrastive loss* kemudian digunakan untuk pra-pelatihan dengan corpus data yang jauh lebih kecil.<br><br>**Temuan Kunci:**<br>1. **Efisiensi Data:** SCodeSearcher yang hanya dilatih pada korpus yang **jauh lebih kecil** (kurang dari sepersepuluh dari *baseline* CL) dapat mencapai kinerja yang sebanding atau lebih baik daripada metode *state-of-the-art* yang dilatih pada dataset berskala besar.<br>2. **Peningkatan Kinerja:** SCodeSearcher mencapai peningkatan MRR relatif 2.08% pada CoSQA dan 3.03% pada StaQC dibandingkan MCodeSearcher, dan peningkatan akurasi 4.50% pada WebQuery.<br>3. **Desain Bobot:** Strategi agregasi representasi semantik contoh positif (*fusion-first*) terbukti jauh lebih unggul daripada strategi agregasi skor kesamaan (*fusion-last*).<br><br>**Kontribusi Utama:**<br>• Mengusulkan SCodeSearcher, yang pertama kali menggunakan *Soft Contrastive Learning* untuk mengatasi skenario menantang *false positive* dan *diverse implementations* dalam *code search*.<br>• Menggunakan LLM untuk augmentasi data secara otomatis, menghemat upaya manusia dan sumber daya komputasi.<br>• Menyediakan kerangka kerja yang sangat efisien dalam penggunaan data pelatihan dibandingkan metode *contrastive learning* berbasis *encoder* lainnya. |

## 1. Pendahuluan & Masalah

*Code search* telah menjadi kegiatan penting dalam pengembangan perangkat lunak, di mana pengembang menghabiskan sekitar 19% waktu kerja mereka untuk mencari dan menggunakan kembali kode yang ada. Meskipun banyak peneliti beralih ke *deep learning* dan, baru-baru ini, *contrastive learning* (CL) untuk meningkatkan kinerja *code search*, model-model ini cenderung mengabaikan skenario menantang:

1.  **Diverse Implementations:** Kueri pengguna harus dapat dicocokkan dengan semua potongan kode yang setara secara fungsional, terlepas dari gaya implementasi yang berbeda.
2.  **Confusing Code Snippets:** Mesin *code search* harus mampu membedakan program yang diinginkan dari potongan kode *false positive* yang membingungkan, yaitu kode yang memiliki implementasi serupa tetapi fungsi yang berbeda.

Model CL yang ada umumnya menggunakan metode heuristik untuk augmentasi data (misalnya, mengganti nama variabel), yang cenderung mempertahankan implementasi yang sama, sehingga gagal memodelkan skenario yang menantang di atas.

::: tip Solusi yang Diusulkan
Kami mengusulkan **SCodeSearcher**, metode *soft contrastive learning* novel yang menyoroti contoh-contoh menantang. Ini dilakukan dengan memberikan **bobot berbeda** (sesuai tingkat tantangannya) dalam tujuan *contrastive learning*. LLM yang kuat digunakan untuk secara otomatis menghasilkan contoh positif dengan implementasi yang beragam dan program *false positive* yang membingungkan.
:::

## 2. Metodologi

SCodeSearcher terdiri dari tiga submodul: Augmentasi Kode Sumber dengan LLM, *Soft Contrastive Learning*, dan *Fine-tuning* pada *Code Search*.

### A. Augmentasi Kode Sumber dengan LLM
LLM digunakan untuk secara otomatis membuat contoh-contoh menantang:
*   **False Positive Programs ($F$):** LLM diinstruksikan untuk membuat **perubahan minimal** yang mengubah fungsionalitas kode asli ($c_i$), tetapi mempertahankan implementasi yang serupa.
*   **Programs with Diverse Implementations ($P$):** LLM diinstruksikan untuk menulis ulang kode asli ($c_i$) dengan **memprioritaskan perubahan struktur dan logika implementasi**, memastikan fungsionalitas tetap setara. LLM juga menghasilkan deskripsi fungsional ($q_{i,p}^z$) untuk program yang diperluas ini, yang digunakan untuk menentukan bobot.

### B. Soft Contrastive Learning
SCodeSearcher menggunakan **GraphCodeBERT** sebagai *backbone* dan mengoptimalkannya dengan tujuan *soft contrastive learning* ($\mathcal{L}_{SCL}$), yang membedakan dari *loss* standar ($\mathcal{L}$) dengan memasukkan bobot $a$ dan $b$ untuk contoh positif dan negatif.

#### Bobot Positif (Diverse Implementations)
Representasi kode asli ($C_i$) dan program positif yang diperluas ($C_{i,p}^z$) **diagregasi** menjadi satu vektor semantik $C_{i,+}$:
$$C_{i,+}=a_{i}C_{i}+\sum_{z=1}^{w}a_{i,p}^{z}C_{i,p}^{z}$$
Di mana bobot agregasi ($a_{i,p}^z$) didasarkan pada kesamaan TF-IDF ($\overline{s}_{i}^{z}$) antara kueri asli ($q_i$) dan deskripsi fungsional dari program yang diperluas ($q_{i,p}^z$).

$$[a_{i}, a_{i,p}^{1},\cdot\cdot\cdot, a_{i,p}^{w}]=softmax(\alpha\cdot[1,s_{i,p}^{1},\cdot\cdot\cdot,s_{i,p}^{w}])$$
$\alpha \in [0, 1]$ adalah batas atas bobot pada contoh positif.

#### Bobot Negatif (False Positive dan Negatif Lain)
Bobot ($b_j$) pada contoh negatif ditentukan oleh tingkat tantangan mereka. Untuk program *false positive*, tingkat tantangan diukur dengan **jarak pengeditan** (*editing distance*) antara kode asli dan kode *false positive*.
$$b_{j}= \begin{cases} \frac{1+\beta}{1+\frac{dis}{\text{avg}}} & \text{jika } 1+\frac{dis}{k} < 1 \\ 1 & \text{lainnya} \end{cases}$$
$\beta \in [1, 2]$ adalah batas atas bobot pada contoh negatif, dan *dis* adalah jarak pengeditan. $k$ adalah batas adaptif yang disesuaikan dengan rata-rata jarak pengeditan (*avg*) korpus pelatihan.

#### Soft Contrastive Loss Function
$$ \mathcal{L}_{SCL}=-\mathbb{E}_{Q_{i}\sim\mathbb{P}_{SCL}}\left[log\frac{e^{S(Q_{i},C_{i,+})/\tau}}{e^{s(Q_{i},C_{i,+})/\tau}+\sum_{C_{j}\in\mathbb{N}_{SCL}}e^{s(Q_{i},b_{j}C_{j})/\tau}}\right] $$

### C. Fine-tuning pada Code Search
Setelah pra-pelatihan, model di-*fine-tune* menggunakan *loss* standar *code search* ($\mathcal{L}_{CS}$) untuk memaksimalkan kesamaan kosinus antara kueri ($\hat{Q}_i$) dan kode *ground-truth* ($\hat{C}_i$).
$$ s(\hat{q}_{i},\hat{c}_{i})=cos(\hat{Q}_{i},\hat{C}_{i})=\frac{\hat{Q}_{i}^{T}\hat{C}_{i}}{||\hat{Q}_{i}|||\hat{C}_{i}|} $$
$$\mathcal{L}_{CS}=-\sum_{i=0}^{k}log\frac{e^{s(Q_{i},C_{i})}}{\sum_{j=1}^{u-1}e^{s(Q_{i},C_{j})}}$$

## 3. Detail Pengujian

### Dataset dan Korpus Pelatihan
*   **Korpus Pra-pelatihan (SCL):** Hanya 40.000 contoh bimodal (20k Java, 20k Python) dari CodeSearchNet, **kurang dari sepersepuluh** dari yang digunakan *baseline* CL.
*   **Dataset Fine-tuning/Uji:** CodeSearchNet (Python/Java), CoSQA (Python), StaQC (Python), dan WebQuery (Code Question Answering).

### Baseline
Sepuluh model canggih diklasifikasikan menjadi:
1.  **Encoder-Only:** RoBERTa(code), CodeBERT, GraphCodeBERT, SyncoBERT.
2.  **Encoder-Decoder:** CodeT5, SPT-Code, UniXcoder.
3.  **Contrastive Learning (CL):** CoCoSoDa, CodeRetriever, MCodeSearcher (semuanya dilatih pada korpus yang jauh lebih besar).

### Metrik Evaluasi
*   **Code Retrieval (CSN, CoSQA, StaQC):** **Mean Reciprocal Rank (MRR)**.
$$MRR = \frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{Rank_{i}}$$
*   **Code Question Answering (WebQuery):** **Accuracy** (persentase contoh di mana potongan kode menjawab kueri NL yang diberikan).

## 4. Hasil Eksperimen

### Perbandingan Kinerja Utama (RQ1)
SCodeSearcher menunjukkan kinerja yang sebanding atau unggul pada dataset yang lebih berorientasi pada bahasa alami (CoSQA, StaQC, WebQuery), meskipun menggunakan data pelatihan yang sangat sedikit.

| Model (Type) | CSN-Python (MRR) | CSN-Java (MRR) | COSQA (MRR) | StaQC (MRR) | WebQuery (Acc.) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| GraphCodeBERT (En-Only) | 69.20 | 69.10 | 67.50 | 23.80 | 54.39 |
| UniXcoder (En-De) | 72.17 | 72.67 | 70.10 | 25.74 | 55.74 |
| MCodeSearcher (CL) | 83.54 | 79.57 | 77.23 | 25.93 | 57.07 |
| **SCodeSearcher (SCL)** | **71.23** | **73.08** | **78.84** | **26.52** | **59.64** |

*   **Analisis Kunci:** SCodeSearcher secara signifikan mengungguli *state-of-the-art* CL (MCodeSearcher) pada CoSQA (peningkatan relatif 2.08% MRR) dan StaQC (peningkatan relatif 3.03% MRR). Hal ini memvalidasi bahwa menyoroti contoh-contoh yang menantang adalah strategi yang **efektif dan efisien** untuk menggali hubungan semantik.

### Dampak Rentang Bobot (RQ2)
Bobot $\alpha$ (positif) dan $\beta$ (negatif) memengaruhi kinerja secara signifikan.

| Setting Bobot | COSQA (MRR) | StaQC (MRR) |
| :--- | :--- | :--- |
| GraphCodeBERT | 67.50 | 23.80 |
| $\alpha=0.2$ (Optimal) | 78.84 | 26.52 |
| $\alpha=0.4$ | 68.09 | 24.73 |
| $\beta=1.3$ (Optimal) | 78.84 | 26.52 |
| $\beta=1.7$ | 70.24 | 25.92 |

*   **Analisis:** Bobot $\alpha$ yang terlalu tinggi (misalnya, 0.4) menurunkan kinerja drastis karena model mungkin menjadi terlalu sensitif terhadap gaya pemrograman non-standar dari contoh augmentasi, mengabaikan gaya yang umum dalam korpus kandidat. Bobot $\beta$ yang terlalu tinggi (misalnya, 1.7) membuat model terlalu fokus membedakan *false positive* dan mengabaikan negatif lainnya. Memilih rentang bobot yang tepat sangatlah penting.

### Desain Penyorotan Contoh Menantang (RQ3)
Perbandingan dilakukan antara strategi **Fusion-First** (mengagregasi vektor representasi positif, yang digunakan dalam SCodeSearcher) dan **Fusion-Last** (mengagregasi skor kesamaan).

| Strategi | COSQA (MRR) | StaQC (MRR) |
| :--- | :--- | :--- |
| **Fusion-First (SCodeSearcher)** | **78.84** | **26.52** |
| Fusion-Last | 45.56 | 21.47 |

*   **Analisis:** Strategi **Fusion-First** jauh lebih unggul. Hal ini menunjukkan bahwa menggabungkan representasi semantik di awal (pada vektor $C_{i,+}$) adalah cara yang lebih baik untuk secara **memadai menyoroti contoh-contoh menantang** dan secara efektif menyelaraskan hubungan semantik antara kode dan kueri.

## 5. Kesimpulan

SCodeSearcher berhasil memperkenalkan *soft contrastive learning* untuk mengatasi skenario menantang *code search* dengan mengoptimalkan bobot contoh positif yang beragam dan contoh negatif *false positive*. Model ini menunjukkan efektivitas dan efisiensi yang luar biasa, mampu mencapai kinerja yang sebanding dengan model *state-of-the-art* CL, namun hanya menggunakan **kurang dari sepersepuluh** data pelatihan. Hal ini menghasilkan penghematan signifikan pada sumber daya komputasi dan waktu pelatihan.

::: info Dampak Praktis
SCodeSearcher menawarkan solusi yang **efisien sumber daya** dan **efektif** untuk *code search*. Kemampuannya untuk membedakan kode yang membingungkan dan mengambil implementasi yang beragam akan langsung meningkatkan pengalaman dan produktivitas pengembang, memungkinkan integrasi kode yang lebih mulus ke dalam proyek dengan berbagai gaya pemrograman.
:::