---
title: Review Paper - Toolkit NLP Sumber Terbuka untuk Pengembangan Perangkat Lunak
description: Rangkuman paper tentang pengembangan *toolkit* NLP untuk deteksi *bug*, peringkasan kode, dan *semantic parsing* (Open Research Europe, 2023).
head:
  - - meta
    - name: keywords
      content: Natural Language Processing, Variable Misuse, Code Summarisation, Semantic Parsing, Deep Learning, Software Engineering, DECODER
---

# 061 - An open-source natural language processing toolkit to support software development: addressing automatic bug detection, code summarisation and code search

Tautan (DOI) [https://doi.org/10.12688/openreseurope.14507.2](https://doi.org/10.12688/openreseurope.14507.2)

**Penulis:** **Cristian Robledo** ᵃ*, **Francesca Sallicati** ᵃ*, **Gaël de Chalendar** ᵇ, **Marcos Fernández** ᵃ, **Pablo de Castro** ᵃ, **Eduardo Martín** ᵃ, **Javier Gutiérrez** ᵃ*, **Yannis Bouachera** ᵇ

**Afiliasi:**
* ᵃ Tree Technology, Llanera, Asturias, Spain
* ᵇ CEA, Paris, Île-de-France, France

**Kronologi:** First published: 14 Mar 2022 • Latest published: 27 Oct 2023

<a href="https://www.scimagojr.com/journalsearch.php?q=21101120611&tip=iss" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21101120611" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi (jurnal, topik):** Open Research Europe (Jurnal Akses Terbuka), 2023, 2:37. Paper ini memperkenalkan pekerjaan yang dilakukan dalam proyek Horizon 2020 DECODER (DEveloper Companion for Documented and annotated code Reference).<br><br>**Masalah & Solusi:**<br>• **Masalah:** Pengembang perangkat lunak kehilangan sekitar 60% produktivitas mereka untuk tugas-tugas *tedious* (membosankan) dan memakan waktu seperti *debugging*, pendokumentasian manual, atau pencarian contoh kode (*snippet*).<br>• **Solusi:** Mengembangkan dan mengintegrasikan *toolkit* berbasis **Natural Language Processing (NLP) dan Deep Learning** ke dalam *framework* **Persistent Knowledge Monitor (PKM)** DECODER, yang menyediakan solusi otomatis untuk tiga tugas utama.<br><br>**Contoh Penerapan:**<br>• Model dievaluasi menggunakan empat *use case* DECODER pada bahasa pemrograman **Java, C, dan C++**.<br>• Data diperkaya (*data augmentation*) menggunakan repositori publik seperti GitHub (OpenCV, MyThaiStar, Code and Comments Dataset).<br><br>**Metodologi:**<br>• **VarMisuse:** Model *encoder-decoder* berbasis **LSTM** dengan **Pointer Networks** untuk mendeteksi lokasi dan memperbaiki salah penggunaan variabel secara bersamaan.<br>• **Code Summarisation:** Menggunakan arsitektur **Transformer** (terinspirasi dari Ahmad et al. [5]) untuk menghasilkan deskripsi bahasa alami dari kode sumber.<br>• **Semantic Parsing:** Menggunakan model terjemahan mesin berbasis **RecycleBERT** (BERT *pre-trained* sebagai *encoder*) dan **TRANX** (untuk menghasilkan kode yang secara sintaksis benar menggunakan ASDL).<br><br>**Temuan Kunci:**<br>1. **VarMisuse:** Mencapai Akurasi Klasifikasi $\approx 93\%$ (Java, C/C++). Akurasi Lokalisasi + Perbaikan tertinggi dicapai oleh model Java ($\approx 71\%$), lebih tinggi dari C/C++ ($\approx 60\%$), kemungkinan karena keterbatasan ukuran dataset C/C++.<br>2. **Code Summarisation:** Model versi diperkaya menunjukkan kemampuan generalisasi yang lebih baik dan sedikit mengungguli versi tanpa diperkaya, terutama untuk C dan C++ yang kurang dieksplorasi sebelumnya.<br>3. **Semantic Parsing (Java):** RecycleBERT mencapai skor BLEU 4 tertinggi ($\mathbf{35}$), melampaui hasil SOTA sebelumnya ($\mathbf{22}$), meskipun kode yang dihasilkan masih rentan terhadap kesalahan sintaksis.<br><br>**Kontribusi Utama:**<br>• Pengembangan tiga alat NLP *deep learning* yang ditargetkan (VarMisuse, Code Summarisation, Semantic Parsing) untuk bahasa yang banyak digunakan (Java, C, C++).<br>• Validasi model pada dataset *use case* industri kecil dan menengah (DECODER), menunjukkan solusi yang dapat diterapkan pada data terbatas.<br>• Memperluas model VarMisuse SOTA ke bahasa C dan C++.<br><br>**Dampak:**<br>• Meningkatkan produktivitas pengembang, pemelihara, dan *reviewer* dengan mengotomatisasi tugas-tugas membosankan seperti *debugging* (VarMisuse) dan pendokumentasian kode. |

## 1. Pendahuluan & Masalah

Ketergantungan dunia pada perangkat lunak berkualitas tinggi menuntut peningkatan efisiensi dalam proses pengembangan. Faktanya, diperkirakan pengembang kehilangan hingga 60% waktu produktif mereka karena kesulitan memahami kode yang ditulis dengan buruk atau melakukan tugas-tugas rutin seperti mendeteksi *bug* atau mencari dokumentasi.

*Research Group* telah mulai mengadaptasi arsitektur *deep learning* untuk memenuhi kebutuhan tugas *Software Engineering*, termasuk perbaikan otomatis, *code completion*, dan peringkasan kode. Proyek **DECODER** bertujuan meningkatkan produktivitas profesional TI melalui **Persistent Knowledge Monitor (PKM)**, sebuah *framework* pusat yang menyimpan semua data, informasi, dan pengetahuan terkait ekosistem perangkat lunak.

::: tip Solusi yang Diusulkan
Paper ini berfokus pada tiga alat berbasis **Natural Language Processing (NLP) dan Deep Learning** yang dikembangkan dan diintegrasikan ke dalam PKM untuk mendukung pengembang dalam tugas-tugas harian: **Deteksi dan Perbaikan Salah Penggunaan Variabel (VarMisuse)**, **Peringkasan Kode Otomatis (Code Summarisation)**, dan **Parsing Semantik (Semantic Parsing)** (untuk menghasilkan kode dari instruksi NL).
:::

## 2. Metodologi

Alat-alat NLP dikembangkan sebagai bagian dari paket kerja "Activities for the developer", dengan fokus pada bahasa Java, C, dan C++.

### A. Variable Misuse

Tujuan dari alat ini adalah untuk melokalisasi dan memperbaiki *bug* **VarMisuse** (penggunaan variabel yang salah).

1.  **Arsitektur:** Menggunakan model **LSTM** *encoder-decoder* yang dikombinasikan dengan **Pointer Networks** (terinspirasi dari Vasic et al. [8]).
2.  **Mekanisme Pointer:** Model melatih dua *pointer* (didistribusikan di atas token program): *pointer* pertama memprediksi **lokasi** *bug*, dan *pointer* kedua memprediksi **lokasi variabel perbaikan** yang benar.
3.  **Preparasi Dataset:** *Bug* disintesis secara terprogram pada file kode yang sehat (*bug-free*) dari *use case* DECODER. Untuk memastikan keseimbangan $50/50$ antara file *buggy* dan non-*buggy*, salinan file asli disertakan untuk setiap file *buggy* yang dibuat.
4.  **Fitur:** Kode di-*tokenize* menggunakan **Pygments**, kemudian diproses dengan *padding* dan *truncation* menjadi urutan token sepanjang 200, di mana setiap token dipetakan ke representasi numerik.

### B. Code Summarisation

Alat ini bertujuan menghasilkan deskripsi bahasa alami dari kode sumber, membantu pemahaman kode.

1.  **Arsitektur:** Menggunakan model berbasis **Transformer** (arsitektur *encoder-decoder*) karena keunggulannya dalam menangani ketergantungan jarak jauh (*long-range dependencies*) dan kemampuan komputasi paralel.
2.  **Preprocessing:** Tokenisasi dilakukan dengan **Pygments** (untuk kode) dan *tokenizer* tradisional (untuk deskripsi NL), diikuti dengan pengubahan kasus menjadi *lowercase*, penghapusan token frekuensi rendah (<3 kali), dan penambahan token `<START>` / `<END>`.
3.  **Panjang Urutan:** Urutan kode masukan ditetapkan pada 200 token, dan deskripsi NL keluaran pada 15 token.

### C. Semantic Parsing

Tugas ini merupakan kebalikan dari *code summarisation*: mengubah bahasa alami menjadi kode program (Java atau C++).

1.  **Model yang Dievaluasi:** Dievaluasi beberapa model termasuk **Transformer** klasik, **TRANX** (menggunakan sistem transisi untuk menghasilkan *Abstract Syntax Tree*/AST yang secara sintaksis benar), dan **RecycleBERT** (menggunakan BERT *pre-trained* sebagai *encoder*).
2.  **RecycleBERT:** Dilatih dalam dua langkah: (1) melatih *decoder* dengan parameter BERT dibekukan (*frozen*), (2) *fine-tuning* seluruh model.
3.  **Model Unggulan:** Digunakan gabungan RecycleBERT dan TRANX untuk menghasilkan kode Java dan C++ yang akurat dan valid.

## 3. Detail Pengujian

### A. Dataset

| Use Case | Leader | Programming Language | Files | Lines of code |
| :--- | :--- | :--- | :--- | :--- |
| Drivers | SYSGO | C | 317 | 38,078 |
| OpenCV | TREE | C++ | 593 | 18,435 |
| MyThaiStar | CAPGEMINI | Java | 471 | 906 |
| Java | OW2 | Java | 7,553 | 116,867 |

Dataset **C/C++** dan **Java** juga diperkaya (*augmented*) dengan data dari repositori publik (GitHub/Zenodo) untuk meningkatkan ukuran dan kualitas, terutama untuk mengatasi kelangkaan data C/C++ (di mana C dan C++ digabungkan).

### B. Metrik Evaluasi

1.  **VarMisuse:**
    *   *True Negative Rate*
    *   *Classification Accuracy*
    *   *Localisation Accuracy* (Akurasi Lokasi *bug*)
    *   *Localisation + Repair Accuracy* (Akurasi Lokasi dan Perbaikan *bug*)
2.  **Code Summarisation:**
    *   **BLEU 4 Score** (*Sentence level* dan *Corpus level*, menggunakan *smoothing function* NLTK 'method4')
    *   **SacreBLEU** (untuk mengatasi masalah *pre-processing*)
    *   **ROUGE-L** (menggunakan *Longest Common Subsequence* untuk mengukur $F_1$-score, *precision*, dan *recall*).
3.  **Semantic Parsing:**
    *   **BLEU 4 Score** (untuk perbandingan dengan SOTA).

## 4. Hasil Eksperimen

### A. Hasil Variable Misuse

| Use Cases | True Positive | Classification Accuracy | Localisation Accuracy | Localisation + Repair Accuracy |
| :--- | :--- | :--- | :--- | :--- |
| Java | 99.7% | 93.7% | 88.6% | 71.1% |
| C/C++ | 99.6% | 92.9% | 85.4% | 60.6% |

**Analisis:**
*   Model menunjukkan kinerja klasifikasi yang sangat baik ($\approx 93\%$) untuk kedua bahasa.
*   Model **Java** secara signifikan mengungguli model **C/C++** dalam kemampuan perbaikan (*Repair Accuracy*), mencapai $\mathbf{71.1\%}$ dibandingkan $\mathbf{60.6\%}$. Hal ini disebabkan oleh ukuran dataset C/C++ yang lebih kecil, meskipun sudah diperkaya.
*   Performa ini diklaim lebih baik daripada hasil yang dilaporkan dalam karya asli Vasic et al. [8] pada Python dan C\#, meskipun penulis mencatat bahwa perbedaan tersebut mungkin dipengaruhi oleh konteks kode yang lebih kecil dan kemudahan *bug* yang dihasilkan secara sintetis.

### B. Hasil Code Summarisation

Model yang diperkaya (*augmented*) menunjukkan kinerja yang lebih baik dalam hal generalisasi, meskipun skor BLEU dan ROUGE-L pada *test set* mungkin tidak selalu tertinggi karena keterbatasan metrik tersebut dalam mencerminkan kualitas semantik dan tata bahasa (misalnya, kemampuan *paraphrasing* model).

| Metric (Test Set) | Java DECODER Model | Java Augmented Model | C/C++ DECODER Model | C/C++ Augmented Model |
| :--- | :--- | :--- | :--- | :--- |
| BLEU 4 (smooth) | 42.78 | 31.85 | 38.64 | 41.75 |
| Corpus BLEU | 48.35 | 35.73 | 36.85 | 42.96 |
| ROUGE-L F1-score | 58.61 | 51.59 | 58.43 | 56.12 |

**Analisis:**
*   Model **C/C++ Augmented** mencapai skor *Corpus BLEU* dan *BLEU 4 smooth* tertinggi di antara model C/C++, menunjukkan bahwa penambahan data meningkatkan robustess.
*   Model **C/C++** secara umum menunjukkan kinerja yang baik, bahkan diklaim mengungguli model Java dalam beberapa metrik (terutama versi DECODER murni). Ini merupakan kontribusi penting karena C dan C++ belum banyak dieksplorasi dalam *code summarisation*.

### C. Hasil Semantic Parsing (Java)

| Language | Model | BLEU 4 |
| :--- | :--- | :--- |
| Java (Concode) | Baseline: Concode (authors reported result) | 22 |
| | Transformer | 4 |
| | TRANX | 10.1 |
| | **RecycleBERT** | **35** |
| | RecycleBERT without context | 30.65 |
| | RecycleCharacterBERT | 18.12 |

**Analisis:**
*   Model **RecycleBERT** mencapai skor BLEU 4 tertinggi $\mathbf{35}$, secara signifikan melampaui hasil SOTA yang dilaporkan Concode ($\mathbf{22}$). Hal ini menyoroti keunggulan model NLP terkini dan penggunaan *pre-trained embeddings* BERT.
*   Perbedaan skor yang signifikan antara RecycleBERT dengan dan tanpa konteks menunjukkan bahwa model berhasil menangkap dan menggunakan informasi konteks kelas untuk generasi kode.

## 5. Kesimpulan

Pekerjaan ini berhasil mendemonstrasikan kelayakan dan efektivitas penerapan *toolkit* berbasis **NLP *deep learning*** untuk meningkatkan produktivitas profesional TI. Ketiga alat yang dikembangkan (VarMisuse, Code Summarisation, Semantic Parsing) menunjukkan hasil yang menjanjikan pada bahasa Java, C, dan C++.

Model **VarMisuse** terbukti efektif dalam klasifikasi *bug* dan kemampuan perbaikan, dengan model Java menunjukkan akurasi perbaikan tertinggi. Model **Code Summarisation** berhasil diimplementasikan untuk bahasa C dan C++ yang kurang dieksplorasi, menetapkan titik perbandingan baru. Sementara itu, model **Semantic Parsing (RecycleBERT)** menunjukkan potensi besar untuk mengungguli SOTA dalam generasi kode Java.

::: info Dampak Praktis
Alat-alat ini dapat diintegrasikan dalam siklus hidup pengembangan perangkat lunak untuk secara substansial mengurangi beban kerja *debugging* dan dokumentasi manual. Ada ruang untuk perbaikan di masa depan, termasuk penggunaan representasi kode yang lebih struktural (seperti AST) dan metrik evaluasi yang lebih spesifik untuk kode (seperti CodeBLEU), namun solusi saat ini sudah memberikan dukungan yang valid bagi pengembang dalam pekerjaan sehari-hari.
:::