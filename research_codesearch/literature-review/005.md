---
title: Review Paper - ECSQE untuk Peningkatan Code Search
description: Rangkuman paper tentang model ECSQE yang menggabungkan LSTM, GloVe, dan BERT untuk perluasan kueri dalam pencarian kode (Results in Engineering, 2025).
head:
  - - meta
    - name: keywords
      content: Code search, Query expansion, Deep neural networks, LSTM, GloVe, BERT, Semantic matching
---

# 005 - Enhancing code search through query expansion: A fusion of LSTM with GloVe and BERT model (ECSQE)

**Penulis:** **Nazia Bibi** ᵃ, **Muhammad Usman Tariq** ᵇ, **Zabeeh Ullah** ᵃ, **Muhammad Babar** ᶜ, **Zahid Khan** ᶜ

**Afiliasi:**
* ᵃ Department of Computer Software Engineering, National University of Sciences and Technology, Islamabad, Pakistan
* ᵇ Department of Marketing, Operations, and Information Systems, College of Business, Abu Dhabi University, Abu Dhabi, United Arab Emirates
* ᶜ Robotics and Internet of Things Lab, Prince Sultan University, Riyadh, Saudi Arabia

**Kronologi:** Received: 18 January 2025 • Revised: 11 June 2025 • Accepted: 25 June 2025 • Available Online: 3 July 2025

<a href="https://www.scimagojr.com/journalsearch.php?q=21100904991&tip=sid&clean=0" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21100904991" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Results in Engineering, Vol 27, No 105979 (2025)<br>• **Penerbit:** Elsevier<br>• **Topik:** Peningkatan Pencarian Kode melalui Perluasan Kueri<br><br>**Masalah & Solusi:**<br>• **Masalah:** Kueri pencarian kode yang pendek seringkali tidak berhasil karena kurangnya informasi kontekstual atau spesifik domain (misalnya, nama API, struktur kode). Model tradisional berbasis teks gagal menangkap hubungan linguistik dan struktur kode yang kaya secara semantik.<br>• **Solusi:** Mengusulkan model **ECSQE** (*Enhancing Code Search through Query Expansion*), yang menggabungkan model *word embedding* canggih (**GloVe** dan **BERT**) dengan jaringan sekuensial (**LSTM**) dan **Mekanisme Perhatian** (*Attention Mechanism*) untuk secara otomatis memperluas kueri pengguna dengan istilah yang relevan secara kontekstual dan semantik.<br><br>**Contoh Penerapan:**<br>• **Kueri Awal (NL):** "Sort a list of numbers in descending order."<br>• **Proses ECSQE:** Kueri diperkaya/diperluas secara internal menggunakan pemahaman kontekstual **BERT** dan pemahaman global **GloVe**, diolah secara sekuensial oleh **LSTM**, dan dipertajam oleh *Attention*. Hasilnya berupa representasi kueri yang lebih kaya.<br>• **Keluaran:** Potongan kode (misal: Python atau Java) yang sangat relevan, ditemukan melalui skor kesamaan kosinus yang tinggi antara kueri yang diperluas dan kode yang tersemat.<br><br>**Metodologi:**<br>• **Arsitektur:** Lapisan *Embedding* (GloVe & BERT) $\to$ Lapisan *Fusion* (Penggabungan berbobot) $\to$ Lapisan **LSTM** (untuk dependensi sekuensial) $\to$ Lapisan **Attention** (untuk penekanan kontekstual) $\to$ Lapisan *Ranking* (Kesamaan Kosinus).<br>• **Pengujian:** Menggunakan dataset **CodeSearchNet** (Python & Java) dengan tiga set kueri benchmark ($QuerySet_{99}, QuerySet_{50}, QuerySet_{25}$).<br><br>**Temuan Kunci:**<br>1. **Kinerja Unggul:** ECSQE mengungguli semua *baseline* (UNIF, CNN-CS, DeepCS, CNN-CS-TS) pada semua metrik (Akurasi, F1-Score, MRR, MAP, NDCG) untuk Python dan Java, menunjukkan **peningkatan signifikan** dalam efektivitas pencarian kode.<br>2. **Peran BERT dan Attention:** Varian model yang menyertakan BERT dan Mekanisme Perhatian menunjukkan peningkatan kinerja tertinggi, mengkonfirmasi pentingnya pemahaman kontekstual yang mendalam.<br><br>**Kontribusi Utama:**<br>• Mengusulkan ECSQE, model hibrida *deep learning* baru yang menggabungkan GloVe, BERT, LSTM, dan *Attention* untuk perluasan kueri.<br>• Menghadirkan pendekatan yang **lebih menyeluruh dan efektif** dalam mengatasi keterbatasan teknik perluasan kueri yang ada.<br><br>**Dampak:**<br>• Memberikan alat yang lebih efisien dan akurat bagi pengembang untuk mencari kode, **mengurangi waktu yang dihabiskan untuk formulasi kueri** dan penelusuran hasil.<br><br>**Tautan (DOI):** https://doi.org/10.1016/j.rineng.2025.105979 |

## 1. Pendahuluan & Masalah

Pencarian kode yang efisien dalam repositori besar merupakan tugas penting dalam Rekayasa Perangkat Lunak. Meskipun metode neural canggih telah dikembangkan (seperti NCS), riwayat pencarian menunjukkan bahwa **kueri yang lebih pendek** sering kali menghasilkan sesi pencarian yang kurang berhasil, memaksa pengembang melakukan reformulasi berulang. Perluasan kueri (*query expansion*) adalah solusi yang terbukti dalam *Information Retrieval* (IR) untuk membuat kueri lebih informatif. Namun, teknik perluasan kueri yang ada memiliki kelemahan: (i) Mengabaikan pengetahuan spesifik domain dan konteks kode; (ii) Tidak mampu menangkap hubungan linguistik dan struktur kode yang kaya secara semantik (misalnya, panggilan fungsi, pencocokan struktur data); dan (iii) Kurangnya kerangka evaluasi yang kuat di berbagai bahasa dan repositori.

::: tip Solusi yang Diusulkan
Model **ECSQE** (*Enhancing Code Search through Query Expansion*) diusulkan untuk menjembatani kesenjangan ini. ECSQE mengintegrasikan **LSTM**, *word embedding* global (**GloVe**) dan kontekstual (**BERT**) serta **Mekanisme Perhatian** untuk belajar dan memahami cara memasangkan potongan kode secara koheren dengan kueri yang diperluas dan relevan secara semantik.
:::

## 2. Metodologi

Metodologi ECSQE adalah pendekatan multi-faset yang berpusat pada perpaduan dua teknik *word embedding* canggih dengan jaringan neural sekuensial.

### A. Lapisan Pemrosesan Input dan Embedding
Kueri bahasa alami (NL) di-*tokenize* dan di-*embed* melalui dua jalur paralel:
*   **GloVe Embeddings:** Menghasilkan vektor statis yang menangkap pola *co-occurrence* global dari seluruh kosakata, memberikan makna semantik umum ($v_i$).
*   **BERT Embeddings:** Menghasilkan vektor yang sadar konteks, mempertimbangkan seluruh kueri sekaligus untuk memahami nuansa kontekstual spesifik di sekitar setiap kata ($e_i$).

### B. Lapisan Fusion ($F_q$)
Lapisan ini menggabungkan vektor GloVe dan BERT menggunakan rata-rata berbobot sederhana:
$$f_{i} = \alpha v_{i} + (1-\alpha)e_{i}$$

Di mana $\alpha$ adalah faktor pembobotan yang dapat disetel (*tunable hyperparameter*) untuk menyeimbangkan pengaruh makna semantik umum (GloVe) versus nuansa spesifik konteks (BERT).

### C. Lapisan LSTM dan Mekanisme Perhatian
Vektor *fusion* diumpankan ke jaringan **LSTM** (dua lapisan).
*   **LSTM:** Bertujuan menangkap sifat sekuensial dan dependensi jangka panjang dalam kueri, yang penting untuk menafsirkan niat pengguna secara akurat.
*   **Mekanisme Perhatian (*Attention*):** Diintegrasikan dengan LSTM untuk menghasilkan vektor konteks ($c_t$) yang menyoroti bagian-bagian kueri yang paling penting. Bobot perhatian ($a_t$) dihitung melalui *softmax* pada skor kesamaan antara *hidden state* saat ini ($h_t$) dan *hidden state* sebelumnya ($h_s$):

$$a_{t}=Softmax(score(h_{t},h_{s}))$$

Vektor konteks kemudian digabungkan dengan *hidden state* LSTM saat ini ($h_t$) untuk membuat representasi kueri yang ditingkatkan dan fokus pada perhatian ($h'_t$):

$$h_{t}^{\prime}=tanh(W_{c}[c_{t};h_{t}])$$

### D. Representasi Kode dan Ranking
Kode sumber juga di-*embed* dan di-*fusion* (Fc). Kesamaan antara representasi kueri yang ditingkatkan ($F_q$) dan representasi kode yang digabung ($F_c$) diukur menggunakan **kesamaan kosinus**:

$$Cosine( F_{q},F_{c})$$

Potongan kode kemudian diperingkat dalam urutan menurun berdasarkan skor kesamaan ini.

## 3. Detail Pengujian

### Dataset
*   **Dataset:** Subset **CodeSearchNet** (Python dan Java).
    *   Java: 1.560.804 sampel (Train: 1.402.976, Test: 87.682).
    *   Python: 1.418.606 sampel (Train: 1.274.986, Test: 79.787).
*   **Kueri Benchmark:** Tiga set kueri standar digunakan untuk evaluasi: $QuerySet_{99}, QuerySet_{50}, QuerySet_{25}$.

### Baseline Model
Model *baseline* yang digunakan untuk perbandingan adalah:
*   **DeepCS** (RNN + MLP)
*   **CNN-CS** (CNN + LSTM + Attention)
*   **UNIF** (Attention-based weighting)
*   **CNN-CS-TS** (CNN-CS dengan fitur struktural AST)
*   **UNIF-TS** (UNIF dengan fitur struktural AST)

### Metrik Evaluasi
Tujuh metrik standar digunakan untuk penilaian komprehensif:

*   **Akurasi (Accuracy):**
$$Accuracy = \frac{TP+TN}{TP+TN+FP+FN}$$
*   **Presisi (Precision):**
$$Precision=\frac{TP}{TP+FP}$$
*   **Recall:**
$$Recall = \frac{TP}{TP+FN}$$
*   **F1-Score:**
$$F1-Score=2\times\frac{Precision\times Recall}{Precision+Recall}$$
*   **Mean Reciprocal Rank (MRR):**
$$MRR=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{Rank_{i}}$$
*   **Mean Average Precision (MAP):**
$$MAP=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{AP_{i}}$$
*   **Normalized Discounted Cumulative Gain (NDCG):**
$$NDCG=\frac{DCG}{IDCG}$$

## 4. Hasil Eksperimen

### Perbandingan Kinerja (RQ1)

ECSQE secara konsisten mengungguli semua model *baseline* di semua set kueri untuk bahasa Java dan Python.

| Bahasa | Query Set | Model | Akurasi | F1-Score | MRR | NDCG |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Java** | $QuerySet_{99}$ | CNN-CS-TS | 0.610 | 0.640 | 0.580 | 0.610 |
| | | **ECSQE** | **0.830** | **0.850** | **0.840** | **0.870** |
| | $QuerySet_{50}$ | CNN-CS-TS | 0.620 | 0.650 | 0.590 | 0.620 |
| | | **ECSQE** | **0.840** | **0.860** | **0.850** | **0.880** |
| **Python** | $QuerySet_{99}$ | CNN-CS-TS | 0.75 | 0.77 | 0.76 | 0.78 |
| | | **ECSQE** | **0.90** | **0.91** | **0.90** | **0.92** |
| | $QuerySet_{50}$ | CNN-CS-TS | 0.77 | 0.78 | 0.77 | 0.79 |
| | | **ECSQE** | **0.91** | **0.92** | **0.91** | **0.93** |

*   **Analisis:** Kinerja DeepCS adalah yang terendah di hampir semua skenario, menunjukkan tantangan model RNN/MLP sederhana dalam menghadapi kompleksitas kueri modern. ECSQE menunjukkan peningkatan signifikan (misalnya, Akurasi ~36% lebih tinggi dari CNN-CS-TS untuk $QuerySet_{99}$ Java), yang dikaitkan dengan perluasan kueri kontekstual yang unggul.

### Dampak Embedding dan Attention (RQ2)

Kinerja model meningkat secara progresif seiring penambahan komponen yang lebih canggih (Java Language, Rata-rata Query Sets):

| Model Varian | Akurasi | F1-Score | MRR | Analisis Kunci |
| :--- | :--- | :--- | :--- | :--- |
| ECSQE (GloVe+LSTM) | 0.82 | 0.83 | 0.81 | Base model (Static Semantics) |
| ECSQE (BERT+LSTM) | 0.85 | 0.86 | 0.84 | Peningkatan signifikan (Contextual Semantics) |
| ECSQE (GloVe+BERT+LSTM) | 0.87 | 0.88 | 0.86 | Peningkatan lebih lanjut (Complementary Fusion) |
| **ECSQE (GloVe+BERT+LSTM+Att)** | **0.90** | **0.91** | **0.89** | **Pencapaian tertinggi (Targeted Focus)** |

*   **Result 2:** Penambahan **BERT** secara substansial meningkatkan hasil dengan menangkap nuansa kontekstual. Kombinasi GloVe dan BERT menawarkan informasi pelengkap yang lebih kaya. Kinerja tertinggi dicapai ketika **Mekanisme Perhatian** ditambahkan, membuktikan pentingnya memfokuskan model pada bagian kueri yang paling krusial selama perluasan.

### Analisis Efisiensi (RQ3)

| Model | Waktu Pelatihan (jam) | Waktu Kueri (detik) |
| :--- | :--- | :--- |
| UNIF | 3.2 | 0.3 |
| CNN-CS | 13.2 | 0.5 |
| DeepCS | 35.6 | 1.1 |
| CNN-CS-TS | 15.7 | 0.6 |
| **ECSQE** | **6.2** | **0.4** |

*   **Result 3:** ECSQE menunjukkan **keseimbangan kuat antara efisiensi dan kompleksitas**. Meskipun lebih lambat dari UNIF, ECSQE jauh lebih cepat dilatih daripada model yang lebih kompleks (DeepCS, CNN-CS-TS) dan menawarkan waktu respons kueri yang sangat cepat (0.4 detik), menjadikannya praktis untuk aplikasi *real-time*.

## 5. Kesimpulan

Model ECSQE yang diusulkan berhasil meningkatkan kinerja pencarian kode secara signifikan melalui skema perluasan kueri berbasis *deep learning*. Dengan memadukan GloVe dan BERT, diolah secara sekuensial oleh LSTM, dan diperkuat oleh Mekanisme Perhatian, ECSQE unggul dalam memahami niat kueri yang kompleks dan struktur semantik kode. Model ini menghasilkan skor tertinggi di semua metrik dan set kueri, mengkonfirmasi keefektifannya dibandingkan model tradisional. Konfigurasi optimal dicapai menggunakan pengoptimal **Adam** dengan 30 *epoch* dan *batch size* 64.

::: info Dampak Praktis
ECSQE menawarkan transformasiprosedur *code search* dengan memberikan hasil yang sangat **presisi** dan **relevan** bahkan dari kueri awal yang singkat, secara efektif mengurangi waktu pengembangan. Kecepatan kueri yang cepat dikombinasikan dengan akurasi superior ECSQE menjadikannya kandidat yang ideal untuk alat *code search* di lingkungan *software engineering* profesional.
:::