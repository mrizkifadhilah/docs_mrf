---
title: Review Paper - SAN-CS Jaringan Self-Attention untuk Pencarian Kode
description: Rangkuman paper tentang SAN-CS, model pencarian kode berbasis Self-Attention Network yang mengatasi batasan DeepCS dalam efektivitas dan efisiensi (Information and Software Technology, 2021).
head:
  - - meta
    - name: keywords
      content: Code search, Self-attention mechanism, Joint embedding, SAN-CS, Deep Learning
---

# 074 - Self-Attention Networks for Code Search
Tautan (DOI) [https://doi.org/10.1016/j.infsof.2021.106542]

**Penulis:** **Sen Fang** $^{a}$, **You-Shuai Tan** $^{a}$, **Tao Zhang** $^{a*}$, **Yepang Liu** $^{b}$

**Afiliasi:**
* $^{a}$ Macau University of Science and Technology, Macau, China
* $^{b}$ Southern University of Science and Technology, Shenzhen, China

**Kronologi:** Received: 18 Oktober 2020 • Revised: 29 Januari 2021 • Accepted: 2 Februari 2021 • Available Online: 10 Februari 2021

<a href="https://www.scimagojr.com/journalsearch.php?q=18732&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=18732" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Information and Software Technology 134 (2021)<br>• **Topik:** Peningkatan model pencarian kode (*code search*) berbasis *deep learning* menggunakan mekanisme *Self-Attention* untuk mengatasi keterbatasan LSTM.<br><br>**Masalah & Solusi:**<br>• **Masalah 1:** Model DeepCS (*state-of-the-art* berbasis *deep learning* pertama) menggunakan dua LSTM terpisah, mengabaikan hubungan semantik langsung antara potongan kode dan deskripsinya, yang menciptakan hambatan kinerja (*performance bottleneck*).<br>• **Masalah 2:** Arsitektur sekuensial LSTM (*Long Short-Term Memory*) lambat dalam eksekusi dan tidak dapat menangkap informasi kontekstual global secara penuh (memerlukan $O(n)$ operasi sekuensial).<br>• **Solusi:** Mengusulkan **SAN-CS** (*Self-Attention Network for Code Search*). SAN-CS menggunakan **Self-Attention Networks (SANs)** untuk: (1) merepresentasikan kode dan deskripsi secara terpisah dengan menangkap informasi kontekstual global yang lebih baik, dan (2) menggunakan Jaringan *Self-Attention* tambahan sebagai **Jaringan *Code-Description Attention*** untuk membangun hubungan semantik mendalam (*joint representation*) antara vektor kode dan vektor kueri sebelum pemetaan ruang vektor.<br><br>**Contoh Penerapan:**<br>• Diuji pada *dataset* publik Java skala besar (18.23 juta sampel pelatihan) yang dibagikan oleh Gu et al. (pengembang DeepCS).<br>• SAN-CS mencapai MRR **0.908**, jauh melebihi DeepCS (0.568) dan CARLCS-CNN (0.535).<br><br>**Metodologi:**<br>• **Arsitektur:** Mengganti LSTM/CNN pada DeepCS dengan *Self-Attention Networks* (SANs) dan menambahkan Jaringan *Code-Description Attention* (CDAN).<br>• **Penyematan Kode:** Kode dibagi menjadi 3 komponen (Nama Metode, API, Token). Masing-masing dienkode menggunakan SANs untuk mendapatkan $v_{name}, v_{api}, v_{token}$. Kemudian dikonkatenasi: $V_{code} = \text{concat}(v_{name}, v_{api}, v_{token})$.<br>• **Penyematan Deskripsi:** Kueri deskripsi dienkode menggunakan SANs untuk mendapatkan $V_{desc}$.<br>• **Jaringan *Code-Description Attention* (CDAN):** Menggunakan varian *self-attention network* untuk menghasilkan representasi bersama $c$ (kode) dan $d$ (deskripsi), yang secara eksplisit membangun korelasi semantik antar-modal.<br>$$A=\text{SoftMax}(\frac{Q_{c}\cdot K_{d}^{T}}{\sqrt{d}})$$ <br>$$c=A\cdot V_{d}; \quad d=A^{T}\cdot V_{c}$$ <br>• **Representasi Akhir:** Vektor $c$ dan $d$ dikonversi menjadi vektor semantik akhir $C$ dan $D$ menggunakan operasi **Average-Pooling** (Max-pooling ditemukan tidak valid karena SANs sudah membangun vektor kontekstual).<br>• **Pelatihan:** Meminimalisir fungsi *rank loss* untuk mendorong vektor dengan semantik serupa agar berdekatan di ruang vektor bersama. <br>$$L(\theta)=\max(0,\xi-\cos(c,d^{+})+\cos(c,d^{-}))$$<br><br>**Temuan Kunci:**<br>1. **Efektivitas Unggul:** SAN-CS secara signifikan mengungguli DeepCS (peningkatan MRR $\mathbf{59.9\%}$) dan CARLCS-CNN, membuktikan bahwa SANs dapat menangkap informasi kontekstual dan semantik yang lebih kaya.<br>2. **Efisiensi Cepat:** SAN-CS 3,3 kali lebih cepat dalam pelatihan (0.3ms/sampel vs 1.0ms/sampel DeepCS) dan 6 kali lebih cepat dalam pencarian (0.1s/kueri vs 0.6s/kueri DeepCS) karena arsitektur *self-attention* memungkinkan komputasi paralel pada GPU.<br>3. **Pentingnya *Joint Representation*:** Model varian SAN-CS tanpa Jaringan *Code-Description Attention* hanya menunjukkan sedikit peningkatan dibandingkan DeepCS (MRR 0.577 vs 0.568), menunjukkan bahwa SANs saja tidak cukup; **Jaringan *Joint Representation*** adalah kunci peningkatan kinerja yang drastis.<br>4. **Parameter Optimal:** Pengaturan parameter terbaik adalah dimensi penyematan $d=\mathbf{128}$ dan menggunakan **satu lapisan *Self-Attention***, yang berbeda dari model Transformer (6 lapisan).<br><br>**Kontribusi Utama:**<br>• Mengusulkan SAN-CS, model pencarian kode pertama yang sepenuhnya berbasis *Self-Attention Network*.<br>• Memperkenalkan Jaringan *Code-Description Attention* untuk membangun *joint representation* semantik antar-modal yang mendalam.<br>• Mendemonstrasikan peningkatan efektivitas dan efisiensi yang signifikan dibandingkan DeepCS dan CARLCS-CNN.<br><br>**Dampak:**<br>• Menyediakan alat *code search* dengan kinerja tinggi (MRR $>0.9$) dan waktu respons yang cepat, secara efektif **menghemat waktu pengembang** (yang menghabiskan rata-rata 20% waktunya untuk mencari kode) dan mempercepat siklus pengembangan produk. |

## 1. Pendahuluan & Masalah

Pencarian kode (*code search*) adalah aktivitas penting yang sering dilakukan dalam pengembangan perangkat lunak untuk menemukan dan menggunakan kembali potongan kode yang sudah ada, yang secara langsung meningkatkan produktivitas pengembang. Namun, merancang alat pencarian kode yang efektif adalah tantangan karena adanya **kesenjangan semantik** (*semantic gap*) antara kueri bahasa alami (NL) dan kode sumber (PL). Metode *Information Retrieval* (IR) tradisional gagal membangun jembatan semantik ini karena fokus utamanya pada kesamaan teks.

DeepCS (*Deep Code Search*) yang diusulkan oleh Gu et al. adalah model pencarian kode pertama berbasis *deep learning* yang mengungguli model IR tradisional. Namun, DeepCS menggunakan dua model LSTM (*Long Short-Term Memory*) terpisah untuk menyematkan kode dan deskripsi, lalu mencoba menyelaraskan keduanya di ruang vektor bersama. Pendekatan ini **mengabaikan hubungan semantik antar-modal** sebelum operasi penyematan akhir, sehingga membatasi kinerja model. Selain itu, sifat sekuensial LSTM menyebabkan efisiensi eksekusi yang lambat.

::: tip Solusi yang Diusulkan
Diperkenalkan **SAN-CS** (*Self-Attention Network for Code Search*), model yang sepenuhnya menggantikan LSTM dengan **Self-Attention Networks (SANs)** untuk: (1) merepresentasikan kode dan deskripsi secara terpisah, karena SANs lebih baik dalam menangkap informasi kontekstual global dengan komputasi paralel, dan (2) membangun **Jaringan *Joint Representation*** (Jaringan *Code-Description Attention*) menggunakan *self-attention* untuk secara eksplisit menciptakan hubungan semantik mendalam antara vektor kode dan kueri sebelum proyeksi akhir, sehingga memecahkan hambatan kinerja DeepCS.
:::

## 2. Metodologi

SAN-CS adalah model representasi pembelajaran bersama yang didasarkan sepenuhnya pada arsitektur *self-attention network*.

### A. Penyematan Kode

Potongan kode diproses menjadi tiga sekuens (Nama Metode, API, Token), yang masing-masing dienkode secara individual oleh **SANs** dan kemudian digabungkan.

1.  **SANs untuk Sekuens:**
    *   Berbeda dengan LSTM dan CNN, SANs memanfaatkan mekanisme *self-attention* (berbasis operasi *dot-product* dan rata-rata berbobot) untuk menangkap informasi kontekstual global untuk setiap elemen sekuens, tanpa bergantung pada jarak.
    *   Setiap sekuens $S_n$ diubah menjadi vektor Kueri $Q_n$, Kunci $K_n$, dan Nilai $V_n$ melalui matriks bobot yang dapat dipelajari ($W_Q, W_K, W_V$).
    *   Vektor konteks dihitung:
    $$\text{context}_n=\text{SoftMax}(\frac{Q_{n}\cdot K_{n}^{T}}{\sqrt{d}})\cdot V_{n}$$
    *   Output akhir $v$ diperoleh dengan memasukkan $\text{context}_n$ ke Jaringan *Feed-Forward* posisi-bijaksana.

2.  **Penggabungan Penyematan:**
    *   $v_{name}, v_{api}$, dan $v_{token}$ yang telah disematkan digabungkan melalui konkatenasi sederhana untuk membentuk vektor kode gabungan $V_{code} \in \mathbb{R}^{(I+N+M)\times d}$.

### B. Penyematan Deskripsi

Kueri deskripsi bahasa alami dienkode menggunakan **SANs** yang serupa (Langkah 1 di atas) untuk menghasilkan vektor deskripsi $V_{desc} \in \mathbb{R}^{J\times d}$.

### C. Jaringan *Code-Description Attention*

Untuk memetakan $\langle V_{code}, V_{desc} \rangle$ ke ruang vektor yang sama dengan lebih baik, **Jaringan *Code-Description Attention*** (CDAN) diterapkan sebagai langkah *joint embedding* tambahan, membangun korelasi semantik antar-modal.

1.  **Representasi Bersama:** $V_{code}$ (sebagai $Q_c$ dan $V_c$) dan $V_{desc}$ (sebagai $K_d$ dan $V_d$) diumpankan ke CDAN.
2.  **Matriks *Attention*:** Matriks *attention* $A$ dihitung, memungkinkan kode dan deskripsi untuk saling memperhatikan:
    $$A=\text{SoftMax}(\frac{Q_{c}\cdot K_{d}^{T}}{\sqrt{d}})$$
3.  **Vektor *Joint Embedding*:** Vektor kode $c$ (*joint embedding* dengan $V_d$) dan vektor deskripsi $d$ (*joint embedding* dengan $V_c$) dihasilkan:
    $$c=A\cdot V_{d}$$
    $$d=A^{T}\cdot V_{c}$$

### D. Pelatihan dan Prediksi

Vektor *joint embedding* $c$ dan $d$ direduksi menjadi vektor semantik akhir $C \in \mathbb{R}^{d}$ dan $D \in \mathbb{R}^{d}$ menggunakan operasi **Average-Pooling**. Model dilatih dengan meminimalisir fungsi *rank loss* untuk memaksimalkan kesamaan kosinus antara vektor kode $c$ dan deskripsi positif $d^+$, sambil meminimalkan kesamaan dengan deskripsi negatif $d^-$.

$$L(\theta)=\max(0,\xi-\cos(c,d^{+})+\cos(c,d^{-}))$$

## 3. Detail Pengujian

### Dataset
*   **Pelatihan:** 18.23 juta metode kode Java dari repositori GitHub (2008-2016).
*   **Pengujian:** 10.000 pasangan kode-kueri Java dari GitHub.

### Baseline Model
1.  **DeepCS:** Model *state-of-the-art* berbasis LSTM.
2.  **CARLCS-CNN:** Model berbasis CNN yang menggunakan *co-attention* untuk membangun hubungan semantik kode-kueri.

### Metrik Evaluasi
Tiga metrik digunakan untuk menilai efektivitas:

1.  **Recall@k (R@k):** Persentase kueri yang kode terkaitnya diindeks dalam daftar *top-k*.
2.  **NDCG (Normalized Discounted Cumulative Gain):** Mengukur kualitas keseluruhan hasil pencarian, memberi bobot lebih tinggi pada hasil yang relevan di peringkat teratas.
3.  **MRR (Mean Reciprocal Rank):** Rata-rata kebalikan peringkat hasil relevan pertama. MRR menunjukkan seberapa pendek daftar yang perlu diperiksa pengembang.
    $$\text{MRR}=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{\text{Index}_{Q_{i}}}$$

## 4. Hasil Eksperimen

### A. Efektivitas Model (RQ1)

Perbandingan kinerja antara DeepCS, CARLCS, dan SAN-CS ditunjukkan pada Tabel 3.

| Model | R@1 | R@5 | R@10 | NDCG | MRR |
| :--- | :--- | :--- | :--- | :--- | :--- |
| DeepCS | 0.585 | 0.750 | 0.816 | 0.626 | 0.568 |
| CARLCS | 0.549 | 0.713 | 0.782 | 0.592 | 0.535 |
| **SAN-CS** | **0.931** | **0.956** | **0.962** | **0.921** | **0.908** |

*   **Kesimpulan:** SAN-CS secara signifikan mengungguli DeepCS dan CARLCS-CNN pada semua metrik. Peningkatan MRR sebesar **59.9%** dibandingkan DeepCS membuktikan efektivitas jaringan *self-attention* dan *joint representation*.

### B. Efisiensi Model (RQ2)

| Model | Parameters | Training | Searching |
| :--- | :--- | :--- | :--- |
| DeepCS | 5.81M | 1.0ms/sample | 0.6s/query |
| **SAN-CS** | 6.64M | **0.3ms/sample** | **0.1s/query** |

*   **Kesimpulan:** SAN-CS menunjukkan peningkatan efisiensi yang dramatis. SAN-CS melatih 3,3 kali lebih cepat dan mencari 6 kali lebih cepat daripada DeepCS, berkat kemampuan komputasi paralel *self-attention network* di GPU.

### C. Efek Jaringan *Self-Attention* (RQ3)

Model varian SAN-CS (tanpa *joint representation network*) dibandingkan dengan DeepCS dan CARLCS:

| Model | R@1 | MRR |
| :--- | :--- | :--- |
| DeepCS | 0.585 | 0.568 |
| CARLCS | 0.549 | 0.535 |
| SAN-CS$_{only}$ | 0.595 | 0.577 |
| **SAN-CS** | **0.931** | **0.908** |

*   **Kesimpulan:** SAN-CS$_{only}$ hanya menunjukkan sedikit peningkatan (MRR 0.577) dibandingkan *baseline*, menunjukkan bahwa representasi sekuens SANs saja tidak cukup untuk mengatasi *semantic gap*. **Jaringan *Joint Representation***lah yang memberikan peningkatan kinerja luar biasa pada SAN-CS secara keseluruhan.

### D. Dampak Pengaturan Parameter (RQ4)
*   **Dimensi Representasi ($d$):** Kinerja terbaik dicapai pada $\mathbf{d=128}$ (MRR 0.908).
*   **Jumlah Lapisan *Self-Attention*:** Kinerja optimal dicapai dengan hanya **satu lapisan *Self-Attention*** (MRR 0.908), yang bertentangan dengan arsitektur Transformer yang kompleks. Hal ini menyiratkan bahwa untuk tugas pencarian kode, lapisan yang lebih sedikit sudah memadai jika disertai dengan *joint representation*.

## 5. Kesimpulan

Paper ini berhasil memperkenalkan **SAN-CS**, model pencarian kode pertama yang sepenuhnya memanfaatkan *Self-Attention Networks*. SAN-CS memecahkan *performance bottleneck* DeepCS dengan secara efektif menangkap informasi kontekstual global dan secara eksplisit membangun hubungan semantik antar-modal melalui Jaringan *Code-Description Attention*. Hasil eksperimen menunjukkan peningkatan efektivitas yang signifikan (MRR 0.908) dan peningkatan efisiensi yang dramatis (6 kali lebih cepat dalam pencarian) dibandingkan *state-of-the-art* sebelumnya.

::: info Dampak Praktis
SAN-CS menyediakan alat pencarian kode yang **sangat efektif dan efisien** bagi para pengembang. Dengan MRR yang tinggi dan waktu respons yang cepat, SAN-CS secara langsung **meningkatkan produktivitas perangkat lunak** dengan secara akurat merekomendasikan potongan kode yang sesuai di peringkat teratas, meminimalkan waktu yang dihabiskan pengembang untuk mencari.
:::