---
title: Review Paper - Penyematan Gabungan Fitur Semantik dan Statistik untuk Pencarian Kode
description: Rangkuman paper tentang Model S&S-JEM untuk Code Search Efektif melalui Joint Embedding Fitur Semantik dan Statistik (Applied Sciences, 2022).
head:
  - - meta
    - name: keywords
      content: code search, semantic features, statistical features, joint embedding, multi-modal, deep learning
---

# 062 - Joint Embedding of Semantic and Statistical Features for Effective Code Search
Tautan (DOI) [https://doi.org/10.3390/app12199738]

**Penulis:** **Kun Liu** ᵃ*, **Haining Wang** ᵇ, **Jianxun Liu** ᵃ, **Haize Hu** ᵃ, **Bo Liu** ᵃ

**Afiliasi:**
* ᵃ School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan 411100, China
* ᵇ Department of Computer Science, University of Delaware, Newark, DE 19716, USA

**Kronologi:** Received: 9 September 2022 • Accepted: 22 September 2022 • Available Online: 5 October 2022

<a href="https://www.scimagojr.com/journalsearch.php?q=21100829268&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21100829268" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Applied Sciences 12, 19 (2022)<br>• **Topik:** Meningkatkan efektivitas *code search* dengan mengintegrasikan fitur **Semantik** (diambil oleh *encoder* neural) dan fitur **Statistik** (diambil oleh *Bag of Words*) ke dalam ruang *embedding* gabungan (*joint embedding space*).<br><br>**Masalah & Solusi:**<br>• **Masalah:** Model *deep learning* untuk *code search* (misalnya, DeepCS, CNN-CS) umumnya mengabaikan **fitur statistik** kode yang berharga (misalnya, frekuensi token, TF-IDF). Mengintegrasikan fitur statistik dan semantik sangat menantang karena perbedaan domain dan dimensi fitur yang signifikan, sehingga menyebabkan model seringkali hanya mengandalkan fitur semantik saja, menghasilkan akurasi yang suboptimal.<br>• **Solusi:** Mengusulkan **S\&S-JEM** (*Semantic and Statistical Feature Joint Embedding Model*), sebuah kerangka kerja yang: (1) Menggunakan dua *encoder* berbeda (**Bi-LSTM** untuk fitur semantik dan **MLP** untuk fitur statistik) untuk pemrosesan paralel; (2) Mengembangkan **Strategi Fusi Fitur Heterogen** yang efektif untuk menggabungkan representasi dari kedua *encoder* ke dalam ruang *embedding* gabungan tunggal; dan (3) Menggunakan *Attention Mechanism* untuk menyoroti fitur yang paling signifikan.<br><br>**Contoh Penerapan:**<br>• Model diuji pada tugas *code retrieval* menggunakan *dataset* besar **DeepCS** (Java) dan *dataset* **Hu et al.** (Java).<br><br>**Metodologi:**<br>• **Fitur Statistik:** Menggunakan metode **Bag of Words (BOW)** dan **TF-IDF** pada token kode/kueri. Fitur ini dienkode oleh **MLP** (Multi-Layer Perceptron).<br>• **Fitur Semantik:** Menggunakan fitur *multi-field* kode (Nama Metode, API, Tokens) dan Deskripsi. Fitur ini dienkode oleh **Bi-LSTM**.<br>• **Fusion Strategy:** Menggunakan *fusion layer* (lapisan terhubung penuh/FC) untuk menggabungkan vektor fitur semantik dan statistik: $V_{Final} = \tanh(W_{fusion}[V_{Semantic} \oplus V_{Statistical}])$.<br>• **Attention:** Menggunakan *Self-Attention* untuk pembobotan kata-kata kunci dalam setiap urutan sebelum *fusion*.<br>• **Loss Function:** Menggunakan *Margin Loss* (Triplet Loss) untuk mengoptimalkan pemetaan ke ruang *joint embedding*.<br><br>**Temuan Kunci:**<br>1. **Kinerja SOTA:** S\&S-JEM mengungguli *baseline* SOTA (DeepCS, UNIF, TabCS) di semua metrik. Peningkatan MRR rata-rata $\mathbf{10.2\%}$ dibandingkan DeepCS dan $\mathbf{2.8\%}$ dibandingkan TabCS.<br>2. **Kontribusi Statistik:** Integrasi fitur statistik meningkatkan akurasi secara signifikan (MRR naik hingga $\mathbf{0.038}$ poin), membuktikan bahwa fitur statistik memberikan informasi pelengkap yang kuat yang tidak dapat ditangkap oleh *encoder* neural.<br>3. **Efektivitas Fusi:** Strategi fusi fitur heterogen (menggabungkan output Bi-LSTM dan MLP) terbukti berhasil dalam menciptakan ruang *embedding* yang koheren, mengatasi tantangan perbedaan domain dan dimensi.<br><br>**Kontribusi Utama:**<br>• Mengusulkan **S\&S-JEM**, model *code search* pertama yang secara eksplisit mengintegrasikan fitur Semantik (Bi-LSTM) dan Statistik (MLP/BOW) ke dalam satu ruang *joint embedding*.<br>• Membuktikan bahwa fitur statistik (TF-IDF/BOW) memberikan sinyal pelengkap yang krusial untuk meningkatkan kemampuan pemadanan semantik model DL.<br><br>**Dampak:**<br>• **Akurasi Peringkat:** Model ini memberikan peningkatan signifikan dalam akurasi pemeringkatan *code search*, yang membantu pengembang menemukan kode yang lebih relevan dengan cepat. Model ini juga menetapkan metodologi untuk menggabungkan fitur heterogen dalam sistem *code search*. |

## 1. Pendahuluan & Masalah

*Code search* (pencarian kode sumber) adalah salah satu tugas yang paling sering dilakukan oleh pengembang, namun tantangan utamanya adalah mengatasi **kesenjangan semantik** (*semantic gap*) antara kueri bahasa alami (NL) dan kode sumber (PL). Metode *Deep Learning* (DL) saat ini (misalnya, DeepCS, UNIF) berupaya menjembatani kesenjangan ini dengan memetakan kedua modalitas ke ruang vektor bersama.

Namun, model *deep learning* yang ada memiliki kelemahan serius:

1.  **Mengabaikan Fitur Statistik:** Sebagian besar model DL berfokus secara eksklusif pada fitur semantik yang diekstrak oleh *sequence encoders* (LSTM/RNN), mengabaikan **fitur statistik** yang kaya (misalnya, frekuensi token, TF-IDF). Fitur statistik ini terbukti efektif dalam metode *Information Retrieval* (IR) tradisional dan dapat memberikan informasi pelengkap.
2.  **Tantangan Fusi Heterogen:** Mengintegrasikan fitur **Semantik** (kontekstual) dan **Statistik** (frekuensi/global) ke dalam satu ruang vektor adalah tugas yang menantang karena perbedaan mendasar dalam sifat data dan dimensi fitur yang diekstraksi.

::: tip Solusi yang Diusulkan
Kami mengusulkan **S\&S-JEM** (*Semantic and Statistical Feature Joint Embedding Model*), sebuah kerangka kerja hibrida. Model ini secara eksplisit mengintegrasikan fitur **Semantik** (diproses oleh Bi-LSTM) dan fitur **Statistik** (diproses oleh MLP) ke dalam ruang *joint embedding* tunggal, memastikan kedua jenis informasi ini saling melengkapi untuk akurasi *code search* yang lebih tinggi.
:::

## 2. Metodologi

S\&S-JEM adalah arsitektur *dual encoder* yang memproses fitur semantik dan statistik secara paralel, kemudian menggabungkannya sebelum perhitungan *loss*.

### A. Feature Extraction (Paralel Encoding)

1.  **Fitur Statistik:**
    * Menggunakan representasi **Bag of Words (BOW)** dan **TF-IDF** untuk kode dan kueri.
    * Fitur-fitur ini, yang biasanya berskala besar dan jarang (*sparse*), di-*embed* dan diolah oleh **Multi-Layer Perceptron (MLP)** menjadi vektor fitur statistik dimensi tetap ($V_{Statistical}$).
2.  **Fitur Semantik:**
    * Menggunakan fitur *multi-field* kode (Method Name, API Sequence, Tokens) dan Deskripsi.
    * Fitur-fitur ini diolah oleh **Bi-LSTM** untuk menangkap konteks sekuensial dua arah, diikuti oleh **Attention Mechanism** untuk memberikan bobot adaptif pada kata-kata kunci, menghasilkan vektor fitur semantik ($V_{Semantic}$).

### B. Heterogeneous Feature Fusion

Representasi dari kedua domain (semantik dan statistik) digabungkan di Lapisan *Fusion* untuk menghasilkan vektor kode dan kueri akhir ($V_{Final}$).

1.  **Concatenation:** Vektor fitur semantik dan statistik digabungkan secara horizontal:
    $$V_{\text{fusion}} = [V_{\text{Semantic}} \oplus V_{\text{Statistical}}]$$
2.  **Lapisan Terhubung Penuh (FC Layer):** Vektor gabungan tersebut dilewatkan melalui lapisan FC dan fungsi aktivasi $\tanh$ untuk menghasilkan vektor $\mathbf{V_{Final}}$ yang padat (*dense*) dalam ruang *joint embedding*:
    $$V_{\text{Final}} = \tanh(W_{\text{fusion}} V_{\text{fusion}})$$

### C. Optimization Objective

Model dilatih menggunakan **Margin Loss** (Triplet Loss) untuk mengoptimalkan pemetaan ke ruang *joint embedding*.
$$\mathcal{L}(\theta)=\sum_{(C,D^{+},D^{-})}max(0, \xi - \cos(C, D^{+}) + \cos(C, D^{-}))$$
Di mana $\xi$ adalah *margin* dan $D^{+}$/ $D^{-}$ adalah sampel positif/negatif. *Loss* memastikan vektor pasangan positif menjadi lebih dekat daripada vektor pasangan negatif.

## 3. Detail Pengujian

### Dataset
Model diuji pada dua dataset Java besar:
* **DeepCS Dataset:** $\approx 4.5$ juta pasangan kode-deskripsi.
* **Hu et al.'s Dataset:** $\approx 480$ ribu pasangan kode-deskripsi.

### Baseline
Model dibandingkan dengan SOTA: **DeepCS, UNIF, TabCS** (sebagai model *attention* canggih).

### Metrik Evaluasi
Metrik akurasi utama adalah **Mean Reciprocal Rank (MRR)**.
$$MRR=\frac{1}{|Q|}\sum_{j=1}^{|Q|}\frac{1}{Rank_{j}}$$
Di mana $Rank_j$ adalah posisi peringkat *snippet* kode yang benar pertama.

## 4. Hasil Eksperimen

### Efektivitas S&S-JEM (MRR)

| Model | MRR (DeepCS Dataset) | MRR (Hu et al.'s Dataset) |
| :--- | :--- | :--- |
| DeepCS | 0.5891 | 0.6033 |
| UNIF | 0.6033 | 0.6125 |
| TabCS | 0.6698 | 0.6871 |
| **S&S-JEM** | **0.6883** ($\mathbf{\uparrow 2.8\%}$ vs TabCS) | **0.7100** ($\mathbf{\uparrow 3.3\%}$ vs TabCS) |

**Analisis:** S\&S-JEM mencapai kinerja *state-of-the-art*, mengungguli *baseline* TabCS sebesar $\mathbf{2.8\%}$ hingga $\mathbf{3.3\%}$ MRR. Peningkatan ini membuktikan bahwa integrasi fitur statistik secara eksplisit memberikan informasi pelengkap yang krusial untuk pemadanan semantik, yang tidak dapat ditangkap oleh *encoder* neural secara mandiri.

### Studi Ablasi (Kontribusi Fitur)
* Menghilangkan fitur **Statistik** secara signifikan mengurangi MRR, kembali mendekati *baseline* yang lebih rendah. Ini memvalidasi hipotesis bahwa fitur Statistik memberikan sinyal *orthogonal* (pelengkap) yang kuat terhadap fitur Semantik.

## 5. Kesimpulan

S\&S-JEM berhasil mengatasi masalah pengabaian fitur statistik dalam *code search* berbasis *deep learning*. Dengan mengintegrasikan fitur **Semantik** (Bi-LSTM) dan **Statistik** (MLP/BOW) ke dalam ruang *joint embedding* yang koheren, model ini menghasilkan representasi yang lebih komprehensif, yang berujung pada peningkatan akurasi *code search* secara signifikan.

::: info Dampak Praktis
S\&S-JEM menawarkan kerangka kerja yang efektif untuk **meningkatkan model *code search* yang sudah ada** (seperti DeepCS dan TabCS) dengan biaya komputasi yang relatif rendah. Model ini menekankan pentingnya **data heterogen** dan dapat diadopsi di industri untuk meningkatkan presisi pemeringkatan hasil pencarian kode.
:::