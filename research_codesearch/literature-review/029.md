---
title: Review Paper - RAPID Adaptasi Domain Zero-Shot untuk Pencarian Kode
description: Rangkuman paper tentang kerangka kerja adaptasi domain zero-shot untuk pencarian kode menggunakan model pre-trained (ACM Transactions on Software Engineering and Methodology, 2024).
head:
  - - meta
    - name: keywords
      content: Code search, zero-shot learning, domain adaption, pre-trained models, CodeBERT, CodeT5, hard negative sampling
---

# 029 - RAPID: Zero-Shot Domain Adaptation for Code Search with Pre-Trained Models
Tautan (DOI) [10.1145/3641542](https://doi.org/10.1145/3641542)

**Penulis:** **Guodong Fan** ¹, **Shizhan Chen** ¹, **Cuiyun Gao** ²*, **Jianmao Xiao** ³*, **Tao Zhang** ⁴, **Zhiyong Feng** ¹

**Afiliasi:**
* ¹ College of Intelligence and Computing, Tianjin University, Tianjin, China
* ² Harbin Institute of Technology, Shenzhen, China
* ³ School of Software, Jiangxi Normal University, Nanchang, China
* ⁴ Macau University of Science and Technology, Macau, China

**Kronologi:** Received: 25 May 2023 • Revised: 29 December 2023 • Accepted: 10 January 2024 • Available Online: June 2024

<a href="https://www.scimagojr.com/journalsearch.php?q=18121&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=18121" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** ACM Trans. Softw. Eng. Methodol. 33, 5, Article 128 (June 2024)<br>• **Topik:** Mengatasi penurunan performa pencarian kode dalam skenario *cross-domain* (*zero-shot*) akibat kelangkaan data berlabel, menggunakan model *pre-trained* untuk sintesis data.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Pendekatan *code search* saat ini sangat bergantung pada data berlabel untuk *fine-tuning*. Dalam skenario *cross-domain* (misalnya, bahasa atau proyek spesifik seperti SQL atau Solidity) yang mengalami **kelangkaan data (*data scarcity*)** atau tidak memiliki data berlabel (*zero-shot*), performa model (*retriever*) menurun drastis karena ketidakmampuan menangkap semantik spesifik domain.<br>• **Solusi:** Mengusulkan kerangka kerja **RAPID** (*Zero-shot domAin adaPtion with pre-traIned moDels*) yang memanfaatkan model generatif (*CodeT5*) untuk menghasilkan label semu (*pseudo-labels*) kueri dari kode target. Data sintetis ini kemudian disampel dengan strategi **Mixture Sampling** untuk mendapatkan *hard negative samples* sebelum melatih model *retriever* (*CodeBERT/UniXcoder*).<br><br>**Contoh Penerapan:**<br>• Diuji pada tiga dataset spesifik domain: **SQL, Solidity, dan CoSQA**, serta pada tiga proyek GitHub dunia nyata (*real-world zero-shot*) untuk memvalidasi efektivitasnya dalam skenario *cross-domain* dan *cross-project*.<br><br>**Metodologi:**<br>• **Synthetic Query Generation:** Menggunakan *CodeT5* yang sudah dilatih sebelumnya untuk menghasilkan *pseudo-labels* kueri untuk kode target. Digunakan **Nucleus Sampling** dan *fine-tuning* *few-shot* untuk meningkatkan kualitas dan keragaman kueri yang dihasilkan.<br>• **Mixture Sampling Strategy (Hard Negative Sampling):** Diusulkan strategi *sampling* yang mempertimbangkan **relevansi dan keragaman** untuk memilih *hard negative samples*. Strategi ini mencampur *negatives* dari berbagai sumber (Random, BM25, Neural) dan memfilter *Code Clone Samples* (CCSs) menggunakan gabungan metrik *Jaccard similarity* dan *Levenshtein distance* ($Sim_{C_{i},C_{j}}=(Sim_{J}(C_{i},C_{j})+Sim_{E}(C_{i},C_{j}))/2$).<br>• **Model Training (Domain Adaptation):** Model *retriever* (*bi-encoder*) dilatih menggunakan *softmax cross-entropy loss* dengan *in-batch negative* dan *hard negative samples* yang telah disampel.<br><br>**Temuan Kunci:**<br>1. **Kinerja Zero-Shot Superior:** RAPID mengungguli *baseline* zero-shot seperti CoCoSoDa dan UniXcoder rata-rata $\mathbf{15.7\%}$ dan $\mathbf{10\%}$ dalam metrik MRR. Untuk dataset CoSQA, RAPID (dengan CodeBERT) bahkan melampaui *baseline* yang dilatih dengan *Full Data*.<br>2. **Peningkatan Full Data:** Ketika dilatih dengan *full data*, penambahan *hard negative* RAPID menghasilkan peningkatan rata-rata $\mathbf{7.5\%}$ pada metrik MRR (menggunakan CodeBERT).<br>3. **Real-World Efficacy:** Dalam skenario *real-world zero-shot* (3 proyek GitHub), RAPID menunjukkan peningkatan MRR rata-rata $\mathbf{18\%}$ dibandingkan model performa terbaik, dikonfirmasi oleh evaluasi manusia (POU dan POS yang lebih tinggi).<br>4. **Efek Pseudo-Label:** *Fine-tuning* *CodeT5* menggunakan *few-shot* ($100 \text{-shot}$) untuk menghasilkan *pseudo-labels* memberikan hasil yang sebanding dengan *baseline supervised* CodeBERT.<br><br>**Kontribusi Utama:**<br>• Kerangka kerja **RAPID** novel untuk *zero-shot domain adaptation* dalam *code search* menggunakan *pseudo-labels* yang dihasilkan oleh *CodeT5*.<br>• Strategi *mixture sampling* untuk memperoleh *hard negative samples* yang tangguh, mempertimbangkan **relevansi, keragaman, dan penghapusan *code clone***.<br>• Demonstrasi bahwa performa model yang lebih lemah (*CodeBERT*) mendapat peningkatan substansial dari *hard negatives*, sementara model yang lebih kuat (*UniXcoder*) lebih diuntungkan dari *pseudo-labels*.<br><br>**Dampak:**<br>• Memungkinkan implementasi *code search* yang efektif di domain atau proyek baru yang tidak memiliki anotasi data (situasi umum di dunia nyata), mengurangi ketergantungan pada pelabelan manual yang mahal dan sulit, serta meningkatkan kemampuan generalisasi model *pre-trained*. |

## 1. Pendahuluan & Masalah

Pencarian kode (*Code search*), yaitu proses mengidentifikasi *snippet* kode paling relevan untuk kueri bahasa alami yang diberikan, merupakan tugas yang sangat penting dalam pemeliharaan perangkat lunak. Model bahasa *pre-trained* (PLM) seperti CodeBERT dan UniXcoder telah menjadi tulang punggung untuk tugas ini, memfasilitasi transfer model.

Namun, mengadaptasi model ke domain atau proyek baru seringkali menghadapi masalah serius: **kelangkaan data berlabel**. Banyak proyek perangkat lunak memiliki dokumentasi yang tidak memadai, usang, atau ambigu, membuat *fine-tuning* model pada domain target menjadi tidak efektif. Dalam skenario *zero-shot* (tidak ada data berlabel domain target), kinerja model dapat menurun drastis, hingga sekitar $45\%$ (seperti yang ditunjukkan oleh CodeBERT pada data SQL).

Untuk mengatasi masalah kelangkaan data, peneliti sering menggunakan data sintetis. Meskipun model generatif seperti CodeT5 dapat menghasilkan *pseudo-labels* dari kode sumber, memasukkan label sintetis ini secara langsung dalam pelatihan dapat menyebabkan kinerja yang kurang optimal karena adanya *noise* (label berkualitas rendah) dalam data sintetis.

::: tip Solusi yang Diusulkan
RAPID (*Zero-shot domAin adaPtion with pre-traIned moDels*) adalah kerangka kerja yang memanfaatkan model generatif CodeT5 untuk menghasilkan *pseudo-labels* kueri dari kode target. Kerangka ini kemudian melatih model *retriever* dengan data sintetis yang disampel, menggunakan **Strategi Mixture Sampling** yang inovatif untuk secara efektif memperoleh *hard negative samples* yang beragam dan relevan, sehingga memitigasi pengaruh *noise* data.
:::

## 2. Metodologi

Arsitektur RAPID terdiri dari tiga komponen utama: *Synthetic Query Generation*, *Sampling Strategy*, dan *Training (Domain Adaptation)*.

### A. Synthetic Query Generation

Tujuan dari komponen ini adalah untuk menghasilkan *pseudo-labels* kueri yang relevan dan beragam untuk kode target (domain atau proyek baru).

1.  **Model Generatif:** Digunakan **CodeT5** (varian T5 untuk tugas kode) untuk memodelkan tugas sebagai *Text-to-Text*, di mana kode sumber ($c$) digunakan untuk menghasilkan kueri ($q$).
    $$ w_{1},w_{2},...,w_{n}=f_{\theta}(\text{Summarize}:c_{1},c_{2},...,c_{m},[\text{EOS}]) $$
2.  **Nucleus Sampling:** Untuk meningkatkan **keragaman** kueri yang dihasilkan, diterapkan **Nucleus Sampling**. Metode ini memilih kata dari subset kosa kata yang probabilitas kumulatifnya melebihi ambang batas $p$, memungkinkan ukuran kandidat kata yang dinamis.
3.  **Fine-Tuning:** Kualitas kueri ditingkatkan melalui *fine-tuning* *CodeT5* dengan sampel *few-shot* (misalnya $100\text{-shot}$) dari data domain sumber, meminimalkan *negative log-likelihood* dari *target query tokens* ($q$) untuk input kode ($c$).

### B. Sampling Strategy

Komponen ini dirancang untuk memilih *hard negative samples* yang paling sulit dibedakan dari *positive sample* (pasangan kode dan kueri yang dihasilkan).

1.  **Mixture Sampling:** Strategi ini mencampur berbagai jenis *hard negative* dari *pool* untuk memastikan **kekerasan (*hardness*) dan keragaman** sampel:
    *   **Random Sampling:** Negatif yang dipilih secara acak (distribusi uniform).
    *   **BM25 Negatives:** Negatif yang dipilih dari top-$k$ hasil BM25 (mirip di level karakter).
    *   **Neural Negatives:** Negatif yang dipilih dari model *neural retrieval* yang sudah ada (MD, MM, atau *NeuralSelf*), yang menangkap hubungan semantik yang lebih kompleks.
2.  **Mengidentifikasi *Code Clone Samples* (CCSs):** Untuk mencegah kode klon (duplikat) secara keliru diberi label sebagai *negative sample*, yang dapat mengurangi akurasi, kode klon diidentifikasi dan **dihapus** dari *negative samples* menggunakan gabungan *Jaccard similarity* dan *Edit Distance* (*Levenshtein distance*).
    $$ \text{Sim}_{C_{i},C_{j}}=(\text{Sim}_{J}(C_{i},C_{j})+\text{Sim}_{E}(C_{i},C_{j}))/2 $$
    Jika skor kesamaan melebihi ambang batas (misalnya $0.95$), sampel tersebut diklasifikasikan sebagai kode klon dan diabaikan.

### C. Model Training

Model *retriever* (*bi-encoder* seperti CodeBERT/UniXcoder) dilatih menggunakan *in-batch negative method* dan *softmax cross-entropy loss*. Tujuannya adalah meminimalkan *negative log-likelihood* untuk setiap instansi $\{q,c^{+},c_{1}^{-},...,c_{k}^{-}\}$ (satu kueri, satu kode relevan, $k$ kode tidak relevan).

$$ \mathcal{L}(q,c)=-\frac{1}{B}\sum_{i=1}^{B}\log\frac{e^{\phi(q_{i},c_{i})}}{\sum_{j=1}^{B}e^{\phi(q_{i},c_{j})}+\sum_{j=1}^{N}e^{\phi(q_{i},c_{j}^{-})}} $$
Di mana $\phi(q,c)$ adalah fungsi *dot-product similarity* antara *embedding* kueri $q$ dan *embedding* kode $c$. Kerugian timbal balik $\mathcal{L}(c,q)$ juga ditambahkan (dari kode ke kueri) untuk melatih model membedakan antara pasangan relevan dan tidak relevan di kedua arah.

## 3. Detail Pengujian

### Dataset
Digunakan tiga dataset spesifik domain yang tidak termasuk dalam *CodeSearchNet*:
*   **Solidity:** 56,976 (Train), 4,096 (Valid), 1,000 (Test).
*   **SQL:** 14,000 (Train), 2,068 (Valid), 1,000 (Test).
*   **CoSQA:** 20,000 (Train), 602 (Valid), 901 (Test).

Juga digunakan dataset **AdvTest** untuk evaluasi *real-world zero-shot* (*cross-project*).

### Baseline
*   **Retrieval Baselines:** BERT, DistilBERT, CodeBERT, GraphCodeBERT, UniXcoder, CoCoSoDa.
*   **Domain Adaptation Baselines (Zero-shot):** CDCS, MLM, TSDAE, GenQ, GenQ CL (Contrastive Loss).

### Metrik Evaluasi

*   **Top-k Accuracy ($Acc@k$):** Proporsi kueri di mana jawaban yang benar muncul di antara top-$k$ hasil.
    $$ \text{Acc}@k = \frac{1}{|Q|}\sum_{q=1}^{|Q|}\mathbb{I}(\text{retrieval}_{q,k} > 0) $$
*   **Mean Reciprocal Rank (MRR):** Mengukur kualitas hasil pencarian dengan mengevaluasi kebalikan peringkat hasil yang benar pertama ($rank_q$).
    $$ \text{MRR} = \frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{1}{\text{rank}_{q}} $$
*   **Evaluasi Manusia (*Human Evaluation* - RQ5):**
    *   **POU** (*Percentage of Useful Results*): Rasio hasil yang bermanfaat.
    *   **POS** (*Percentage of User Satisfaction*): Kepuasan pengguna, dinilai menggunakan skala *Likert* 5-poin.
    *   **FRank** (*The First Rank*): Peringkat hasil yang benar pertama.

## 4. Hasil Eksperimen

### RQ1. Perbandingan dengan Baseline (Zero-Shot)

Hasil utama menunjukkan efektivitas RAPID dalam skenario *zero-shot* (Tabel 4, RAPID dengan *Mixture Sampling*).

| Model Dasar | Domain | MRR Baseline | MRR +RAPID | Peningkatan MRR |
| :--- | :--- | :--- | :--- | :--- |
| **CodeBERT** | SQL | 0.037 | **0.753** | 71.6 |
| **CoCoSoDa** | SQL | 0.559 | **0.785** | 40.4% |
| **UniXcoder** | Solidity | 0.690 | **0.779** | 12.9% |
| **UniXcoder** | CoSQA | 0.807 | **0.897** | 11.2% |

*   **Zero-Shot Efficacy:** RAPID pada CodeBERT mencapai $\text{MRR}=0.753$ untuk SQL, yang sebanding dengan CodeBERT yang dilatih *Full Data* ($\text{MRR}=0.812$). Untuk CoSQA, RAPID pada CodeBERT mencapai $\text{MRR}=0.861$, melampaui CodeBERT *Full Data* ($\text{MRR}=0.824$).
*   **Full Data Improvement:** Ketika dilatih dengan *full data*, penambahan *hard negative* RAPID menghasilkan peningkatan $\mathbf{7.5\%}$ MRR rata-rata untuk CodeBERT.
*   **Model Performance:** Model yang lebih lemah (seperti BERT dan CodeBERT) menunjukkan peningkatan substansial dengan *hard negative samples*, sedangkan model yang lebih kuat (UniXcoder) terutama mendapat manfaat dari *pseudo-labels*.

### RQ2. Dampak Model Generatif

Kualitas *pseudo-labels* sangat memengaruhi performa *retrieval*.
*   **Model Generatif Terbaik:** CodeT5 umumnya menghasilkan kueri kualitas terbaik (BLEU/ROUGE tertinggi) dan memberikan performa *retrieval* MRR terbaik.
*   **Few-Shot Fine-Tuning:** *Fine-tuning* CodeT5 dengan **$100 \text{-shot}$** data berlabel dapat menghasilkan *pseudo-labels* yang memberikan kinerja *retrieval* yang sebanding dengan *baseline supervised* CodeBERT *Zero-shot*. $1000 \text{-shot}$ dapat melampaui kinerja *Full Data*.
*   **Semantic Closeness:** Kueri yang dihasilkan, meskipun skor BLEU-nya relatif rendah, mempertahankan **kesamaan semantik** yang signifikan dengan kode, dikonfirmasi oleh *similarity score* ($\approx 0.6-0.8$ pada model UniXcoder/CoCoSoDa) dan Recall@10 ($>0.8$).

### RQ3. Dampak Hard Negatives

*   **Efektivitas *Mixture Sampling***: Strategi *Mixture Negative* menunjukkan performa terbaik di semua dataset, mengungguli setiap strategi tunggal (Random, BM25, MD, MM, NS). Ini memvalidasi bahwa kombinasi sampel yang keras dan beragam meningkatkan kemampuan diskriminatif model.
*   **Korelasi Kinerja:** Kinerja model *hard negative* berkorelasi positif dengan kinerja *retrieval* akhir. Model *neural hard negative* (MD, MM, NS) umumnya lebih unggul daripada BM25 dan Random.

### RQ5. Evaluasi Manusia (Real-World Zero-Shot)

Evaluasi pada tiga proyek GitHub nyata (*cross-project zero-shot*) mengonfirmasi efektivitas RAPID.

| Proyek | MRR (RP) | MRR (CC) | MRR (UX) | POU (RP) | POS (RP) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| cloud9ers/gurumate | **0.631** | 0.544 | 0.456 | 4.24 | 3.90 |
| apache/airflow | **0.733** | 0.622 | 0.548 | 4.47 | 4.09 |
| Clinical-Genomics/scout | **0.543** | 0.442 | 0.363 | 3.55 | 3.24 |
| **Rata-rata** | **↑ 18%** vs. Terbaik | - | - | **↑ 6.3%** vs. Terbaik | **↑ 10.5%** vs. Terbaik |

RAPID meningkatkan MRR rata-rata $\mathbf{18\%}$ di semua proyek dibandingkan model berkinerja terbaik. Skor POU dan POS yang lebih tinggi juga menunjukkan bahwa pengembang menemukan hasil RAPID lebih bermanfaat dan memuaskan.

## 5. Kesimpulan

RAPID berhasil mengatasi tantangan utama dalam *code search*, yaitu penurunan kinerja dalam skenario *zero-shot cross-domain* akibat kelangkaan data berlabel. Dengan menggabungkan generasi *pseudo-labels* berbasis *CodeT5* dan strategi *Mixture Sampling* untuk *hard negative* yang tangguh, RAPID mencapai kinerja *code search* yang sebanding atau bahkan melampaui *baseline supervised* CodeBERT. Penemuan ini menunjukkan bahwa data sintetis dapat dimanfaatkan secara efektif, bahkan di domain di mana anotasi data sangat terbatas.

::: info Dampak Praktis
RAPID menawarkan solusi praktis untuk mengadaptasi alat *code search* pada proyek atau bahasa pemrograman baru yang kekurangan dokumentasi atau anotasi data, suatu kondisi yang lazim terjadi di industri. Ini secara signifikan mengurangi biaya pelabelan manual dan memperluas generalisasi model bahasa *pre-trained* ke skenario *real-world zero-shot* (*cross-project*), sehingga meningkatkan efisiensi pemeliharaan perangkat lunak.
:::