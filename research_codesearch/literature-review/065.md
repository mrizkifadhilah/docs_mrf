---
title: Review Paper - Pencarian Kode Fusi Embedding Graf dan Mekanisme Perhatian
description: Rangkuman paper tentang GraphCS, algoritma pencarian kode yang menggabungkan fitur struktural dan perhatian (Journal of Frontiers of Computer Science and Technology, 2022).
head:
  - - meta
    - name: keywords
      content: code search, graph embedding, attention mechanism, GraphCS, PDG, LSTM, Graph2Vec
---

# 065 - 融合图嵌入和注意力机制的代码搜索 (Code Search Combining Graph Embedding and Attention Mechanism)
Tautan (DOI) [https://doi.org/10.3778/j.issn.1673-9418.2010087]

**Penulis:** **黄思远 (HUANG Siyuan)** $^{1}$, **赵宇海 (ZHAO Yuhai)** $^{1*}$, **梁铭 (LIANG Yiming)** $^{1}$

**Afiliasi:**
* $^{1}$ 东北大学 计算机科学与工程学院, 沈阳 110169 (School of Computer Science and Engineering, Northeastern University, Shenyang 110169, China)

**Kronologi:** Received: 2020-10-28 • Revised: 2021-01-18 • Accepted: 2021-01-18 • Available Online: 2022/16(04)

<a href="https://www.scimagojr.com/journalsearch.php?q=21101088821&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21101088821" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** 计算机科学与探索 (Journal of Frontiers of Computer Science and Technology) 16, 4 (2022)<br>• **Topik:** Meningkatkan tugas *source code retrieval* (pencarian kode sumber) dari kueri Bahasa Alami (NL) dengan menggabungkan representasi tekstual dan struktural kode.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Mayoritas algoritma *code search* hanya mempertimbangkan informasi urutan tekstual (*text sequence*) dari cuplikan kode, mengabaikan informasi **struktur logis** kode. Hal ini mengakibatkan kurangnya pemahaman yang memadai terhadap semantik dan sintaksis bahasa pemrograman.<br>• **Solusi:** Mengusulkan algoritma **GraphCS** (*Code Search combining Graph Embedding and Attention Mechanism*) yang: (1) Mengekstrak **fitur tekstual** menggunakan **Bi-LSTM** dan **MLP**; (2) Mengekstrak **fitur struktural** dari *Program Dependency Graph* (PDG) menggunakan **Graph2Vec**; (3) Menggunakan **Mekanisme Perhatian** (*Attention Mechanism*) untuk menggabungkan ketiga fitur (nama, token, graf PDG) secara adaptif untuk mendapatkan representasi kode yang komprehensif.<br><br>**Contoh Penerapan:**<br>• Diuji pada *dataset* besar **Java** dengan $2.141.921$ pasangan metode/anotasi setelah pembersihan, dan dibandingkan dengan algoritma SOTA **CODEnn**.<br>• GraphCS mencapai peningkatan Precision@k hingga $\mathbf{56.5\%}$ dan MRR $\mathbf{0.39}$ (naik $25.8\%$ dari CODEnn).<br><br>**Metodologi:**<br>• **Representasi Kode:** Diekstrak dari Nama Metode (setelah *camel case splitting*), Token (setelah pembersihan *stop word* dan *keyword*), dan PDG (diekstraksi dari *Control Flow Graph* + relasi data/kontrol dependensi).<br>• **Embedding:** Nama Metode dan Anotasi NL di-*embed* menggunakan **Bi-LSTM** dan *Max Pooling*. Token di-*embed* menggunakan **MLP** dan *Max Pooling*. PDG di-*embed* menggunakan **WL (*Weisfeiler-Lehman*) Relabeling Algorithm** untuk ekstraksi *subgraph* dan **Graph2Vec (*Skip-Gram*)** untuk representasi vektor graf.<br>• **Fusi Fitur:** Menggunakan *Attention Mechanism* adaptif untuk menimbang dan menggabungkan vektor fitur (nama, token, PDG) menjadi satu vektor kode akhir (*code*) dan satu vektor kueri NL akhir (*desc*).<br>• **Pelatihan:** Menggunakan fungsi *Ranking Loss* untuk memetakan fitur kode dan NL (data heterogen) ke ruang vektor bersama di mana sampel semantik serupa memiliki jarak kosinus terdekat.<br><br>**Temuan Kunci:**<br>1. **Kinerja Unggul:** GraphCS mengungguli CODEnn, RNN, dan NeuralBOW pada semua metrik (MRR, Success Rate@k, Precision@k). Peningkatan terbesar terjadi pada Precision@k ($40.0\%$ hingga $56.5\%$).<br>2. **Nilai Struktur Logis:** Hasil menunjukkan bahwa penggabungan informasi struktur logis PDG secara signifikan meningkatkan akurasi retrieval, membuktikan bahwa informasi tekstual saja tidak cukup.<br>3. **Fusi yang Lebih Baik:** Mekanisme perhatian berhasil memberikan bobot yang lebih baik pada fitur-fitur, yang menghasilkan rasio keterkaitan Nama Metode/Semantik yang lebih tinggi ($0.649$ vs $0.545$ CODEnn).<br><br>**Kontribusi Utama:**<br>• Mengusulkan GraphCS, algoritma yang secara eksplisit menggabungkan **Graph Embedding** dari PDG dan **Attention Mechanism** untuk *code search*.<br>• Mendefinisikan proses ekstraksi dan fusi fitur (Nama Metode, Token, PDG) menggunakan bobot perhatian adaptif.<br><br>**Dampak:**<br>• Menyediakan alat *code search* yang lebih efisien dan akurat bagi pengembang, yang mampu memahami tidak hanya apa yang dikatakan kode, tetapi juga bagaimana kode tersebut secara logis terstruktur, sehingga dapat mempercepat pengembangan perangkat lunak secara signifikan. |

## 1. Pendahuluan & Masalah

Tugas *Source Code Retrieval* (pencarian kode sumber) adalah proses menemukan cuplikan kode yang relevan dari *code base* menggunakan Bahasa Alami (NL) sebagai kueri. Penelitian menunjukkan bahwa pengembang menghabiskan sekitar seperlima waktu mereka untuk mencari solusi secara daring, menyoroti pentingnya alat *code search* yang efisien.

Namun, metode *code search* yang ada menghadapi keterbatasan serius:
*   **Metode Berbasis *Information Retrieval* (IR):** Terlalu bergantung pada pencocokan kata kunci dan gagal memahami semantik mendalam dari kueri NL.
*   **Metode Berbasis *Deep Learning* (DL) SOTA (seperti CODEnn):** Meskipun mampu mempelajari semantik NL, sebagian besar hanya mempertimbangkan informasi **urutan tekstual murni** dari kode sumber, mengabaikan **struktur logis** dan sintaksis yang kaya dari bahasa pemrograman.

Kegagalan untuk memanfaatkan informasi struktural (seperti alur kontrol dan ketergantungan data) menghambat pemahaman program secara penuh dan membatasi akurasi *retrieval*.

::: tip Solusi yang Diusulkan
Untuk meningkatkan pemahaman bahasa pemrograman, kami mengusulkan **GraphCS** (*Code Search combining Graph Embedding and Attention Mechanism*), sebuah algoritma yang secara sistematis mengekstrak dan memfusi **fitur tekstual** dengan **fitur graf struktural** (*Program Dependency Graph*, PDG). **Mekanisme Perhatian** kemudian diintegrasikan untuk secara adaptif memberikan bobot yang sesuai pada setiap fitur, memastikan representasi kode yang paling komprehensif.
:::

## 2. Metodologi

GraphCS bertujuan untuk memetakan fitur kode (heterogen) dan fitur kueri NL ke dalam ruang vektor bersama di mana jarak yang dekat menunjukkan kesamaan semantik.

### A. Ekstraksi Fitur Data

Data diekstrak dari metode Java:
1.  **Nama Metode (*Method Name*):** Dipecah menggunakan aturan *camel case* (misalnya, `readXmlFiles` menjadi `read`, `xml`, `files`).
2.  **Token:** Semua token dalam badan metode dipecah, kemudian *stop word* umum dan *keyword* Java yang berulang dihapus.
3.  **Anotasi NL:** Baris pertama komentar JavaDoc diekstrak sebagai deskripsi NL.
4.  **Graf PDG (*Program Dependency Graph*):** Untuk menangkap struktur logis. PDG dibangun dari *Control Flow Graph* (CFG) dengan menambahkan relasi ketergantungan data dan ketergantungan kontrol antar-node.

### B. Generasi Embedding Kode Struktural (Graph2Vec)

Untuk mengekstrak representasi vektor dari PDG:
1.  **Ekstraksi *Subgraph* (WL Relabeling):** Algoritma **Weisfeiler-Lehman (WL) Relabeling** digunakan untuk memberikan label ulang pada setiap node di PDG. Algoritma ini secara iteratif mengagregasi label node tetangga untuk menghasilkan label baru, yang secara efektif menangkap pola struktur *subgraph* lokal hingga derajat $d$.
2.  **Graph2Vec:** Himpunan *subgraph* $\{subgraph_{n}^{0},subgraph_{n}^{1},\dots,subgraph_{n}^{d_{max}-1}\}$ dari setiap node $n$ diperlakukan sebagai informasi kontekstual dari graf PDG. Model **Skip-Gram** (diadopsi dari Doc2Vec) kemudian digunakan untuk mempelajari representasi vektor graf PDG (*pdg*), di mana setiap *subgraph* adalah "kata" dan graf PDG adalah "dokumen".

### C. Generasi Embedding Sekuensial (Bi-LSTM dan MLP)

1.  **Nama Metode dan Anotasi NL:** Karena urutan kata pada nama metode dan deskripsi NL penting, **Bi-directional LSTM (Bi-LSTM)** digunakan untuk mempelajari fitur tersembunyi (*hidden features*) dengan mempertimbangkan konteks maju dan mundur. Representasi akhir diperoleh melalui **Max Pooling** pada urutan status tersembunyi ($nm$ dan $desc$).
    $$\vec{h_{t}}=\overrightarrow{\text{LSTM}}(\vec{h_{t-1}},x_{t}), \quad \overline{h_{t}}=\overleftarrow{\text{LSTM}}(\overline{h_{t-1}},x_{ND-t+1})$$
    $$desc=\text{maxpooling}([\vec{h_{1}};\overline{h_{ND}}], [\vec{h_{2}};\overline{h_{ND-1}}], \dots, [\vec{h_{ND}};\overline{h_{1}}])$$
2.  **Token:** Karena urutan token tidak dianggap penting dalam ekstraksi fitur ini, **Multi-Layer Perceptron (MLP)** digunakan, diikuti oleh **Max Pooling** untuk menghasilkan vektor token akhir ($tk$).

### D. Fusi Fitur dan Mekanisme Perhatian

Fitur kode diekstraksi dari tiga perspektif: Nama Metode ($nm$), Token ($tk$), dan Graf PDG ($pdg$). **Mekanisme Perhatian** digunakan untuk secara dinamis memberikan bobot pada masing-masing fitur ini:

$$\alpha_{nm}=\frac{\exp(nm)}{\exp(nm)+\exp(tk)+\exp(pdg)}$$
$$\text{code}=\alpha_{nm} \times nm + \alpha_{tk} \times tk + \alpha_{pdg} \times pdg$$

Vektor kode akhir (*code*) dan vektor kueri NL akhir (*desc*) kemudian dipetakan ke ruang vektor yang sama. Kesamaan diukur menggunakan **Cosine Similarity**:

$$\cos(\text{code},\text{desc})=\frac{\text{code}^{\top}\text{desc}}{\|\text{code}\| \times \|\text{desc}\|}$$

Pelatihan dilakukan dengan meminimalkan **Ranking Loss** pada triple $\langle C, D^{+}, D^{-} \rangle$:

$$L(\theta)=\min \sum \max(0, \Delta - \cos(C,D^{+}) + \cos(C,D^{-}))$$

Di mana $\Delta$ adalah margin (ditetapkan ke $0.3986$), $D^{+}$ adalah deskripsi positif (benar), dan $D^{-}$ adalah deskripsi negatif (salah). *Ranking Loss* memastikan bahwa kesamaan $\cos(C,D^{+})$ lebih tinggi daripada $\cos(C,D^{-})$.

## 3. Detail Pengujian

### Metrik
*   **MRR (*Mean Reciprocal Rank*):** Mengukur rata-rata invers dari peringkat pertama hasil yang benar. Nilai yang lebih tinggi menunjukkan kinerja yang lebih baik.
$$MRR=\frac{1}{|Query|}\sum_{query}^{\text{Query}}\frac{1}{\text{Frank}_{query}}$$
*   **Success Rate@k:** Persentase kueri yang memiliki setidaknya satu hasil benar di peringkat $k$ teratas.
$$\text{Success Rate@}k=\frac{1}{|Query|}\sum_{query}^{\text{Query}}F(\text{Frank}_{query}\le k)$$
*   **Precision@k:** Persentase hasil yang relevan di peringkat $k$ teratas.
$$\text{Precision}@k=\frac{\text{count}(\text{relevant in top-}k)}{k}$$

### Parameter Utama
*   Dimensi Vektor Kata/LSTM: $512/256$.
*   Ukuran *Embedding* Graf: $128$.
*   Ukuran Vokabulari: $10.000$ (mencakup $>95\%$ korpus).
*   Panjang Maksimal: Nama Metode (6), NL (30), Token (50).

## 4. Hasil Eksperimen

GraphCS dibandingkan dengan CODEnn, RNN, dan NeuralBOW.

### A. Perbandingan Kinerja Akurasi (k=1/5/10)

| Model | Success Rate@1/5/10 | Precision@1/5/10 | MRR |
| :--- | :--- | :--- | :--- |
| **GraphCS** | **0.28/0.56/0.74** | **0.28/0.35/0.36** | **0.39** |
| CODEnn | 0.20/0.42/0.66 | 0.20/0.24/0.23 | 0.31 |
| RNN | 0.16/0.40/0.50 | - | 0.26 |
| NeuralBOW | 0.12/0.30/0.42 | - | 0.21 |

**Analisis Kinerja:**
*   **Peningkatan MRR:** GraphCS mencapai MRR $\mathbf{0.39}$, meningkat $\mathbf{25.8\%}$ dibandingkan CODEnn ($0.31$).
*   **Peningkatan Presisi:** Peningkatan paling signifikan terlihat pada Precision@k, yang naik $\mathbf{40.0\%}$ (k=1) hingga $\mathbf{56.5\%}$ (k=10) dibandingkan CODEnn. Ini menunjukkan bahwa hasil yang dikembalikan oleh GraphCS lebih relevan dan akurat.
*   **Keunggulan PDG:** Hasil ini membuktikan bahwa fusi informasi **struktur logis PDG** berhasil mengatasi keterbatasan CODEnn yang hanya mengandalkan fitur tekstual.

### B. Frank dan Validitas Semantik

*   **Peringkat Frank:** Analisis *Frank* (peringkat kemunculan pertama yang benar) pada kueri sampel menunjukkan bahwa hasil GraphCS sebagian besar memiliki nilai *Frank* yang lebih kecil (peringkat lebih tinggi) daripada CODEnn. GraphCS memiliki 13 kueri yang gagal ditemukan (NF), sedangkan CODEnn memiliki 17 NF, menunjukkan tingkat keberhasilan *retrieval* yang lebih tinggi.
*   **Metode Name/Semantik:** GraphCS juga menunjukkan rasio **Metode Name/Semantik** yang lebih tinggi ($0.649$) dibandingkan CODEnn ($0.545$), yang berarti hasil yang diretriev oleh GraphCS lebih terkait secara semantik dan sintaksis (nama metode lebih relevan), menunjukkan fusi fitur yang lebih baik.

### C. Efisiensi Waktu
*   Waktu Pelatihan GraphCS: $67.4$ jam.
*   Waktu Pelatihan CODEnn: $49.3$ jam.
*   Waktu *Retrieval* GraphCS: $164$ detik.
*   Waktu *Retrieval* CODEnn: $157$ detik.

**Analisis Waktu:** Meskipun GraphCS membutuhkan waktu pelatihan yang sedikit lebih lama karena pemrosesan graf PDG yang kompleks, perbedaan waktu *retrieval* (7 detik) dianggap dapat diabaikan dibandingkan dengan peningkatan akurasi yang signifikan.

## 5. Kesimpulan

GraphCS berhasil memitigasi kelemahan model *code search* berbasis teks dengan secara efektif menggabungkan **fitur struktural (PDG)** dan **fitur sekuensial** menggunakan **Mekanisme Perhatian** adaptif. Penerapan *graph embedding* (Graph2Vec + WL) memungkinkan representasi semantik kode yang lebih mendalam, yang terbukti meningkatkan akurasi *retrieval* secara substansial pada semua metrik dibandingkan *baseline* SOTA.

::: info Dampak Praktis
Dengan memberikan hasil pencarian yang lebih akurat dan relevan (*Precision* hingga 56.5% lebih tinggi), GraphCS secara langsung meningkatkan efisiensi kerja pengembang. Model ini menggarisbawahi pentingnya memahami *Program Dependency Graph* selain hanya teks kode untuk tugas *code search* yang efektif, membuka jalan untuk model *code intelligence* yang lebih kuat.
:::