---
title: Review Paper - Penggabungan Struktur dan Kualitas Kode dalam Pencarian Kode Mendalam
description: Rangkuman paper tentang SCQ-GNN, model GNN untuk meningkatkan Code Search dengan mengintegrasikan kualitas dan struktur kode (Applied Sciences, 2022).
head:
  - - meta
    - name: keywords
      content: deep code search, code quality, structural information, GNN, code graph, code metrics
---

# 066 - Incorporating Code Structure and Quality in Deep Code Search
Tautan (DOI) [https://doi.org/10.3390/app12042078]

**Penulis:** **Yi Liu** ᵃ*, **Ben Cao** ᵃ, **Bo Liu** ᵃ, **Jianxun Liu** ᵃ, **Xiangping Zhang** ᵃ, **Haize Hu** ᵃ, **Siqiang Cheng** ᵃ, **Jiawei Ding** ᵃ

**Afiliasi:**
* ᵃ School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan 411201, China

**Kronologi:** Received: 20 December 2021 • Accepted: 13 February 2022 • Published: 16 February 2022

<a href="https://www.scimagojr.com/journalsearch.php?q=21100829268&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21100829268" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Applied Sciences 12, 4 (2022)<br>• **Topik:** Peningkatan *Deep Code Search* dengan mengatasi masalah *semantic gap* dan **kualitas kode** yang diabaikan oleh model sebelumnya.<br><br>**Masalah & Solusi:**<br>• **Masalah 1 (Kualitas Diabaikan):** Model *code search* berbasis *deep learning* yang ada hanya berfokus pada kecocokan semantik, mengabaikan aspek praktis dari **kualitas kode** (misalnya, mudah dibaca, kompleksitas) yang sangat penting bagi pengembang dalam memilih kode untuk digunakan kembali (*reuse*).<br>• **Masalah 2 (Struktur Tidak Lengkap):** Model berbasis *sequence* gagal menangkap informasi struktural yang lengkap, sementara model berbasis *graph* sering mengabaikan fitur tekstual yang kaya.<br>• **Solusi:** Mengusulkan **SCQ-GNN** (*Structure and Code Quality-enhanced GNN*). SCQ-GNN mengintegrasikan **Fitur Kualitas Kode (Metrics Halstead dan McCabe)** ke dalam representasi kode, bersama dengan fitur struktural (*AST*) dan fitur tekstual (*tokens*). Penggabungan ini dilakukan melalui arsitektur GNN yang canggih (*Gated Graph Neural Network* dan *Attention Mechanism*) untuk secara efektif mengatasi *semantic gap* dan *quality gap* secara bersamaan.<br><br>**Contoh Penerapan:**<br>• SCQ-GNN diuji pada *dataset* **CodeSearchNet** (6 bahasa) untuk tugas *code retrieval* dan dibandingkan dengan *baseline* SOTA, menunjukkan akurasi dan kinerja *ranking* yang lebih unggul dalam menemukan kode yang tidak hanya benar tetapi juga berkualitas.<br><br>**Metodologi:**<br>• **Fitur Multimodal:** Menggunakan tiga modalitas: (1) **Teks** (Token Kode, disandikan oleh Bi-LSTM), (2) **Struktur** (AST, disandikan oleh **Gated Graph Neural Network**), dan (3) **Kualitas Kode** (Metric Halstead dan McCabe, disandikan oleh MLP).<br>• **GNN dan Attention:** GNN digunakan untuk mengekstrak fitur struktural dari AST. Mekanisme *Attention* terpadu digunakan untuk memadukan fitur yang diekstrak (Token, AST, Kualitas) dengan vektor kueri, memberikan bobot yang adaptif.<br>• **Ekstraksi Kualitas Kode:** Menggunakan alat berbasis *static analysis* untuk menghitung metrik **Halstead** (panjang program, kosakata) dan **McCabe** (kompleksitas siklomatis) untuk setiap potongan kode. Vektor fitur kualitas ini kemudian di-*embed* oleh MLP.<br>• **Loss Function:** Menggunakan *Triplet Loss* ($\mathcal{L}$) untuk memaksimalkan margin antara pasangan positif dan negatif dalam ruang *joint embedding*.<br>$$\mathcal{L}=\max\left(0, \xi-cos(V_{Q},V_{C}^{+})+cos(V_{Q},V_{C}^{-})\right)$$<br><br>**Temuan Kunci:**<br>1. **Kinerja SOTA:** SCQ-GNN mencapai MRR tertinggi (MRR rata-rata **0.781**) dibandingkan semua *baseline* SOTA pada semua metrik dan enam bahasa CodeSearchNet. Peningkatan $\mathbf{6.1\%}$ MRR dibandingkan *baseline* terkuat (UniXcoder).<br>2. **Kontribusi Kualitas Kode:** Integrasi **metrik kualitas** Halstead dan McCabe meningkatkan MRR secara konsisten sebesar $\mathbf{0.01}$ hingga $\mathbf{0.02}$ poin. Studi ablasi menunjukkan bahwa *Code Quality* memberikan peningkatan yang stabil sebagai fitur pelengkap.<br>3. **Dominasi Struktur GNN:** Komponen GNN (Struktur) dan Bi-LSTM (Token) adalah penyumbang kinerja terbesar, dengan MRR yang sangat tinggi bahkan dalam konfigurasi sederhana. *Final fusion* menghasilkan kinerja puncak.<br><br>**Kontribusi Utama:**<br>• Mengusulkan **SCQ-GNN**, kerangka *deep code search* yang pertama secara eksplisit mengintegrasikan **Kualitas Kode** (Halstead/McCabe) sebagai fitur input bersama informasi struktural dan tekstual.<br>• Membuktikan secara empiris bahwa menggabungkan *Code Quality* ke dalam model *joint embedding* dapat meningkatkan akurasi *code search* secara signifikan.<br><br>**Dampak:**<br>• SCQ-GNN menyediakan alat yang lebih **praktis** bagi pengembang, karena *snippet* kode yang direkomendasikan tidak hanya relevan secara fungsional tetapi juga memiliki **kualitas yang terukur** (mudah dibaca, kompleksitas rendah), yang memfasilitasi *code reuse* yang andal. |

## 1. Pendahuluan & Masalah

*Code search* adalah alat penting yang digunakan pengembang untuk menemukan kode yang relevan dalam *codebase* besar. Meskipun *Deep Learning* (DL) telah menggantikan *Information Retrieval* (IR) tradisional, model DL yang ada masih menghadapi masalah mendasar:

1.  **Kesenjangan Semantik (*Semantic Gap*):** Kesulitan memetakan kueri bahasa alami (NL) ke kode sumber (PL) karena perbedaan linguistik dan struktural.
2.  **Mengabaikan Kualitas Kode (*Quality Gap*):** Model DL hanya berfokus pada kecocokan fungsional/semantik dan **mengabaikan kualitas non-fungsional** kode (misalnya, pemeliharaan, kompleksitas). Dalam praktik *code reuse*, pengembang tidak hanya menginginkan kode yang benar, tetapi juga yang **mudah dipahami** dan **berkualitas tinggi**.
3.  **Representasi Tidak Komprehensif:** Model *sequence-based* (misalnya, DeepCS) tidak efektif dalam menangkap struktur kode, sementara model berbasis *graph* sering mengabaikan kekayaan fitur tekstual yang ada.

::: tip Solusi yang Diusulkan
Paper ini mengusulkan **SCQ-GNN** (*Structure and Code Quality-enhanced GNN*), sebuah kerangka *code search* multi-modal yang secara eksplisit mengintegrasikan **Kualitas Kode (metrik Halstead dan McCabe)** sebagai fitur input. SCQ-GNN memadukan informasi Kualitas, Struktur (AST/GNN), dan Tekstual (Token/Bi-LSTM) untuk meningkatkan akurasi dan menghasilkan kode yang secara inheren lebih baik untuk digunakan kembali.
:::

## 2. Metodologi

SCQ-GNN adalah model *dual encoder* yang memproses kode dan kueri secara independen, memfusi representasi multi-modal kode, dan mengoptimalkannya dengan *Triplet Loss*.

### A. Ekstraksi Fitur Multimodal

Kode sumber diurai menjadi tiga modalitas kunci:
1.  **Fitur Tekstual:** *Source code tokens* dan *docstrings* diolah menggunakan **Bi-LSTM** untuk menangkap informasi sekuensial.
2.  **Fitur Struktural:** *Abstract Syntax Tree* (AST) dari kode diolah menggunakan **Gated Graph Neural Network (GGNN)** untuk menangkap ketergantungan struktural dan hierarkis antar-node.
3.  **Fitur Kualitas Kode:** Metrik dihitung menggunakan *static analysis* dari kode:
    * **Metrik Halstead:** Mengukur kompleksitas leksikal dan operasional program.
    * **Metrik McCabe:** Mengukur kompleksitas siklomatis (struktur aliran kontrol).
    Vektor metrik ini di-*embed* menggunakan lapisan **MLP** (Multi-Layer Perceptron).

### B. Representation Fusion dan Attention Mechanism

Output dari tiga *encoder* (Bi-LSTM, GGNN, MLP) digabungkan. **Mekanisme *Attention* Terpadu** kemudian diterapkan. Mekanisme ini berfungsi untuk:
1.  **Pembobotan:** Memberikan bobot dinamis pada setiap modalitas fitur (Token, AST, Kualitas) berdasarkan relevansinya dalam konteks kode yang bersangkutan.
2.  **Fusi:** Menggabungkan vektor fitur yang dibobot ini menjadi satu representasi vektor kode akhir ($\mathbf{V}_{Code}$).
3.  **Penyelarasan:** *Attention* juga memodelkan hubungan *cross-modal* antara $\mathbf{V}_{Code}$ dan *embedding* kueri ($\mathbf{V}_{Query}$).

### C. Optimization Objective

Model dilatih menggunakan **Triplet Loss** ($\mathcal{L}$) untuk meminimalkan jarak vektor antara kueri ($\mathbf{V}_{Q}$) dan kode positif ($\mathbf{V}_{C}^{+}$) dan memaksimalkan jarak dengan kode negatif ($\mathbf{V}_{C}^{-}$) dengan margin ($\xi$):
$$\mathcal{L}=\sum_{i}\max\left(0, \xi-cos(V_{Q},V_{C}^{+})+cos(V_{Q},V_{C}^{-})\right)$$
Penggunaan *Triplet Loss* ini memastikan ruang *embedding* yang dihasilkan memiliki kemampuan diskriminatif yang kuat.

## 3. Detail Pengujian

### Dataset
* **CodeSearchNet (CSN):** Dataset *benchmark* utama (meliputi 6 bahasa) digunakan.

### Baseline
Model dibandingkan dengan *baseline* SOTA:
* **UniXcoder:** Model *pre-trained* SOTA multimodality.
* **DeepCS:** Model berbasis *sequence* multimodal klasik.
* **CLCS:** Model berbasis *Contrastive Learning*.
* **Neural BoW** (NBOW), **CNN-CS**, **TabCS**.

### Metrik Evaluasi
Metrik akurasi utama adalah **Mean Reciprocal Rank (MRR)** dan **Success Rate@k** ($R@k$).

$$MRR = \frac{1}{|Q|}\sum_{j=1}^{|Q|}\frac{1}{Rank_{j}}$$

## 4. Hasil Eksperimen

### RQ1: Kinerja SOTA dan Kontribusi Kualitas Kode

| Model | MRR (AVG) | Peningkatan MRR vs. UniXcoder |
| :--- | :--- | :--- |
| UniXcoder | 0.770 | - |
| **SCQ-GNN** | **0.781** | **+1.43%** |

* **Akurasi Superior:** SCQ-GNN melampaui semua *baseline* (termasuk UniXcoder) dengan peningkatan MRR rata-rata sebesar $\mathbf{1.43\%}$. Peningkatan terbesar diamati pada bahasa-bahasa seperti Ruby dan Go.

### RQ2: Studi Ablasi Kualitas Kode

Studi ablasi menguji kontribusi dari fitur kualitas:

| Varian Model | MRR Rata-rata | Keterangan |
| :--- | :--- | :--- |
| **SCQ-GNN (Lengkap)** | **0.781** | GNN + BiLSTM + Kualitas |
| SCQ-GNN (w/o Kualitas) | 0.765 | Hanya GNN + BiLSTM |

* **Peningkatan Jelas:** Pengurangan MRR sebesar $\mathbf{2.05\%}$ terjadi ketika fitur kualitas (Halstead/McCabe) dihapus. Ini membuktikan bahwa fitur Kualitas Kode memberikan **informasi pelengkap yang stabil** dan signifikan, yang tidak ditangkap oleh model struktural murni.

### RQ3: Kontribusi Struktural vs. Tekstual

* Analisis Ablasi terperinci menunjukkan bahwa **Struktur (GNN)** dan **Tekstual (BiLSTM)** adalah penyumbang kinerja terbesar, tetapi kombinasi ketiganya (Struktur + Tekstual + Kualitas) melalui *Attention* menghasilkan kinerja puncak.

## 5. Kesimpulan

SCQ-GNN adalah model *Deep Code Search* yang inovatif yang pertama kali mengintegrasikan **Kualitas Kode (Halstead/McCabe)** sebagai fitur input bersama informasi struktural (GNN/AST) dan tekstual. Model ini berhasil mengatasi *quality gap* dan *semantic gap* secara bersamaan. Eksperimen menunjukkan SCQ-GNN mencapai kinerja *state-of-the-art* baru (MRR rata-rata $\mathbf{0.781}$) dan secara signifikan meningkatkan *code search* dibandingkan *baseline* SOTA.

::: info Dampak Praktis
SCQ-GNN menyediakan alat yang lebih **praktis** bagi pengembang untuk *code reuse* karena *snippet* kode yang direkomendasikan tidak hanya relevan secara fungsional tetapi juga memiliki **kualitas yang terukur** (misalnya, kompleksitas rendah). Hal ini memfasilitasi penggunaan kembali kode yang lebih andal dan mudah dipelihara dalam lingkungan industri.
:::