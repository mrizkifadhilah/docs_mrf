---
title: Review Paper - LLM for Query Expansion in Code Search
description: Rangkuman paper tentang efektivitas Large Language Models (LLM) untuk ekspansi kueri dalam pencarian kode (The Journal of Systems and Software, 2025).
head:
  - - meta
    - name: keywords
      content: Query Expansion, Large Language Models, Code Search, Deep Learning, BERT, GPT-2
---

# 002 - On the effectiveness of large language models for query expansion in code search

**Penulis:** **Xiangzheng Liu** ᵃ,ᵇ, **Jianxun Liu** ᵃ,ᵇ,* (Corresponding Author), **Guosheng Kang** ᵃ,ᵇ, **Min Shi** ᶜ, **Yi Liu** ᵃ,ᵇ, **Yiming Yin** ᵃ,ᵇ

**Afiliasi:**
* ᵃ Hunan Key Lab for Services Computing and Novel Software Technology, Hunan University of Science and Technology, Xiangtan, 411100, China
* ᵇ School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan, 411100, China
* ᶜ School of Computing & Informatics, University of Louisiana at Lafayette, Lafayette, LA, USA

**Kronologi:** Received: 23 March 2025 • Revised: 20 July 2025 • Accepted: 22 July 2025 • Available Online: 5 August 2025

<a href="https://www.scimagojr.com/journalsearch.php?q=19309&tip=iss" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=19309" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** The Journal of Systems and Software, Vol 230 (2025)<br>• **Penerbit:** Elsevier (Q1)<br>• **Topik:** Software Engineering, Code Search, LLM<br><br>**Masalah & Solusi:**<br>• **Masalah:** "**Lexical Gap**" atau kesenjangan leksikal antara kueri bahasa alami pengguna yang singkat dengan deskripsi kode/implementasi yang detail, menyebabkan kegagalan pencarian berbasis kata kunci atau vektor standar.<br>• **Solusi:** Menggunakan pendekatan **Self-Supervised Generative Query Expansion** (SG-BERT dan SG-GPT2) untuk memperkaya kueri pengguna dengan istilah semantik yang relevan sebelum proses pencarian.<br><br>**Contoh Penerapan (Input $\to$ Output):**<br>• *Input Kueri:* "convert int to str in python"<br>• *Proses (BERT):* Masking keyword $\to$ `[MASK] convert [MASK] int...` $\to$ Prediksi token.<br>• *Output Ekspansi:* "efficiently convert string int string to str array"<br>• *Hasil Pencarian:* Menemukan fungsi kode yang relevan dengan variasi istilah tersebut.<br><br>**Metodologi:**<br>• **Dataset:** Kumpulan korpus kueri besar (**19 juta kalimat**) dari CodeSearchNet, CoDesc, CoNaLa, DeepCS, dan StackOverflow.<br>• **Metode:** Fine-tuning model **BERT** (via Masked Language Model/MLM) dan **GPT-2** (via Next Token Prediction) khusus untuk domain kode.<br><br>**Temuan Kunci:**<br>1. **Superioritas:** SG-BERT dan SG-GPT2 mengungguli metode ekspansi lain (WordNet, GooglePS, SEQUER, SSQR) pada metrik MRR di hampir semua 6 bahasa pemrograman yang diuji.<br>2. **Pentingnya Fine-tuning:** Model yang di-fine-tune secara signifikan mengungguli model *zero-shot*, menghindari ekspansi yang tidak relevan.<br>3. **Panjang Kueri:** Ekspansi sangat efektif untuk kueri pendek, namun bisa kontraproduktif untuk kueri yang sudah sangat panjang.<br><br>**Kontribusi Utama:**<br>• Mengusulkan kerangka kerja *self-supervised* untuk ekspansi kueri menggunakan LLM tanpa memerlukan data berlabel manual.<br>• Membangun dataset *fine-tuning* skala besar dari berbagai sumber.<br>• Melakukan evaluasi ekstensif pada 6 bahasa pemrograman (Python, Java, PHP, Ruby, Go, JavaScript).<br><br>**Dampak:**<br>• **Akurasi Pencarian:** Meningkatkan kemungkinan pengembang menemukan kode yang tepat meskipun menggunakan kueri yang ambigu atau singkat.<br>• **Efisiensi:** Mengurangi waktu yang dihabiskan pengembang untuk merumuskan ulang kueri pencarian secara manual.<br><br>**Tautan:** [10.1016/j.jss.2025.112582](https://doi.org/10.1016/j.jss.2025.112582) |

## 1. Pendahuluan & Masalah

Pencarian kode (*code search*) bertujuan untuk menemukan potongan kode yang relevan dari repositori besar berdasarkan kueri bahasa alami. Namun, tantangan utamanya adalah **Lexical Gap** (kesenjangan leksikal/heterogenitas). Kueri pengguna seringkali singkat dan tidak mengandung istilah teknis yang tepat, sementara kode sumber atau dokumentasinya mengandung deskripsi yang kaya dan spesifik.

Metode tradisional seperti pencarian kata kunci gagal ketika tidak ada kecocokan kata yang tepat. Metode berbasis *Deep Learning* mencoba menjembatani ini dengan ruang vektor, namun sering kali dilatih menggunakan pasangan <Deskripsi Kode, Kode>, bukan <Kueri User, Kode>. Karena kueri pengguna asli jauh lebih pendek daripada deskripsi kode, model sering gagal menangkap maksud pengguna.

::: tip Solusi yang Diusulkan
Paper ini memperkenalkan **SG-BERT** dan **SG-GPT2**. Ini adalah metode ekspansi kueri generatif yang memanfaatkan kemampuan pemahaman bahasa dari LLM (BERT dan GPT-2) yang telah di-*fine-tune* secara *self-supervised* pada korpus kueri pemrograman skala besar untuk menjembatani kesenjangan semantik tersebut.
:::

## 2. Metodologi

Penelitian ini menggunakan kerangka kerja dua tahap: pelatihan generator dan proses pencarian kode.

### A. Self-Supervised Generator (Pelatihan)
Penulis mengumpulkan korpus kueri besar (19 juta kalimat) dari berbagai sumber (CSND, CoDesc, CoNaLa, DeepCS, StackOverflow). Dua model dilatih ulang (*fine-tuned*) menggunakan data ini:
1. **SG-BERT (Masked Language Model):** Menggunakan tugas MLM. Kata kunci dalam kueri di-*mask* (misal: `[MASK]`), dan model belajar memprediksi kata yang hilang berdasarkan konteks pemrograman. Ini membantu mengisi istilah yang mungkin terlewat oleh pengguna.
2. **SG-GPT2 (Generative Pre-trained Transformer):** Menggunakan tugas prediksi kata berikutnya (*Next Token Prediction*). Model belajar melengkapi atau memperpanjang kalimat kueri agar lebih deskriptif.

### B. Proses Pencarian (Inference)
1. **Query Encoding:** Kueri asli pengguna dimasukkan ke generator (SG-BERT/SG-GPT2).
2. **Expansion:** Generator menghasilkan beberapa variasi kueri yang diperluas (menggunakan *top-k sampling*).
3. **Retrieval:** Kueri yang diperluas digunakan sebagai input ke model pencarian kode utama (seperti CoCoSoDa atau GraphCodeBERT) untuk menghitung kesamaan vektor dengan basis data kode.

## 3. Detail Pengujian

### Dataset
* **Sumber:** CodeSearchNet (CSND).
* **Bahasa:** 6 Bahasa (Go, Java, JavaScript, PHP, Python, Ruby).
* **Pembagian:** Training set menggunakan deskripsi panjang (>7 kata), Test set menggunakan deskripsi pendek (<7 kata) untuk mensimulasikan kueri pengguna.

### Baseline (Metode Pembanding)
* **WordNet:** Ekspansi berbasis sinonim.
* **GooglePS:** Menggunakan hasil *autocomplete/reconstruction* dari Google Search.
* **SEQUER:** Model berbasis *Machine Translation* (supervised).
* **SSQR:** Model *self-supervised* berbasis T5 (hanya dilatih pada Python).

### Metrik Evaluasi
Evaluasi dilakukan menggunakan dua metrik standar dalam *Information Retrieval*:

1. **Recall@k:** Persentase fragmen kode yang benar yang muncul dalam $k$ hasil teratas.
    $$Recall@k = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \mathbb{I}(Rank(Q_i) \le k)$$
2. **Mean Reciprocal Rank (MRR):** Rata-rata kebalikan dari peringkat hasil yang benar.
    $$MRR = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{Rank(Q_i)}$$

## 4. Hasil Eksperimen

### A. Perbandingan Kinerja (MRR)
Tabel berikut menunjukkan perbandingan performa MRR menggunakan *backbone* model pencarian **CoCoSoDa**:

| Metode | Java | Python | JS | PHP | Ruby | Go |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Original Query | 0.665 | 0.644 | 0.525 | 0.662 | 0.606 | 0.829 |
| WordNet | 0.670 | 0.652 | 0.537 | 0.670 | 0.601 | 0.827 |
| SEQUER | 0.688 | 0.671 | 0.555 | 0.686 | 0.614 | 0.818 |
| SSQR | 0.691 | 0.685 | 0.569 | 0.685 | 0.617 | 0.829 |
| **SG-BERT (Proposed)** | **0.734** | 0.697 | 0.567 | 0.710 | **0.632** | **0.833** |
| **SG-GPT2 (Proposed)** | 0.723 | **0.711** | **0.570** | **0.732** | 0.631 | 0.829 |

**Analisis:**
* **SG-BERT** dan **SG-GPT2** secara konsisten mengungguli metode lain, terutama pada bahasa Java dan PHP.
* Peningkatan MRR mencolok (misal, 0.665 menjadi **0.734** pada Java), memvalidasi efektivitas ekspansi berbasis LLM.

### B. Analisis Panjang Kueri
Hasil menunjukkan korelasi negatif antara panjang kueri dan efektivitas ekspansi.
* **Kueri Pendek (5 kata):** Ekspansi memberikan peningkatan MRR terbesar.
* **Kueri Panjang (10+ kata):** Peningkatan mengecil atau bahkan menurun, karena ekspansi dapat menambahkan informasi redundan atau "noise" yang mengalihkan fokus model pencarian.

### C. Efek Fine-tuning
Studi ablasi menunjukkan bahwa model *fine-tuned* (**SG-BERT/SG-GPT2**) jauh lebih unggul daripada model *Zero-shot*. Tanpa *fine-tuning* pada korpus kueri pemrograman, LLM dapat salah menginterpretasikan istilah domain (misalnya, mengasosiasikan "lambda" dengan kalkulus, bukan fungsi pemrograman), yang mengakibatkan hasil pencarian yang lebih buruk.

## 5. Kesimpulan

Penelitian ini menyimpulkan bahwa **SG-BERT** dan **SG-GPT2** adalah metode yang efektif untuk mengatasi masalah *lexical gap* dalam pencarian kode. Dengan melatih model bahasa pada korpus kueri pemrograman yang besar secara *self-supervised*, model mampu menghasilkan ekspansi kueri yang relevan secara semantik, yang secara langsung meningkatkan akurasi pencarian kode di berbagai bahasa pemrograman.

::: info Dampak Praktis
Bagi pengembang perangkat lunak, metode ini berarti mesin pencari kode dapat memahami "maksud" di balik kueri singkat mereka dengan lebih baik, mengurangi frustrasi saat mencari solusi untuk masalah pemrograman, dan mempercepat siklus pengembangan.
:::