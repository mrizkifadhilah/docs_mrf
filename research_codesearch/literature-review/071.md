---
title: Review Paper - CRaDLe Code Retrieval Berbasis Pembelajaran Ketergantungan Semantik
description: Rangkuman paper tentang CRaDLe, sebuah model jaringan saraf dalam yang mengintegrasikan informasi ketergantungan program tingkat pernyataan untuk meningkatkan akurasi pencarian kode (Neural Networks, 2021).
head:
  - - meta
    - name: keywords
      content: Code retrieval, Semantic dependency, Dependency learning, Neural network, PDG, CRaDLe
---

# 071 - CRaDLe: Deep code retrieval based on semantic Dependency Learning
Tautan (DOI) [https://doi.org/10.1016/j.neunet.2021.04.019]

**Penulis:** **Wenchao Gu** $^{a*}$, **Zongjie Li** $^{b}$, **Cuiyun Gao** $^{b}$, **Chaozheng Wang** $^{b}$, **Hongyu Zhang** $^{c}$, **Zenglin Xu** $^{b}$, **Michael R. Lyu** $^{a}$

**Afiliasi:**
* $^{a}$ The Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China
* $^{b}$ The School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China
* $^{c}$ The University of Newcastle, Australia

**Kronologi:** Received: 10 November 2020 • Revised: 8 Maret 2021 • Accepted: 15 April 2021 • Available Online: 26 April 2021

<a href="https://www.scimagojr.com/journalsearch.php?q=24804&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=24804" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Neural Networks 141 (2021)<br>• **Topik:** Peningkatan akurasi pencarian kode (*code retrieval*) dengan memitigasi *semantic gap* melalui representasi kode yang kaya struktur.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Tantangan utama dalam *code retrieval* adalah *semantic gap* antara kueri bahasa alami (NL) dan potongan kode (PL) yang heterogen. Upaya sebelumnya menggunakan struktur kode (AST/CFG) terlalu dalam atau bias, gagal menangkap dependensi struktural yang penting untuk semantik kode secara efektif.<br>• **Solusi:** Mengusulkan **CRaDLe** (*Code Retrieval based on semantic Dependency Learning*). CRaDLe mengintegrasikan **informasi ketergantungan tingkat pernyataan** (dari *Program Dependency Graph*, PDG) dengan semantik token tingkat pernyataan untuk mendapatkan representasi kode yang lebih akurat.<br><br>**Contoh Penerapan:**<br>• Diuji pada dua *dataset* dunia nyata: **CodeSearchNet** (Python) dan **Code2seq** (Python 3).<br>• CRaDLe mengungguli *state-of-the-art* (SOTA) seperti SelfAttn: Peningkatan R@1 minimal $\mathbf{36.38\%}$ dan MRR $\mathbf{25.26\%}$ pada CodeSearchNet, serta R@1 minimal $\mathbf{22.34\%}$ pada Code2seq.<br><br>**Metodologi:**<br>• **Arsitektur:** Terdiri dari *Code Encoder*, *Description Encoder*, dan komponen *Similarity Measurement*.<br>• **Code Encoder (CRaDLe):** Menggabungkan informasi struktural dan semantik pada tingkat pernyataan.<br>    1. **Ekstraksi Dependensi:** Menggunakan PDG (berdasarkan *data dependency* dan *control dependency* yang diekstraksi dari AST yang disederhanakan) untuk membuat Matriks Dependensi $\Upsilon$.<br>    2. **Penyematan Dependensi:** Matriks $\Upsilon$ disematkan menjadi vektor dependensi $P$ menggunakan MLP.<br>    3. **Penyematan Token:** Semantik token tingkat pernyataan disematkan menjadi $T$ menggunakan mekanisme *Attention*.<br>    4. **Penyematan Dependensi Semantik:** Vektor $P$ dan $T$ digabungkan/dikonkatenasi ($s_i = [t_i; p_i]$), lalu dimasukkan ke Bi-LSTM untuk menghasilkan Vektor Kode $c$.<br>• **Description Encoder:** Menggunakan Bi-LSTM diikuti dengan *Maxpooling* untuk menghasilkan Vektor Deskripsi $d$.<br>• **Pengukuran Kesamaan:** Menggunakan jarak **Cosine** antara $c$ dan $d$ dalam ruang penyematan bersama.<br>• **Fungsi Loss:** Menggunakan *ranking loss* untuk melatih pasangan $(C, D^+, D^-)$ agar meminimalkan jarak antara kode dan deskripsi positif ($D^+$) sambil memaksimalkan jarak dari deskripsi negatif ($D^-$).<br>$$\mathcal{L}(\theta)=\sum_{(C,D^{+},D^{-})\in T}\max(0,\epsilon-\cos(c,d^{+})+\cos(c,d^{-}))$$<br><br>**Temuan Kunci:**<br>1. **Dependensi Kunci Peningkatan:** CRaDLe (menggabungkan dependensi dan semantik) secara signifikan mengungguli semua *baseline*, membuktikan pentingnya dependensi tingkat pernyataan. Peningkatan R@1 sangat signifikan ($>20\%$ di kedua *dataset*).<br>2. **Peran Ketergantungan:** Model yang menggunakan kombinasi *data dependency* dan *control dependency* ($CRaDLe_{Full}$) mengungguli model yang hanya menggunakan salah satunya, menunjukkan bahwa kedua jenis dependensi itu penting dan saling melengkapi.<br>3. **Generalisasi Lebih Baik:** CRaDLe menunjukkan generalisasi yang lebih baik antar *dataset* dibandingkan model *baseline* (misalnya SelfAttn).<br>4. **Strategi Baru yang Lebih Baik (Diskusi):** Strategi penyematan dependensi yang diperkaya semantik yang baru (mengintegrasikan token tingkat pernyataan secara langsung ke matriks dependensi) sedikit mengungguli desain asli CRaDLe (MRR $0.851$ vs $0.843$ pada CodeSearchNet).<br><br>**Kontribusi Utama:**<br>• Model *code retrieval* pertama yang secara eksplisit mengintegrasikan **informasi ketergantungan dan semantik pada tingkat pernyataan** berbasis PDG.<br>• Menghadirkan model CRaDLe yang secara konsisten dan signifikan mengungguli SOTA pada *benchmark* publik.<br><br>**Dampak:**<br>• Menjembatani *semantic gap* secara lebih efektif dengan memanfaatkan struktur kode yang relevan. Hal ini menghasilkan alat *code retrieval* yang lebih akurat, secara langsung **meningkatkan efisiensi dan reusabilitas kode** bagi para programmer. |

## 1. Pendahuluan & Masalah

*Code retrieval* (pencarian kode) adalah praktik umum bagi pemrogram untuk menggunakan kembali potongan kode yang ada. Tantangan utama terletak pada **kesenjangan semantik** (*semantic gap*) antara kueri bahasa alami (NL) dan kode sumber (PL) karena heterogenitas leksikal, sinonim, dan struktur bahasa.

Studi terdahulu mengandalkan teknik *Information Retrieval* (IR) berbasis kesamaan token atau beralih ke *Deep Neural Network* (DNN) untuk memetakan kode dan kueri ke dalam ruang vektor bersama. Meskipun arsitektur struktural seperti *Abstract Syntax Tree* (AST) dan *Control Flow Graph* (CFG) telah diusulkan untuk menangkap semantik kode, AST seringkali terlalu dalam dan kompleks, sementara CFG dapat mencakup jalur eksekusi yang tidak berkontribusi pada hasil, yang berpotensi menghasilkan representasi kode yang bias.

*Ketergantungan tingkat pernyataan* (*statement-level dependency*) yang berasal dari *Program Dependency Graph* (PDG), mencerminkan hubungan fungsional di antara pernyataan selama eksekusi. Informasi ini, yang terbukti berguna dalam tugas seperti deteksi *bug* dan klon kode, belum pernah dieksplorasi untuk tugas *code retrieval*.

::: tip Solusi yang Diusulkan
Diperkenalkan **CRaDLe** (*Code Retrieval based on semantic Dependency Learning*), sebuah model jaringan saraf baru. CRaDLe adalah pendekatan pertama yang menggabungkan secara eksplisit **informasi ketergantungan (struktural)** dan **informasi semantik (token)** pada **tingkat pernyataan** untuk menghasilkan representasi kode yang kaya, sehingga secara efektif mengurangi *semantic gap* untuk *code retrieval*.
:::

## 2. Metodologi

CRaDLe memiliki kerangka kerja yang terdiri dari *Code Encoder*, *Description Encoder*, dan komponen *Similarity Measurement*.

### A. Code Encoder

Tujuan *Code Encoder* adalah menyematkan potongan kode menjadi vektor, memadukan semantik token tingkat pernyataan dengan informasi ketergantungan yang diekstraksi dari PDG.

1.  **Ekstraksi Informasi Dependensi:**
    *   *Program Dependency Graph* (PDG) dibangun dari AST yang disederhanakan pada tingkat pernyataan.
    *   PDG menangkap *data dependency* (variabel yang digunakan didefinisikan di tempat lain) dan *control dependency* (eksekusi pernyataan bergantung pada hasil pernyataan lain).
    *   Matriks Dependensi $\Upsilon \in \{0, 1\}^{(l)\times(l)}$ dibuat, di mana $l$ adalah jumlah pernyataan. $v_{ij}=1$ jika pernyataan $i$ bergantung pada pernyataan $j$.

2.  **Penyematan Dependensi Tingkat Pernyataan:**
    *   Matriks $\Upsilon$ disematkan menjadi vektor dependensi $P=[p_1...p_l]$ menggunakan *Multi-Layer Perceptron* (MLP).
    $$p_{i}=\tanh(W^{\Upsilon}v_{i}), \quad \forall i=1,2,...,l$$

3.  **Penyematan Token Tingkat Pernyataan:**
    *   Token pada setiap pernyataan disematkan, dan lapisan *Attention* digunakan untuk menghitung rata-rata berbobot, menghasilkan representasi semantik token $t_i$.
    $$t_{i}=\sum_{j}\alpha_{i,j}e_{i,j}^{\top}, \quad \text{di mana } \alpha_{i,j} \text{ adalah bobot attention}$$

4.  **Penyematan Dependensi Semantik:**
    *   Vektor dependensi $p_i$ dan vektor token $t_i$ digabungkan (dikonkatenasi) untuk setiap pernyataan: $s_{i}=[t_{i};p_{i}]$.
    *   Urutan penyematan pernyataan ($s_1, \dots, s_l$) kemudian diumpankan ke **Bi-LSTM** untuk menghasilkan vektor representasi kode akhir ($c$).
    $$c=\text{BiLSTM}(h_{l},s_{l})$$

### B. Description Encoder

*Description Encoder* menggunakan model **Bi-LSTM** diikuti oleh lapisan **Maxpooling** untuk menyematkan kueri bahasa alami menjadi vektor deskripsi $d$. *Maxpooling* membantu menangkap fitur global kalimat dan mengurangi hilangnya informasi jangka panjang.

### C. Pengukuran Kesamaan dan Pelatihan Model

Kesamaan semantik antara vektor kode $c$ dan vektor deskripsi $d$ diukur menggunakan **Cosine Distance**.
$$\cos(c,d)=\frac{c^{\top}d}{||c||||d||}$$
Model dilatih menggunakan *ranking loss* pada triplet $\langle C, D^+, D^- \rangle$ (Kode, Deskripsi Positif, Deskripsi Negatif).
$$\mathcal{L}(\theta)=\sum_{(C,D^{+},D^{-})\in T}\max(0,\epsilon-\cos(c,d^{+})+\cos(c,d^{-}))$$

## 3. Detail Pengujian

### Dataset
Dua *dataset* Python 3 digunakan:
1.  **CodeSearchNet** (Python): 407.126 pasangan latih. Median pernyataan: 7.
2.  **Code2seq** (Python 3): 329.328 pasangan latih. Median pernyataan: 7.

### Metrik Evaluasi
Evaluasi dilakukan dengan 999 *distractor snippets* per pasangan uji, menggunakan metrik peringkat standar:
1.  **R@k (Recall at k):** Menilai apakah jawaban yang benar berada di antara $k$ hasil teratas.
    $$R@k=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\delta(\text{FRank}_{q}\le k)$$
2.  **MRR (Mean Reciprocal Rank):** Rata-rata kebalikan peringkat dari jawaban yang benar.
    $$MRR=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{1}{\text{FRank}_{q}}$$

### Baseline
Model SOTA dan *baseline* yang dibandingkan meliputi: CODEnn, UNIF, NeuralBoW, RNN, CONV, CONVSelf, dan SelfAttn (arsitektur berbasis *multi-head attention* yang terbukti efektif).

## 4. Hasil Eksperimen

### A. Hasil Utama (Tabel 5 & 6)

| Pendekatan | CodeSearchNet R@1 | CodeSearchNet MRR | Code2seq R@1 | Code2seq MRR |
| :--- | :--- | :--- | :--- | :--- |
| SelfAttn (SOTA) | 0.580 | 0.673 | 0.525 | 0.599 |
| **CRaDLe** | **0.791** | **0.843** | **0.668** | **0.749** |

**Analisis Kinerja:**
*   **Peningkatan Signifikan:** CRaDLe secara substansial mengungguli semua *baseline*. Peningkatan terbesar terlihat pada R@1, yang sangat penting bagi *programmer* yang mencari hasil terbaik di urutan pertama.
*   **Efek Dependensi:** Peningkatan kinerja membuktikan bahwa penggabungan **penyematan dependensi semantik** (melalui PDG dan token) adalah strategi yang efektif untuk representasi kode, menjembatani *semantic gap*.

### B. Studi Ablasi (Tabel 7 & 8)

| Pendekatan | CodeSearchNet R@1 | CodeSearchNet MRR |
| :--- | :--- | :--- |
| $CRaDLe_{Full}$ (Data + Control) | **0.791** | **0.843** |
| $CRaDLe_{DataDependency}$ | 0.779 | 0.840 |
| $CRaDLe_{ControlDependency}$ | 0.785 | 0.845 |

**Analisis Dependensi:**
*   Kombinasi *data dependency* dan *control dependency* menghasilkan kinerja terbaik ($CRaDLe_{Full}$), mengindikasikan bahwa kedua jenis dependensi tersebut penting dan saling melengkapi untuk penangkapan semantik kode secara akurat.
*   Model yang hanya menggunakan satu jenis dependensi berkinerja lebih rendah, terutama pada metrik R@1.

### C. Analisis Parameter

Kinerja mencapai nilai tertinggi ketika:
*   **Jumlah Unit Tersembunyi (Hidden Units) Bi-LSTM:** 1024 (kinerja meningkat, namun laju peningkatan menurun setelahnya).
*   **Jumlah Maksimum Pernyataan:** 20 (melebihi ini, kinerja menurun karena median pernyataan hanya 7-10).
*   **Jumlah Maksimum Token per Pernyataan:** 5 (konsisten dengan rata-rata 3 token per pernyataan di *dataset*).

## 5. Kesimpulan

Paper ini memperkenalkan **CRaDLe**, sebuah model jaringan saraf dalam baru yang merupakan model pertama yang memanfaatkan informasi **ketergantungan program tingkat pernyataan** untuk tugas *code retrieval*. Dengan memadukan informasi struktural PDG dan semantik token tingkat pernyataan, CRaDLe berhasil menciptakan representasi kode terpadu yang secara signifikan mengurangi *semantic gap* dengan kueri bahasa alami. Hasil eksperimen pada *dataset* CodeSearchNet dan Code2seq menunjukkan bahwa CRaDLe mengungguli SOTA dan *baseline* secara substansial, terutama pada metrik R@1.

::: info Dampak Praktis
CRaDLe menawarkan solusi yang lebih andal dan akurat untuk *code retrieval* dengan secara efektif memanfaatkan informasi struktural yang krusial dalam kode, yang sebelumnya diabaikan atau ditangkap secara tidak efisien. Ini secara langsung **meningkatkan reusabilitas kode** dan **produktivitas pengembang** dengan mengembalikan potongan kode yang paling relevan di urutan teratas.
:::