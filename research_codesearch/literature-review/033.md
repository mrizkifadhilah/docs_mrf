---
title: Review Paper - JBLG Arsitektur Bi-LSTM-GNN Gabungan untuk Code Retrieval
description: Rangkuman paper tentang peningkatan pengambilan kode sumber dengan arsitektur Bi-LSTM-GNN gabungan dan studi komparatif dengan ChatGPT-LLM (Journal of King Saud University - Computer and Information Sciences, 2024).
head:
  - - meta
    - name: keywords
      content: Code reuse, Code recommendation, Source code retrieval, Joint model, Bi-directional LSTM, GNN, Deep learning, ChatGPT
---

# 033 - Enhancing source code retrieval with joint Bi-LSTM-GNN architecture: A comparative study with ChatGPT-LLM
Tautan (DOI) [10.1016/j.jksuci.2023.101865](https://doi.org/10.1016/j.jksuci.2023.101865)

**Penulis:** **Nazia Bibi** $^{a}$*, **Ayesha Maqbool** $^{a}$, **Tauseef Rana** $^{a}$

**Afiliasi:**
* $^a$ Department of Computer Software Engineering, National University of Sciences and Technology, Islamabad, 44000, Pakistan

**Kronologi:** Received: 3 July 2023 • Revised: 16 November 2023 • Accepted: 26 November 2023 • Available Online: 14 December 2023

<a href="https://www.scimagojr.com/journalsearch.php?q=21100389724&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21100389724" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Journal of King Saud University - Computer and Information Sciences 36 (2024) 101865<br>• **Topik:** Mengatasi keterbatasan model *deep learning* yang ada dalam menangkap informasi struktural kode yang kompleks untuk meningkatkan akurasi pengambilan kode sumber (*source code retrieval*).<br><br>**Masalah & Solusi:**<br>• **Masalah 1 (Keterbatasan Struktural):** Model *deep learning* yang ada (*Bi-LSTM, GNN* individual) tidak secara efektif menangkap informasi **struktural** kode yang rumit dan kompleks (misalnya, hubungan dependensi) dan **sekuensial** (aliran eksekusi) secara holistik. Bi-LSTM kuat di sekuensial tetapi lemah di struktural/hierarkis, sementara GNN kuat di struktural tetapi lemah di sekuensial/temporal.<br>• **Masalah 2 (Model LLM Umum):** Model *Large Language Model* (LLM) seperti **ChatGPT** (GPT-3.5) meskipun menjanjikan, tidak dioptimalkan untuk sintaks dan semantik kode yang spesifik dan kompleks, sehingga kinerjanya cenderung lebih rendah untuk tugas *code retrieval* dibandingkan model yang dirancang khusus.<br>• **Solusi:** Mengusulkan model **JBLG** (*Joint Bi-directional LSTM and Graph Neural Networks*). Arsitektur hibrida ini menggabungkan: (1) **Bi-LSTM** untuk menangkap dependensi **sekuensial** dan **kontekstual** kueri/kode. (2) **GNN** untuk memodelkan struktur **graf** kode yang rumit (menggunakan AST sebagai basis graf). Model ini juga memasukkan lapisan **Atensi** dan **Graf Atensi** untuk bobot yang dinamis.<br><br>**Contoh Penerapan:**<br>• Diuji pada dua *dataset* beragam: **CodeSearchNet** (6 bahasa pemrograman: Java, Python, JavaScript, Ruby, Go, PHP) dan **CosBench** (52 kueri StackOverflow + distractor).<br><br>**Metodologi:**<br>• **Arsitektur Hibrida:** Input kueri dan kode di-encode secara paralel oleh lapisan Bi-LSTM dan GNN.<br>• **Bi-LSTM Layer:** Memproses urutan *embedding* kueri dan kode dalam dua arah (maju dan mundur) untuk menangkap konteks sekuensial.\\($h_{i}^{c}=[\vec{h}_{i}^{c};\overline{h}_{i}^{c}]\\$).<br>• **GNN Layer:** Memproses representasi kode sebagai graf (berdasarkan AST), memperbarui representasi *node* berdasarkan tetangga untuk menangkap informasi struktural. GNN menggunakan *Graph Convolutional Networks* (GCN) dan *Self-Attention* pada graf.<br>• **Attention Layer:** Menerapkan **Attention** (membandingkan *embedding* kueri dengan kode) dan **Graph Attention** (membobotkan *node* dalam graf berdasarkan kueri) secara terpisah.<br>• **Concatenation Layer:** Menggabungkan output dari Bi-LSTM, GNN, dan kedua mekanisme *attention* menjadi satu representasi akhir $h_i$ per *snippet* kode: $h_{i}=[h_{i}^{f},h_{i}^{b},h_{i}^{g},\alpha_{i},\beta_{i}].$<br>• **Ranking:** MLP memprediksi skor relevansi $\hat{y}_i = \text{MLP}(h_i)$, dan skor ini digunakan untuk menentukan peringkat (cosine similarity).<br><br>**Temuan Kunci:**<br>1. **Kinerja Superior:** JBLG secara konsisten mengungguli *baseline* (Bi-LSTM, GNN, DGMS) dan LLM umum (**ChatGPT**) di semua metrik evaluasi (P, R, F1, MRR, NDCG, MAP) pada kedua *dataset* dan di berbagai bahasa pemrograman.<br>2. **MRR Tertinggi:** JBLG mencapai MRR $\mathbf{0.7823}$ dan $\mathbf{0.89}$ (pada CodeSearchNet dan CosBench), tertinggi dibandingkan DGMS (0.7143/0.86), GNN (0.6857/0.80), Bi-LSTM (0.6635/0.85), dan ChatGPT (0.5543/0.73).<br>3. **Kelemahan LLM Umum:** ChatGPT menunjukkan kinerja terendah karena kurangnya optimasi spesifik untuk sintaks dan struktur kode, serta keterbatasan dalam menangani konteks teknis atau OOV (*Out-of-Vocabulary*).<br>4. **Efektivitas Hibrida:** Penggabungan Bi-LSTM dan GNN terbukti efektif dalam menangani skenario kompleks seperti pengambilan kode **lintas-bahasa** dan pengambilan kode dengan **kueri tidak lengkap**.<br><br>**Kontribusi Utama:**<br>• Mengusulkan dan mengembangkan arsitektur **JBLG** yang menggabungkan Bi-LSTM dan GNN untuk pengambilan kode sumber yang ditingkatkan.<br>• Mendemonstrasikan secara empiris keunggulan JBLG dibandingkan *state-of-the-art* *baseline* dan perbandingan langsung dengan **ChatGPT**.<br>• Memberikan wawasan tentang efektivitas JBLG dalam menangani pengambilan kode **lintas-bahasa** dan **kueri tidak lengkap**.<br><br>**Dampak:**<br>• JBLG berpotensi merevolusi *source code retrieval* di dunia nyata dengan memberikan akurasi yang jauh lebih tinggi dan pemahaman yang komprehensif terhadap kode sumber, baik dari aspek sekuensial maupun struktural. Model ini adalah solusi yang sangat menjanjikan untuk meningkatkan produktivitas pengembang. |

## 1. Pendahuluan & Masalah

Pengambilan kode sumber (*source code retrieval*) yang relevan dari repositori besar merupakan tantangan signifikan dalam rekayasa perangkat lunak, terutama karena jumlah kode yang terus bertambah. Meskipun metode *deep learning* (DL) tradisional (seperti CNN, RNN) telah digunakan, mereka memiliki keterbatasan dalam menangkap **informasi struktural** yang rumit dan kompleks yang tertanam dalam kode sumber, sehingga menghambat akurasi pengambilan.

Model yang ada, seperti Bi-LSTM, unggul dalam menangkap dependensi sekuensial tetapi lemah dalam struktur hierarkis. Sebaliknya, *Graph Neural Networks* (GNNs) mahir dalam memodelkan struktur graf, tetapi mungkin tidak efektif dalam menangkap dependensi sekuensial dan temporal. Keterbatasan ini membutuhkan pendekatan yang lebih komprehensif.

Selain itu, munculnya *Large Language Models* (LLMs) seperti **ChatGPT** menghadirkan alternatif, namun model-model ini, yang terutama dilatih pada teks bahasa alami (NL), belum tentu dioptimalkan untuk kompleksitas sintaks dan semantik yang spesifik dari kode sumber, sering kali menunjukkan kinerja yang lebih rendah dibandingkan model yang dirancang khusus.

::: tip Solusi yang Diusulkan
Studi ini memperkenalkan **JBLG** (*Joint Bi-directional LSTM and Graph Neural Networks*), arsitektur hibrida novel yang menggabungkan kekuatan **Bi-LSTM** (untuk dependensi sekuensial) dan **GNN** (untuk pemodelan struktural berbasis graf). Tujuannya adalah untuk memberikan solusi komprehensif dan sangat efektif untuk tugas pengambilan kode, mengatasi keterbatasan model individual dan mengungguli LLM umum seperti ChatGPT.
:::

## 2. Metodologi

Metodologi JBLG dirancang untuk secara simultan mengekstrak informasi sekuensial dan struktural dari kode sumber dan kueri, memfusi keduanya untuk representasi yang komprehensif.

### A. Input Encoding Layer

Kueri $Q = q_1, q_2, \dots, q_m$ dan *snippet* kode $C = c_1, c_2, \dots, c_n$ di-*tokenize* dan dipetakan ke vektor padat melalui lapisan *embedding* dengan *positional encoding* untuk mempertahankan urutan token.

$$ W_i^c=\text{Emb}(c_i); W_i^q=\text{Emb}(q_i) $$

### B. Joint Bi-LSTM-GNN Layer

1.  **Bi-LSTM Layer:** Menerapkan *Bi-LSTM* untuk memproses urutan *embedding* kueri dan kode dalam dua arah (maju $\vec{h}$ dan mundur $\overline{h}$). Ini menghasilkan representasi terkontekstualisasi yang menangkap dependensi sekuensial:
    $$ h_i^c=[\vec{h}_i^c;\overline{h}_i^c] $$
2.  **GNN Layer:** Kode sumber direpresentasikan sebagai graf (berdasarkan AST), di mana *node* adalah token dan *edge* adalah hubungan dependensi. Lapisan GNN (menggunakan *Graph Convolutional Layers*) secara iteratif memperbarui representasi *node* berdasarkan tetangga untuk menangkap informasi struktural.
    $$ h_v^{(l+1)}=\text{ReLU}(\sum_{u\in\mathcal{N}(v)}\frac{1}{\mathcal{N}(v)}W_c^{(l)}h_u^{(l)}) $$

### C. Attention Layer

Dua mekanisme atensi terpisah diterapkan untuk bobot dinamis:

1.  **Attention:** Digunakan untuk membobot pentingnya bagian kode yang berbeda untuk kueri.
    $$ a_i=\text{softmax}(f(q,h_i)) $$
2.  **Graph Attention:** Diterapkan pada representasi graf yang dipelajari oleh GNN untuk memfokuskan pada *node* penting dalam graf sehubungan dengan *embedding* kueri.
    $$ \vec{\beta}_i=\text{softmax}(\alpha^T h_i^g) $$

### D. Concatenation, MLP, dan Ranking

1.  **Concatenation Layer:** Output dari Bi-LSTM, GNN, dan bobot atensi digabungkan menjadi satu representasi komprehensif per *snippet* kode.
    $$ h_i=[h_i^f,h_i^b,h_i^g,\alpha_i,\beta_i] $$
2.  **Multi-Layer Perceptron (MLP):** MLP memproses representasi gabungan $h_i$ untuk memprediksi skor relevansi $\hat{y}_i$.
    $$ \hat{y}_i=\text{MLP}(h_i) $$
3.  **Similarity & Ranking:** Skor relevansi $\hat{y}_i$ digunakan sebagai skor kesamaan $s(q, x_i)$. *Snippet* kode kemudian diberi peringkat dalam urutan menurun berdasarkan skor ini.

## 3. Detail Pengujian

### Dataset
*   **CodeSearchNet:** Kumpulan data skala besar yang mencakup enam bahasa pemrograman (Java, Python, JavaScript, Ruby, Go, PHP) dengan total $\approx 4.5$ juta *snippet* pelatihan. Digunakan untuk evaluasi kinerja lintas-bahasa.
*   **CosBench (CB):** Terdiri dari 52 kueri terpilih dari StackOverflow dengan *ground truths* dan sejumlah besar *distractor code snippets* ($\approx 4.2$ juta). Digunakan untuk menguji kinerja pengambilan di dunia nyata.

### Baseline
*   **Bi-LSTM:** Model berbasis sekuensial.
*   **GNN:** Model berbasis graf.
*   **ChatGPT:** *Large Language Model* (LLM) (GPT-3.5 architecture) sebagai perbandingan model umum.
*   **DGMS:** (*Deep Graph Matching and Searching*) model *code search* berbasis GNN SOTA.

### Metrik Evaluasi
Enam metrik digunakan untuk penilaian yang komprehensif:

*   **Precision (P):**
    $$ \text{Precision} = \frac{\text{Number of relevant retrieved items}}{\text{Number of retrieved items}} $$
*   **Recall (R):**
    $$ \text{Recall} = \frac{\text{Number of relevant retrieved items}}{\text{Total number of relevant items}} $$
*   **F1-score:**
    $$ \text{F1-score} = \frac{2 \times (\text{Precision} \times \text{Recall})}{(\text{Precision} + \text{Recall})} $$
*   **Mean Reciprocal Rank (MRR):**
    $$ \text{MRR} = \frac{1}{\text{Total number of queries}} \times \sum \frac{1}{\text{Rank of first relevant item}} $$
*   **Normalized Discounted Cumulative Gain (NDCG):**
    $$ \text{NDCG}=\frac{\text{DCG}}{\text{IDCG}} \quad \text{where} \quad \text{DCG}=\sum \frac{(2^{\text{rel}_i}-1)}{\log_2(i+1)} $$
*   **Mean Average Precision (MAP):** Mengukur rata-rata presisi di semua level *recall* yang mungkin.

## 4. Hasil Eksperimen

### Perbandingan Kinerja Keseluruhan (CodeSearchNet)

| Model | P@10 | R@10 | F1-measure@10 | MRR | NDCG@10 | MAP |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Bi-LSTM | 0.6635 | 0.8318 | 0.7227 | 0.6635 | 0.8468 | 0.7332 |
| GNN | 0.6857 | 0.8477 | 0.7439 | 0.6857 | 0.8632 | 0.7587 |
| ChatGPT | 0.5543 | 0.7282 | 0.6118 | 0.5543 | 0.7585 | 0.6364 |
| DGMS | 0.7143 | 0.8586 | 0.7807 | 0.7143 | 0.8756 | 0.7843 |
| **JBLG** | **0.7932** | **0.8937** | **0.8313** | **0.7823** | **0.9153** | **0.8557** |

*   **JBLG secara konsisten mengungguli** semua model *baseline* dan ChatGPT di semua metrik.
*   JBLG mencapai MRR tertinggi ($\mathbf{0.7823}$), menunjukkan efisiensi tertinggi dalam memeringkat kode yang paling relevan.
*   **ChatGPT** menunjukkan **kinerja terendah** di semua metrik, menggarisbawahi kurangnya kesesuaiannya untuk tugas *code retrieval* yang spesifik.

### Analisis Bahasa Pemrograman (CodeSearchNet)
JBLG mempertahankan kinerja superior di seluruh enam bahasa pemrograman (Python, PHP, Java, JavaScript, Go, Ruby). Contoh:

*   **Python (MRR):** JBLG $\mathbf{0.8819}$ vs DGMS $\mathbf{0.8539}$ vs GNN $0.8402$ vs ChatGPT $0.7978$.
*   **Java (MRR):** JBLG $\mathbf{0.849}$ vs DGMS $\mathbf{0.793}$ vs GNN $0.763$ vs ChatGPT $0.638$.

### Analisis CosBench (CB) Dataset
Pada *dataset* yang lebih menantang ini, JBLG juga menunjukkan dominasi:

| Model | P@10 | R@10 | F1-measure@10 | MRR | NDCG@10 | MAP |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Bi-LSTM | 0.78 | 0.88 | 0.83 | 0.85 | 0.91 | 0.70 |
| DGMS | 0.80 | 0.89 | 0.84 | 0.86 | 0.90 | 0.80 |
| **JBLG** | **0.85** | **0.92** | **0.88** | **0.89** | **0.93** | **0.86** |

JBLG melampaui DGMS, menunjukkan presisi yang lebih tinggi (P@10 $\mathbf{0.85}$ vs $0.80$) dan MRR yang lebih baik ($\mathbf{0.89}$ vs $0.86$), membuktikan ketangguhannya dalam skenario kueri StackOverflow yang kompleks.

## 5. Kesimpulan

Studi ini memperkenalkan JBLG, sebuah model *Joint Bi-directional LSTM-GNN*, yang mengatasi masalah umum dalam *source code retrieval* dengan secara efektif mengintegrasikan penangkapan informasi sekuensial dan struktural kode. Evaluasi ekstensif pada *dataset* CodeSearchNet dan CosBench, termasuk perbandingan langsung dengan LLM umum ChatGPT, secara meyakinkan menunjukkan bahwa JBLG secara konsisten memberikan kinerja superior di semua metrik dan bahasa pemrograman. Kinerja JBLG yang unggul menyoroti pentingnya model yang dirancang khusus yang mampu menangani sintaks dan struktur kode yang spesifik, berbeda dengan LLM tujuan umum.

JBLG telah menunjukkan potensi besar dalam menangani skenario kompleks seperti pengambilan kode **lintas-bahasa** dan pengembalian yang akurat bahkan dengan **kueri tidak lengkap**, menjadikannya solusi yang sangat menjanjikan untuk aplikasi rekayasa perangkat lunak di dunia nyata.

::: info Dampak Praktis
Model JBLG mewakili langkah maju yang signifikan untuk pengambilan kode sumber, menawarkan peningkatan akurasi dan efisiensi yang substansial. Potensinya mencakup peningkatan produktivitas pengembang, karena mampu memberikan *snippet* kode yang sangat relevan secara andal. Arah penelitian di masa depan melibatkan eksplorasi mekanisme *attention* yang lebih canggih dan memperluas penerapan JBLG untuk tugas rekayasa perangkat lunak lainnya seperti **code summarization** (mengadaptasi JBLG menjadi arsitektur *sequence-to-sequence*) dan **code completion**.
:::