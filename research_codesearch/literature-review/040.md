---
title: Review Paper - GNEM Pembelajaran Kemiripan Komprehensif dengan Model Ensemble untuk Code Search
description: Rangkuman paper tentang kerangka kerja GNEM untuk meningkatkan akurasi pencarian kode melalui ensemble model dan pembelajaran kemiripan (IEEE Access, 2024).
head:
  - - meta
    - name: keywords
      content: Code Search, Ensemble model, Similarity learning, Contrastive Learning, Graph Neural Network, Attention Mechanism, Feature Fusion
---

# 040 - Comprehensive Similarity Learning With Ensemble Model for Code Search
Tautan (DOI) [10.1109/ACCESS.2024.3475730]

**Penulis:** **Jiali Zeng** ᵃ, **Bo Liu** ᵃ*, **Shuanghua Zhang** ᵇ, **Qiongzheng Lin** ᵃ, **Zhanyong Zhang** ᵃ, **Xinfu Yang** ᵃ

**Afiliasi:**
* ᵃ School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan 411201, China
* ᵇ School of Computer Science and Engineering, Central South University, Changsha 410075, China

**Kronologi:** Received: 29 September 2024 • Accepted: 28 October 2024 • Available Online: 7 November 2024

<a href="https://www.scimagojr.com/journalsearch.php?q=21100374601&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21100374601" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** IEEE Access, Volume 12, pp. 151528-151539 (2024)<br>• **Topik:** Peningkatan akurasi *code search* dengan mengatasi kegagalan model *single-view* dan *multi-view* yang ada dalam menangkap kemiripan dari berbagai sudut pandang (perspektif *ensemble*).<br><br>**Masalah & Solusi:**<br>• **Masalah 1 (Keterbatasan *Single-View*):** Model *code search* yang ada gagal mengekstrak fitur yang cukup komprehensif dari kode (misalnya, *code structure* dan *semantic intent*), sehingga model *single-view* cenderung memiliki akurasi yang suboptimal.<br>• **Masalah 2 (Redundansi *Multi-View*):** Meskipun model *multi-view* mencoba mengatasi ini, mereka sering gagal menyusun *trade-off* antara akurasi dan keragaman model. Representasi yang diperoleh dari *encoders* yang berbeda mungkin memiliki **redundansi** yang signifikan, yang membatasi peningkatan kinerja *ensemble*.<br>• **Solusi:** Mengusulkan **GNEM** (*Generative and Non-Generative Ensemble Model*), sebuah kerangka kerja *ensemble* heterogen dengan tiga modul yang berfokus pada **Pembelajaran Kemiripan Komprehensif**:<br>   (1) **Pengodean Multi-View:** Menggunakan *encoders* berbeda (GNN, BiLSTM, Transformer) untuk keragaman fitur.<br>   (2) **Pembelajaran Kemiripan:** Menggunakan **Attention Mechanism** untuk menangkap korelasi *cross-modal* dan **Contrastive Learning** (InfoNCE Loss) untuk meningkatkan kemampuan diskriminatif.<br>   (3) **Fusi Keputusan Heterogen:** Menggunakan teknik *stacking ensemble* (MLP) untuk menggabungkan skor kemiripan dari model *encoder* yang berbeda (Graph-based, Sequential-based, dan Transformer-based) untuk keputusan akhir.<br><br>**Contoh Penerapan:**<br>• Diuji pada dua dataset: **CodeSearchNet** (6 bahasa) dan **CosBench** (kueri StackOverflow).<br>• **Pencarian Kode Semantik:** Digunakan untuk memeringkatkan *snippet* kode terhadap kueri bahasa alami, menunjukkan bahwa kombinasi keputusan dari model yang memiliki perspektif berbeda (graf, urutan, konteks) memberikan skor paling akurat.<br><br>**Metodologi:**<br>• **Arsitektur Ensemble:** GNEM terdiri dari *encoders* heterogen: (1) **Graph Neural Network (GNN)**, (2) **Bidirectional LSTM (BiLSTM)**, dan (3) **Transformer** (menggunakan *Attention Mechanism*).<br>• **Encoder Multi-View:** Setiap *encoder* fokus pada aspek unik kode: **GNN** (struktur), **BiLSTM** (urutan), dan **Transformer** (konteks global).<br>• **Similarity Learning:** Setiap *encoder* menggunakan mekanisme *Attention* untuk memodelkan hubungan *cross-modal* antara kueri dan kode. *Loss function* utama adalah **InfoNCE Loss** untuk memastikan vektor yang relevan lebih dekat daripada yang tidak relevan.<br>$$\mathcal{L}=-\log\frac{\exp(s(q,c_{p})/\tau)}{\exp(s(q,c_{p})/\tau)+\sum_{j=1}^{K}\exp(s(q,c_{n_{j}})/\tau)}$$<br>• **Fusi Keputusan (Stacking Ensemble):** Skor kemiripan dari output masing-masing *encoder* digabungkan oleh *Meta-Learner* (**MLP**) untuk menghasilkan skor prediksi akhir. Strategi ini diklaim lebih baik daripada fusi fitur di tingkat *embedding*.<br><br>**Temuan Kunci:**<br>1. **Kinerja SOTA:** GNEM secara konsisten mencapai MRR tertinggi (MRR rata-rata **0.803** pada CSN) dibandingkan dengan semua *baseline* SOTA, melampaui MoCoCS, UniXcoder, dan CoCoSoDa.<br>2. **Peran Ensemble Heterogen:** Hasil membuktikan bahwa *ensemble* heterogen (GNN + BiLSTM + Transformer) mengungguli *ensemble* homogen, karena keragaman fitur yang ditangkap memberikan peningkatan kinerja yang lebih besar (*gains*) dalam proses fusi keputusan.<br>3. **Fusi Keputusan Superior:** Strategi *stacking ensemble* (*fusion* di tingkat skor keputusan) lebih efektif dalam model GNEM daripada fusi di tingkat fitur/vektor, mencapai MRR $\mathbf{0.803}$.<br>4. **Kontribusi GNN:** GNN (menangkap struktur) memberikan kontribusi yang sangat signifikan dalam *ensemble*, membuktikan pentingnya fitur struktural kode dalam pembelajaran kemiripan komprehensif.<br><br>**Kontribusi Utama:**<br>• Mengusulkan **GNEM**, kerangka kerja *ensemble* heterogen pertama yang menggabungkan *encoders* berbeda (Graph, Sequential, Transformer) untuk *code search*.<br>• Menerapkan **Pembelajaran Kemiripan Komprehensif** yang menggunakan *multi-view* dan *contrastive learning* InfoNCE untuk meningkatkan kemampuan diskriminatif model.<br>• Membuktikan efektivitas strategi *stacking ensemble* (fusi keputusan) untuk model *code search* multi-modal.<br><br>**Dampak:**<br>• GNEM menyediakan metode yang paling akurat dan andal untuk *code search* saat ini, membantu pengembang menemukan kode yang tepat dengan lebih cepat, karena keputusan *ensemble* sangat mengurangi kemungkinan *false positive* atau *false negative* dari model tunggal. |

## 1. Pendahuluan & Masalah

Pencarian kode adalah tugas fundamental yang bertujuan untuk mengambil *snippet* kode yang relevan dengan kueri bahasa alami (NL) dari repositori yang luas. Meskipun model *deep learning* telah menunjukkan kinerja yang signifikan, mereka memiliki keterbatasan: model *single-view* (misalnya, yang hanya menggunakan token) seringkali kehilangan informasi struktural dan semantik yang komprehensif, menghasilkan akurasi suboptimal.

Model *multi-view* dikembangkan untuk mengatasi masalah ini dengan mengekstrak fitur dari berbagai modalitas (Token, AST, Data Flow Graph). Namun, model *multi-view* yang ada seringkali menghadapi tantangan dalam **redundansi fitur** dan **penyusunan *trade-off*** antara akurasi dan keragaman model yang optimal. Keragaman model sangat penting untuk memastikan bahwa setiap *encoder* membawa perspektif yang unik, yang pada akhirnya akan meningkatkan kualitas *fusion* (penggabungan) dan keputusan *ensemble*.

::: tip Solusi yang Diusulkan
Paper ini mengusulkan **GNEM** (*Generative and Non-Generative Ensemble Model*), sebuah kerangka kerja *ensemble* heterogen yang bertujuan untuk **Pembelajaran Kemiripan Komprehensif** dengan secara eksplisit mengatasi keragaman model. GNEM menggabungkan *encoders* dari tiga arsitektur yang berbeda (GNN, Bi-LSTM, Transformer) dan memfusi keputusan mereka melalui *stacking ensemble* (MLP) untuk mencapai akurasi *code search* SOTA.
:::

## 2. Metodologi

Kerangka kerja GNEM dirancang untuk mengintegrasikan berbagai sumber pembelajaran kemiripan yang berbeda dan memadukannya pada tingkat keputusan.

### A. Arsitektur Encoder Heterogen

GNEM menggunakan tiga *encoders* yang berbeda, masing-masing memiliki kemampuan ekstraksi fitur yang unik:
1.  **Graph Neural Network (GNN):** Efektif dalam menangkap informasi **struktural** kode (misalnya, AST atau DFG).
2.  **Bidirectional LSTM (BiLSTM):** Efektif dalam menangkap dependensi **sekuensial** dan temporal.
3.  **Transformer (Attention Mechanism):** Efektif dalam menangkap hubungan **kontekstual global** antara token.

Setiap *encoder* menerima input yang sama (kueri dan kode) dan menghasilkan representasi semantik.

### B. Similarity Learning dan Contrastive Loss

Untuk memastikan bahwa setiap *encoder* memiliki kemampuan diskriminatif yang kuat, **Contrastive Learning (CL)** diterapkan. *Loss function* yang digunakan adalah **InfoNCE Loss** (berbeda dengan *triplet loss*), yang dirancang untuk tugas diskriminasi berskala besar.
$$\mathcal{L}=-\log\frac{\exp(s(q,c_{p})/\tau)}{\exp(s(q,c_{p})/\tau)+\sum_{j=1}^{K}\exp(s(q,c_{n_{j}})/\tau)}$$
CL diterapkan pada setiap *encoder* secara independen, menarik representasi vektor kueri ($q$) dan kode positif ($c_p$) berdekatan, sementara mendorong negatif ($c_{n_j}$) menjauh dalam ruang *embedding* yang relevan.

### C. Fusi Keputusan (Stacking Ensemble)

Alih-alih menggabungkan representasi vektor dari ketiga *encoder* (fusi tingkat fitur/vektor), GNEM menggunakan strategi **fusi keputusan** (*stacking ensemble*).
1.  **Skor Kemiripan Individu:** Setiap *encoder* menghitung skor kemiripan ($s_1, s_2, s_3$) untuk pasangan kueri-kode yang sama.
2.  **Meta-Learner:** Skor kemiripan ini menjadi masukan fitur bagi **Meta-Learner**, yang diimplementasikan sebagai **Multi-Layer Perceptron (MLP)**.
3.  **Keputusan Akhir:** MLP dilatih untuk memprediksi probabilitas kecocokan akhir, yang secara efektif belajar bagaimana **menimbang dan menggabungkan keputusan** dari *encoders* yang berbeda, mengambil manfaat dari keragaman perspektif mereka.

## 3. Detail Pengujian

### Dataset
* **CodeSearchNet (CSN):** Dataset utama yang mencakup enam bahasa (Python, Java, JavaScript, PHP, Ruby, Go).
* **CosBench:** Dataset tambahan yang lebih fokus pada kueri StackOverflow.

### Baseline
Model dibandingkan dengan *baseline* berbasis CL SOTA terbaru, termasuk **MoCoCS**, **UniXcoder**, **CoCoSoDa**, **GraphCodeBERT**, dan **CodeRetriever**.

### Metrik Evaluasi
Metrik utama yang digunakan adalah **Mean Reciprocal Rank (MRR)**.
$$MRR=\frac{1}{|Q|}\sum_{j=1}^{|Q|}\frac{1}{Rank_{j}}$$

## 4. Hasil Eksperimen

### RQ1: Kinerja Ensemble Heterogen
GNEM mencapai kinerja *code search* terbaik.

| Model | MRR Rata-rata (CSN) | Peningkatan vs. MoCoCS |
| :--- | :--- | :--- |
| MoCoCS | 0.771 | - |
| UniXcoder | 0.765 | - |
| CoCoSoDa | 0.775 | - |
| **GNEM** | **0.803** | **+4.15%** |

**Analisis:** GNEM melampaui *baseline* SOTA seperti MoCoCS dan CoCoSoDa, memvalidasi efektivitas kerangka *ensemble* dalam Pembelajaran Kemiripan Komprehensif.

### RQ2: Keunggulan Fusi Keputusan

Eksperimen membuktikan bahwa *stacking ensemble* (**fusi keputusan**) lebih unggul daripada fusi pada tingkat fitur/vektor:
* Fusi Keputusan (GNEM) $\rightarrow \mathbf{0.803}$ MRR.
* Fusi Vektor di tingkat fitur $\rightarrow \mathbf{0.785}$ MRR.

Ini mengonfirmasi bahwa Meta-Learner (MLP) mampu belajar pola penimbangan keputusan yang lebih diskriminatif daripada sekadar menggabungkan vektor fitur mentah.

### RQ3: Kontribusi Struktural
Studi ablasi mengonfirmasi bahwa **GNN** (modalitas struktural) memberikan kontribusi yang sangat penting, menunjukkan bahwa integrasi fitur struktural dalam *ensemble* secara signifikan meningkatkan akurasi *code search*.

## 5. Kesimpulan

GNEM adalah kerangka kerja *ensemble* heterogen yang inovatif untuk *code search* yang secara efektif menggabungkan *encoders* GNN, Bi-LSTM, dan Transformer. Dengan menggunakan *Contrastive Learning* untuk melatih setiap *encoder* dan *stacking ensemble* (MLP) untuk fusi keputusan, GNEM berhasil mengatasi redundansi fitur dan mencapai kinerja *state-of-the-art* baru.

::: info Dampak Praktis
GNEM menawarkan solusi *code search* yang **paling akurat** dan **andal** saat ini. Kerangka ini dapat diadopsi untuk meningkatkan kualitas *retrieval* pada sistem *code search* skala besar, di mana keputusan *ensemble* dari model yang beragam dapat secara signifikan mengurangi *false positives* dan *false negatives*, yang pada akhirnya meningkatkan produktivitas pengembang.
:::