---
title: Review Paper - Survei Pencarian Kode Berbasis Pembelajaran Mendalam
description: Rangkuman survei komprehensif mengenai metode pencarian kode berbasis Deep Learning, taksonomi, dan arah penelitian di masa depan (ACM Trans. Softw. Eng. Methodol., 2023).
head:
  - - meta
    - name: keywords
      content: code search, deep learning, code intelligence, pre-training, query representation, code vectorization
---

# 043 - Survey of Code Search Based on Deep Learning
Tautan (DOI) [https://doi.org/10.1145/3628161]

**Penulis:** **Yutao Xie** ᵃᵇ, **Jiayi Lin** ᵇ*, **Hande Dong** ᵇ, **Lei Zhang** ᵇ, **Zhonghai Wu** ᵃ

**Afiliasi:**
* ᵃ Peking University & International Digital Economy Academy, China
* ᵇ International Digital Economy Academy, China

**Kronologi:** Received: 6 April 2023 • Revised: 20 Juli 2023 • Accepted: 13 September 2023 • Available Online: Desember 2023

<a href="https://www.scimagojr.com/journalsearch.php?q=18121&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=18121" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 33, No. 2, Article 54 (2023)<br>• **Topik:** Survei komprehensif mengenai **Deep Learning (DL)** sebagai paradigma terkemuka untuk tugas *Natural Language to Code Search* (NL-to-Code), mengulas taksonomi baru dan tantangan terbuka.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Meskipun DL telah mendominasi *code search*, belum ada tinjauan yang terorganisir dan mendalam tentang bagaimana DL diterapkan secara sistematis dalam proses pencarian kode, mencakup pemodelan kueri, kode, dan pemadanan. *Code search* tradisional berbasis *Information Retrieval* (IR) tidak memadai karena jurang semantik antara bahasa alami dan bahasa pemrograman.<br>• **Solusi:** Menyajikan taksonomi baru yang membagi DL-based *code search* menjadi proses tiga langkah: **1) Pemodelan Semantik Kueri (Query Semantics Modeling)**, **2) Pemodelan Semantik Kode (Code Semantics Modeling)**, dan **3) Pemodelan Pemadanan (Matching Modeling)**, yang mencakup pelatihan model. Survei ini mengumpulkan 64 makalah relevan sejak 2018.<br><br>**Contoh Penerapan:**<br>• Metode DL digunakan untuk memetakan kueri bahasa alami (NL) seperti "get the maximum value" dan *snippet* kode Python ke dalam ruang vektor dimensi tinggi. Kedekatan vektor (misalnya, *Cosine Similarity*) menentukan relevansi hasil pencarian.<br><br>**Metodologi:**<br>• **Kerangka Kerja DL:** Model *Dual Encoder* yang dilatih pada korpus paralel $\langle \mathbf{q}, \mathbf{c}^{+}, \mathbf{c}^{-} \rangle$ untuk meminimalkan *Triplet Sorting Loss*:<br>$$\mathcal{L}(\mathbf{q},\mathbf{c}^{+},\mathbf{c}^{-})=\max\left(0, \delta-s(\mathbf{q},\mathbf{c}^{+})+s(\mathbf{q},\mathbf{c}^{-})\right)$$<br>• **Taksonomi Baru:**<br>  - **Pemodelan Kueri:** Mencakup representasi kueri (menggunakan RNN, LSTM, Transformer) dan peningkatannya (*reformulation* berdasarkan API, *co-occurring terms*, *search logs*).<br>  - **Pemodelan Kode:** Mencakup representasi (STS, MTS, FTS, *Tree/Graph*) dan vektorisasi (Word Embedding, RNN, GNN, **Transformer**).<br>  - **Pemodelan Pemadanan:** Mencakup *pre-training* (MLM, RTD, EP, IP) dan *fine-tuning* (Point-wise, Pair-wise, **List-wise/InfoNCE Loss**).<br><br>**Temuan Kunci:**<br>1. **Kode Encoder Dominan:** Arsitektur **Transformer** adalah *encoder* kode yang paling populer (21 dari 64 makalah), mengungguli RNN dan GNN, sebagian besar karena keberhasilan model *pre-training* skala besar.<br>2. **Representasi Kode Utama:** *Source Code Token Sequence* (STS) adalah representasi kode yang paling umum digunakan.<br>3. **Loss Function Populer:** Pelatihan *List-wise* (menggunakan *InfoNCE Loss* dan *Batch Negative Sampling*) adalah strategi *fine-tuning* yang paling populer dan efektif.<br>4. **Metrik Utama:** $\mathbf{MRR@k}$ adalah metrik evaluasi yang paling sering digunakan (90.6% kasus), diikuti oleh $\mathbf{SuccessRate@k}$.<br>5. **Dataset Utama:** **CodeSearchNet (CSN)** adalah *dataset* yang paling dominan digunakan untuk evaluasi.<br><br>**Kontribusi Utama:**<br>• Menyediakan taksonomi baru dan terorganisir untuk klasifikasi metode *deep code search* yang berfokus pada tiga komponen kunci.<br>• Menganalisis dan merangkum 64 makalah DL-based *code search* berkualitas tinggi yang diterbitkan antara 2018–2023.<br>• Mengidentifikasi tantangan terbuka (misalnya, *over-reliance* pada *identifier*, kurangnya *graph pre-training*, kebutuhan *dataset* berkualitas tinggi) dan 12 arah penelitian di masa depan.<br><br>**Dampak:**<br>• Menjadi panduan komprehensif bagi peneliti dan praktisi industri yang baru dalam bidang ini, membantu mereka memahami fondasi, kemajuan terkini, dan peluang riset di bidang *deep code search*. |

## 1. Pendahuluan & Masalah

Pemrograman, meskipun merupakan upaya kreatif, juga memiliki aspek yang **repetitif dan dapat diprediksi**. Teknik *code intelligence*, termasuk *code search*, dikembangkan untuk meningkatkan produktivitas pengembang. *Code search* (khususnya NL-to-Code *search*) bertujuan untuk mengambil fragmen kode yang relevan dengan kueri bahasa alami dari korpus kode yang besar.

Secara historis, mesin *code search* menggunakan teknologi *Information Retrieval* (IR) tradisional, memperlakukan kode sumber sebagai teks murni dan mencari berdasarkan kecocokan kata kunci. Metode ini memiliki kelemahan signifikan karena perbedaan besar antara bahasa pemrograman dan bahasa alami, yang menyebabkan kegagalan dalam memahami semantik tingkat tinggi.

**Pembelajaran Mendalam (Deep Learning, DL)** telah merevolusi *code search* dengan kemampuan luar biasanya untuk mengekstrak representasi semantik tingkat tinggi. DL telah menjadi paradigma terdepan di bidang ini.

::: tip Solusi yang Diusulkan
Survei ini memberikan tinjauan terstruktur dan komprehensif mengenai *code search* berbasis DL, mengusulkan **taksonomi baru** tiga langkah (Pemodelan Kueri, Pemodelan Kode, dan Pemodelan Pemadanan) untuk menganalisis perkembangan mutakhir dan mengidentifikasi 12 arah penelitian yang menjanjikan di masa depan.
:::

## 2. Metodologi

DL-based *code search* beroperasi dalam kerangka kerja umum: mengkodekan kueri ($\mathbf{q}$) dan kode ($\mathbf{c}$) menjadi vektor dimensi tinggi, dan mengukur kesamaannya, biasanya menggunakan *Cosine Similarity* ($s(\mathbf{q},\mathbf{c})=\frac{\mathbf{q}^{T}\cdot \mathbf{c}}{||\mathbf{q}||\cdot||\mathbf{c}||}$). Model dilatih untuk meminimalkan *Triplet Sorting Loss* pada triplet $\langle \mathbf{q},\mathbf{c}^{+},\mathbf{c}^{-} \rangle$.

### A. Query Representation and Enhancement (RQ1)

Akurasi *code search* sangat bergantung pada pemahaman yang tepat terhadap **niat kueri** pengguna.
*   **Representasi Kueri:** Kueri di-*tokenize* dan di-*embed* menjadi vektor menggunakan arsitektur seperti **RNN, LSTM, GNN, atau Transformer**. Komentar kode sering digunakan sebagai kueri dalam pelatihan karena sulitnya mendapatkan pasangan (kueri pengguna, kode) yang nyata.
*   **Peningkatan Kueri (*Enhancement*):** Mengatasi kueri yang pendek dan ambigu melalui **reformulation** otomatis. Metode utamanya meliputi:
    *   **Berdasarkan API atau Nama Kelas:** Memperkaya kueri dengan pengenal (*identifier*) yang relevan secara semantik yang diekstrak dari sumber seperti Stack Overflow atau GitHub (misalnya, RACK, NLP2API).
    *   **Berdasarkan *Co-occurring Terms***: Mengidentifikasi kata kunci yang sering muncul bersama kueri (misalnya, NQE).
    *   **Berdasarkan *Query Generation***: Menghasilkan kueri yang lebih kaya semantik (misalnya, QueCos, ZaCQ).

### B. Code Representation and Vectorization (RQ2)

Untuk menjembatani jurang semantik, pemahaman kode harus diperdalam.
*   **Representasi Kode:** Kode sumber dapat diwakili dalam berbagai modalitas:
    *   *Source Code Token Sequence* (STS), *Feature Token Sequence* (FTS), atau *Multimodal Token Sequence* (MTS).
    *   Struktur berbasis graf/pohon seperti *Abstract Syntax Tree* (**AST**), *Control Flow Graph* (**CFG**), *Data Flow Graph* (**DFG**), dan *Program Transformation* (**PT**).
*   **Vektorisasi Kode:** Pilihan arsitektur *encoder* bergantung pada jenis representasi kode:
    *   **Word Embedding:** (Word2Vec, FastText) untuk STS.
    *   **RNN/LSTM:** Untuk mengkodekan urutan token.
    *   **GNN/RGCN:** Untuk mengkodekan struktur graf (misalnya, CFG atau DFG).
    *   **Transformer:** Arsitektur yang paling populer, membentuk dasar model *pre-training* seperti **CodeBERT** dan **GraphCodeBERT**.

### C. Training Method (RQ3)

Melatih parameter model ($\theta$) merupakan langkah penting.

1.  **Pre-training Model Besar:**
    *   **Tugas Urutan (*Sequence Tasks*):** *Masked Language Model* (**MLM**), *Replaced Token Detection* (RTD), *Unidirectional Language Modeling* (ULM), *DeNoiSing* (DNS).
    *   **Tugas Struktur Kode:** *Edge Prediction* (EP), *Identifier Prediction* (IP), *Identifier Content Prediction* (ICP).
    *   **Tugas Pemadanan Multi-modal:** *Multi-Modal Matching Prediction* (MMP), *Multi-modal Concatenation Contrastive Learning* (MCCL), *Cross Modal Generation* (CMG). MLM adalah tugas *pre-training* yang paling dasar dan efektif.

2.  **Pelatihan/Fine-tuning Model *Code Search*:**
    *   **Model Diskriminatif:** Paling umum digunakan, dikategorikan berdasarkan tujuan optimasi:
        *   **Point-wise:** Klasifikasi biner (cocok/tidak cocok).
        *   **Pair-wise:** Memaksimalkan margin antara pasangan positif dan negatif dengan *Hinge Loss* (paling umum sebelum munculnya *List-wise*).
        *   **List-wise:** Mengoptimalkan peringkat pasangan positif dalam urutan sampel negatif (*batch*), menggunakan **InfoNCE Loss** (strategi paling populer saat ini).
    *   **Model Generatif:** Menggunakan *Variational Auto-Encoder* (VAE) bimodal dengan *Cross-modal Regularization Term* untuk menyatukan representasi kueri dan kode dalam ruang laten.

## 3. Detail Pengujian

### Dataset
*   **Sumber Data Utama:** GitHub, Stack Overflow (SO), dan *search engine logs* (Bing).
*   **Bahasa Utama:** **Python** dan **Java**.
*   **Dataset Dominan:** **CodeSearchNet (CSN)**, terdiri dari 6 juta sampel (dokumentasi, fungsi) dari 6 bahasa pemrograman.

### Metrik Evaluasi

Metrik mengukur kemampuan model mengambil *snippet* kode yang relevan dari *codebase*.

*   **Precision@k:** Rata-rata proporsi hasil Top k yang benar.
$$Precision@k=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{|Hit@k(q_{i})|}{k}$$
*   **Recall@k:** Rata-rata persentase jawaban benar yang berhasil ditemukan.
$$Recall@k=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{|Hit@k(q_{i})|}{|G_{i}|}$$
*   **F1-Score:** Rata-rata harmonik *Precision* dan *Recall*.
$$F1-Score=\frac{2\cdot Precision\cdot Recall}{Precision+Recall}$$
*   **Mean Average Precision (MAP@k):** Mengukur presisi rata-rata peringkat untuk semua kueri.
$$MAP@k=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{m}\sum_{j=1}^{m}\frac{j}{rank(hit_{j},Top@k(q_{i}))}$$
*   **Mean Reciprocal Rank (MRR@k):** Paling banyak digunakan; mengukur rata-rata kebalikan peringkat jawaban benar pertama.
$$MRR@k=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{rank(hit_{1},Top@k(q_{i}))}$$
*   **Frank@k, SuccessRate@k, Normalized Discounted Cumulative Gain (NDCG)**: Metrik tambahan yang juga digunakan.

## 4. Hasil Eksperimen

(Ringkasan hasil kualitatif dari analisis survei):

*   **Pemodelan Kueri:** Reformulasi kueri berdasarkan **API atau nama kelas** adalah metode yang paling populer untuk meningkatkan niat kueri pengguna.
*   **Pemodelan Kode:**
    *   **Representasi:** **STS** (Source Code Token Sequence) adalah representasi yang paling sering digunakan, meskipun modalitas lain (AST, CFG, DFG) terbukti melengkapi dan meningkatkan pemahaman semantik.
    *   **Vektorisasi:** **Transformer** adalah *encoder* kode yang paling populer (21/64), menggarisbawahi keunggulan model *pre-training* besar.
*   **Pelatihan Model:** *Masked Language Model* (**MLM**) adalah tugas *pre-training* yang paling umum. Untuk *fine-tuning*, strategi **List-wise** (*InfoNCE Loss*) adalah yang paling efektif dan dominan.
*   **Evaluasi:** **CSN** adalah *dataset* yang paling sering dievaluasi, dan **MRR@k** adalah metrik evaluasi yang paling umum.

## 5. Kesimpulan

Survei ini mengkonfirmasi dominasi DL dalam *code search* dan menyajikan kerangka terstruktur (Pemodelan Kueri, Kode, dan Pemadanan) untuk menganalisis kemajuan. Arsitektur **Transformer** yang didukung oleh *pre-training* telah menetapkan standar baru untuk kinerja.

Meskipun DL telah mencapai kesuksesan, masih ada tantangan signifikan:

1.  **Ketergantungan Pengenal (*Identifier*)**: Model DL terlalu bergantung pada nama fungsi/variabel, mengabaikan struktur kode yang mendefinisikan fungsi.
2.  **Keterbatasan Data**: Kurangnya *dataset* berlabel berkualitas tinggi yang konsisten dengan kueri pengguna nyata membatasi generalisasi model.
3.  **Potensi Graf Belum Tergali**: Metode berbasis GNN masih tertinggal di belakang Transformer karena kurangnya penelitian sistematis tentang teknologi *graph pre-training*.

::: info Dampak Praktis
Arah penelitian masa depan yang disarankan meliputi **Robust Optimization**, **Interpretability Research**, pengembangan **High-quality Datasets** yang mencerminkan kueri nyata, eksplorasi **Graph Pre-training**, dan pencarian **New Search Paradigms** (seperti yang diinspirasi oleh Copilot/ChatGPT) untuk menjamin relevansi *code search* di era model bahasa besar.
:::