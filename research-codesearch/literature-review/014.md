---
title: Review Paper - Augmentasi Data Berbasis Kunci dengan Curriculum Learning untuk Few-Shot Code Search
description: Rangkuman paper tentang Kerangka Augmentasi Data dengan Curriculum Learning untuk Few-Shot Code Search (Neural Computing and Applications, 2025).
head:
  - - meta
    - name: keywords
      content: Code search, Data augmentation, Curriculum learning, Few shot learning, domain-specific languages
---

# 014 - Key-based data augmentation with curriculum learning for few-shot code search
[https://doi.org/10.1007/s00521-024-10670-9]

**Penulis:** **Fan Zhang** ¹'²*, **Manman Peng** ¹*, **Qiang Wu** ¹, **Yuanyuan Shen** ¹

**Afiliasi:**
* ¹ College of Computer Science and Electronic Engineering, Hunan University, Lushan South Road, Changsha 410082, Hunan Province, China
* ² Hunan Provincial Key Laboratory of Blockchain Infrastructure and Application, Hunan University, Lushan South Road, Changsha 410082, Hunan Province, China

**Kronologi:** Received: 26 September 2023 • Revised: 7 October 2024 • Accepted: 7 October 2024 • Available Online: 20 November 2024

<a href="https://www.scimagojr.com/journalsearch.php?q=24800&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=24800" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Neural Computing and Applications, Vol 37, No. 2, pp. 1475-1490 (2025)<br>• **Topik:** Peningkatan kinerja *Code Search* untuk bahasa pemrograman spesifik domain (*domain-specific*) dengan data pelatihan terbatas (*Few-Shot*).<br><br>**Masalah & Solusi:**<br>• **Masalah:** Metode *Code Search* yang ada dirancang untuk bahasa pemrograman *mainstream* (data pelatihan melimpah). Untuk bahasa *domain-specific* (misalnya, Solidity, SQL), data pelatihan sangat terbatas (*few-shot*), dan pelabelan data dalam jumlah besar sangat membebani. *Meta-learning* SOTA (*CDCS*) menghadapi masalah ketidakstabilan dan biaya komputasi tinggi (*second-order gradients*). Selain itu, *Data Augmentation* (*DA*) yang ada mengabaikan pernyataan kunci (*key statements*), yang dapat merusak semantik inti kode atau menyuntikkan *noise*.<br>• **Solusi:** Mengusulkan **DAFCS** (*Data Augmentation Framework with Curriculum Learning for Few-Shot Code Search*). DAFCS mengatasi kelangkaan data dengan: (1) **Mengumpulkan kode tak berlabel** untuk sinyal semantik tambahan. (2) Menggunakan metode **berbasis oklusi (*occlusion-based method*)** untuk mengidentifikasi **pernyataan kunci** (*key statements*). (3) Merancang operasi DA **berbasis kunci** (*key-based*) untuk menghasilkan sampel yang beragam dan bersih (melindungi semantik inti). (4) Menggunakan **Curriculum Learning** untuk menjadwalkan sampel yang diaugmentasi dari mudah ke sulit untuk pelatihan model yang optimal, menghindari kelemahan *MAML*.<br><br>**Contoh Penerapan:**<br>• **Code Search Few-Shot pada DSL:** DAFCS diuji pada dua bahasa *domain-specific* utama: **Solidity** (untuk *smart contract*) dan **SQL** (untuk basis data).<br>• **Kinerja Unggul:** DAFCS melampaui SOTA CDCS pada set data Solidity sebesar **5.42% MRR** dan pada set data SQL sebesar **5.05% MRR** (Rata-rata).<br><br>**Metodologi:**<br>• **Pengenalan Pernyataan Kunci (Key Statements):** Menggunakan model *teacher* yang dilatih pada korpus besar (*Python code search*) dan metode *occlusion-based* untuk menghitung skor kepentingan (*importance score*) setiap pernyataan. Pernyataan kunci adalah yang penghapusannya paling signifikan menurunkan skor kecocokan kode-kueri.<br>• **Augmentasi Berbasis Kunci:** Operasi DA dirancang untuk **melindungi** pernyataan kunci (untuk sampel positif: *Replacement, Deletion, Insertion*) dan **merusak** pernyataan kunci (untuk sampel negatif: *Replace Key Statements*). Operasi menggunakan pernyataan serupa/*dissimilar* dari kode tak berlabel yang dikumpulkan.<br>• **Curriculum Learning (Baby Step):** Menggunakan **Predefined Difficulty Measurer** berdasarkan kekuatan augmentasi $p$ (misalnya, $p_{\text{pos}}=\{15, 25, 35, 45\}$). Sampel yang diaugmentasi disusun dari mudah ke sulit, dan dijadwalkan secara bertahap bersama data asli (*few-shot*) untuk pelatihan model (*fine-tuning* GraphCodeBERT).<br><br>**Temuan Kunci:**<br>1. **Kinerja SOTA:** DAFCS mencapai MRR rata-rata 0.699 (Solidity) dan 0.832 (SQL), mengungguli CDCS secara signifikan.<br>2. **Kontribusi Komponen:** *Curriculum Training* adalah komponen yang paling penting (penurunan 22.5% MRR tanpa CT pada SQL), diikuti oleh *Key-based Augmentation* (penurunan 3.74% MRR), dan *Collecting Unlabeled Codes* (penurunan 1.46% MRR).<br>3. **Efisiensi:** DAFCS secara signifikan lebih cepat daripada CDCS, karena menghindari *meta-initialization* yang mahal dan *second-order gradients* dari MAML.<br><br>**Kontribusi Utama:**<br>• Kerangka DA baru (DAFCS) untuk *few-shot code search* yang menggunakan kode tak berlabel dan pengenalan pernyataan kunci.<br>• Memperkenalkan *Curriculum Learning* untuk penjadwalan sampel DA dalam konteks *few-shot code search*.<br>• Mengusulkan operasi augmentasi berbasis kunci yang melindungi/merusak semantik inti kode.<br><br>**Dampak:**<br>• Menyediakan solusi kinerja tinggi dan efisien untuk *Code Search* di bahasa *domain-specific* dengan data terbatas, mengurangi beban pelabelan data yang mahal. |

## 1. Pendahuluan & Masalah

*Code search* adalah tugas penting dalam rekayasa perangkat lunak yang bertujuan untuk menemukan fragmen kode yang cocok dengan kueri bahasa alami dari basis kode yang besar. Metode modern didominasi oleh teknik *deep learning* yang mengandalkan data pelatihan yang melimpah, khususnya untuk bahasa pemrograman *mainstream* seperti Java dan Python.

Namun, metode ini gagal dalam tugas *code search* untuk **bahasa pemrograman spesifik domain** (*domain-specific languages/DSL*), seperti Solidity dan SQL, karena data pelatihan yang tersedia sangat sedikit (*few-shot learning*). Melabeli sejumlah besar data untuk setiap DSL merupakan beban yang besar.

Pendekatan sebelumnya, seperti CDCS, menggunakan algoritma *meta-learning* MAML untuk mendapatkan inisialisasi parameter model yang baik. Akan tetapi, MAML terkenal dengan kelemahannya:
1.  **Ketidakstabilan:** Bergantung pada pembaruan *gradient multi-step* yang rentan terhadap *vanishing* atau *explosion*.
2.  **Biaya Komputasi Tinggi:** Memerlukan komputasi *second-order gradients* yang mahal dan kompleksitas *nested optimization*.

Sementara itu, meskipun *Data Augmentation* (DA) adalah solusi yang menjanjikan, metode DA kode yang ada: (1) tidak memanfaatkan kode tak berlabel yang tersedia di domain yang sama, dan (2) secara acak mengaugmentasi pernyataan, **mengabaikan pernyataan kunci**. Mengubah pernyataan kunci dapat merusak semantik inti kode, sedangkan mengaugmentasi pernyataan non-kunci dapat mengurangi generalisasi dan menyuntikkan *noise*.

::: tip Solusi yang Diusulkan
Kami mengusulkan **DAFCS** (*Data Augmentation Framework with Curriculum Learning for Few-Shot Code Search*). Kerangka ini memanfaatkan **kode tak berlabel** untuk keragaman semantik tambahan, mengidentifikasi **pernyataan kunci** untuk memastikan augmentasi yang bersih dan bermakna, dan menggunakan **Curriculum Learning** untuk menjadwalkan sampel yang diaugmentasi dari mudah ke sulit untuk pelatihan model yang efisien dan berkinerja tinggi.
:::

## 2. Metodologi

DAFCS terdiri dari empat langkah utama: Pengumpulan kode tak berlabel, pengenalan pernyataan kunci, augmentasi berbasis kunci, dan pelatihan *curriculum*.

### A. Collecting Unlabeled Codes

Untuk meningkatkan keragaman sampel yang diaugmentasi, DAFCS mengumpulkan fragmen kode tak berlabel ($N$) dalam bahasa pemrograman yang sama dari sumber seperti GitHub. Kode-kode ini dipecah menjadi pernyataan-pernyataan (menggunakan AST *parser*) dan digunakan di langkah selanjutnya untuk menyediakan sinyal tekstual dan semantik tambahan (pernyataan yang *semantically-similar* atau *dissimilar*) bagi kode asli yang *few-shot*.

### B. Recognize Key Statements

Pernyataan kunci didefinisikan sebagai pernyataan yang paling besar kontribusinya dalam menjaga hubungan kecocokan antara kueri dan kode. Pengenalan ini penting untuk: (1) **Melindungi semantik inti** (dengan tidak mengubah pernyataan kunci untuk sampel positif), dan (2) **Menghasilkan sampel yang bersih** (dengan mengubah pernyataan non-kunci yang kurang penting).

Kami menggunakan metode **Occlusion-Based** untuk mengidentifikasi pernyataan kunci.
1.  Model *teacher* ($T\_model$), dilatih pada korpus *code search* yang besar (misalnya, Python), digunakan untuk mengukur kepentingan.
2.  Untuk setiap pernyataan $s_i$ dalam kode $C$, skor kepentingan dihitung berdasarkan seberapa besar penghapusan $s_i$ mempengaruhi *cross-entropy loss* (CE) kecocokan kueri $Q$ dan kode yang dioklusikan ($c\_occ_i$):

$$Score(s_{i})=1-CE(T\_model(e(Q),e(c\_occ_{i}),1)$$

Pernyataan dengan $Score(s_i)$ yang lebih besar dianggap lebih penting.

### C. Key-based Code Augmentation

Berdasarkan pernyataan kunci, kami merancang operasi augmentasi untuk sampel positif (mempertahankan semantik) dan negatif (membalik semantik).

**Sampel Positif (Melindungi Semantik):** Hanya $p\%$ pernyataan **non-kunci** yang diubah.
*   **Key-based Replacement:** Mengganti pernyataan non-kunci dengan pernyataan *semantically-similar* dari kode tak berlabel.
*   **Key-based Deletion:** Menghapus pernyataan non-kunci.
*   **Key-based Insertion:** Menyisipkan pernyataan *semantically-similar* (terkait dengan pernyataan kunci) pada posisi acak.

**Sampel Negatif (Merusak Semantik):** Dibuat dengan merusak pernyataan kunci.
*   **Replace key statements:** Mengganti pernyataan **kunci** dan pernyataan non-kunci ($p\%$) dengan pernyataan **dissimilar** yang tidak relevan dari kode tak berlabel. Ini memaksa model untuk belajar fitur esensial yang membedakan hubungan kueri-kode.

### D. Curriculum Training

*Curriculum Learning* diterapkan untuk menjadwalkan sampel yang diaugmentasi dari mudah ke sulit, mengoptimalkan pelatihan model.

1.  **Difficulty Measurer:** Kami menggunakan **Predefined Difficulty Measurer** berdasarkan kekuatan augmentasi ($p$). Untuk sampel positif, $p$ yang lebih besar berarti lebih banyak perubahan $\rightarrow$ lebih sulit. Untuk sampel negatif, $p$ yang lebih besar berarti lebih banyak kehancuran $\rightarrow$ lebih mudah (karena hubungan kecocokan lebih jelas rusak).
    $$p_{\text{pos}}=\{15,25,35,45\}, p_{\text{neg}}=\{100,90,80,70\}$$
2.  **Training Scheduler (Baby Step):** Sampel yang diaugmentasi diurutkan berdasarkan kesulitan (mudah ke sulit), didistribusikan ke dalam *bucket*, dan dimasukkan secara bertahap bersama dengan data asli (*D\_origin*) untuk *fine-tuning* model *backbone* (GraphCodeBERT yang telah *fine-tuned* pada korpus *code search* Python yang besar). Data asli (*D\_origin*) diperlakukan sebagai data paling sederhana.

## 3. Detail Pengujian

### Dataset
Eksperimen dilakukan pada set data publik yang mencakup dua DSL: **SQL** dan **Solidity**. Set data dibagi menjadi subset *few-shot* dengan ukuran yang bervariasi (misalnya, 100, 500, 1000, hingga set lengkap).

| Language | Train | Valid | Test |
| :--- | :--- | :--- | :--- |
| **SQL** | 14000 | 2068 | 1000 |
| **Solidity** | 56976 | 4096 | 1000 |

### Baseline
*   **CDCS:** SOTA untuk *few-shot code search* (berbasis MAML).
*   **CodeBERT/GraphCodeBERT:** Model *pre-trained* yang di-*fine-tune* dengan data *few-shot* (representasi *deep learning*).
*   **nlpaug/SODA:** Metode *Data Augmentation* umum dan berbasis kode.

### Metrik Evaluasi
Kami menggunakan metrik standar untuk *code search*: MRR dan Recall@k.

*   **Mean Reciprocal Rank (MRR):**
$$MRR=\frac{1}{Q}\sum_{i=1}^{Q}\frac{1}{r_{i}}$$
Di mana $Q$ adalah jumlah kueri, dan $r_{i}$ adalah peringkat hasil kecocokan paling penting untuk kueri ke-$i$. MRR yang lebih tinggi menunjukkan kinerja yang lebih baik.

*   **Recall@k:** Mengukur frekuensi hasil yang paling relevan muncul di $k$ posisi teratas. Kami menggunakan $k=1$ dan $k=10$.
$$\text{Recall}@k = \frac{1}{Q}\sum_{i=1}^{Q}I(\text{rank}_{i}\le k)$$
Di mana $I(\cdot)$ adalah fungsi indikator.

## 4. Hasil Eksperimen

### RQ1: Efektivitas DAFCS

DAFCS secara konsisten mengungguli semua *baseline* di kedua set data (MRR rata-rata).

| Language | Method | MRR (AVG) | Recall@1 (AVG) | Recall@10 (AVG) |
| :--- | :--- | :--- | :--- | :--- |
| **SQL** | CDCS | 0.792 | 0.703 | 0.944 |
| | DAFCS | **0.832** | **0.751** | **0.961** |
| | **Peningkatan DAFCS** | **+5.05%** | **+6.82%** | **+1.80%** |
| **Solidity** | CDCS | 0.663 | 0.573 | 0.841 |
| | DAFCS | **0.699** | **0.618** | **0.855** |
| | **Peningkatan DAFCS** | **+5.42%** | **+7.85%** | **+1.66%** |

**Analisis:** DAFCS menetapkan SOTA baru untuk *few-shot code search*, menunjukkan bahwa kombinasi augmentasi berbasis kunci dan *curriculum learning* lebih unggul daripada pendekatan *meta-learning* MAML (CDCS) dan *fine-tuning* langsung (*CodeBERT, GraphCodeBERT*).

### RQ2: Kontribusi Komponen Kunci (MRR Rata-Rata)

| Language | DAFCS | w/o unlabeled codes | w/o key-based augmentation | w/o curriculum training |
| :--- | :--- | :--- | :--- | :--- |
| **SQL** | **0.832** | 0.820 (-1.46%) | 0.802 (-3.74%) | 0.679 (-22.5%) |
| **Solidity** | **0.699** | 0.683 (-2.34%) | 0.665 (-5.11%) | 0.614 (-13.8%) |

**Analisis:**
*   **Curriculum Training** adalah komponen yang paling penting, di mana tanpa CT, kinerja turun tajam (22.5% pada SQL). Ini memvalidasi pentingnya penjadwalan sampel dari mudah ke sulit.
*   **Key-based Augmentation** juga sangat penting (penurunan >3.7% MRR), membuktikan bahwa pengenalan pernyataan kunci menghasilkan sampel yang lebih bersih dan melindungi semantik inti kode.

### RQ4: Konsumsi Waktu (Waktu Pelatihan Rata-Rata Total)

| Language | CDCS (Total) | DAFCS (Total) |
| :--- | :--- | :--- |
| **SQL** | $77543.173s$ | **$13604.250s$** |
| **Solidity** | $78409.318s$ | **$24889.905s$** |

**Analisis:** Biaya waktu pelatihan DAFCS secara signifikan lebih rendah daripada CDCS (reduksi sekitar 65% - 80%). Ini disebabkan oleh penghindaran fase *meta-initialization* MAML yang sangat mahal. DAFCS menawarkan efisiensi waktu dan kinerja yang superior.

## 5. Kesimpulan

Kami mengusulkan DAFCS, kerangka *Data Augmentation* dan *Curriculum Learning* untuk tugas *few-shot code search*. DAFCS mengatasi tantangan data terbatas pada bahasa *domain-specific* dengan mengidentifikasi pernyataan kunci melalui metode berbasis oklusi dan menggunakan *curriculum learning* untuk menjadwalkan sampel yang diaugmentasi secara bijaksana. Hasil eksperimen membuktikan bahwa DAFCS secara signifikan melampaui SOTA CDCS (lebih dari 5% MRR pada Solidity dan SQL) dan jauh lebih efisien dalam hal waktu pelatihan.

::: info Dampak Praktis
DAFCS memberikan solusi *high-performance* dan **hemat biaya komputasi** untuk *code search* di domain yang kekurangan data. Dengan mengatasi kelemahan *MAML* dan mengoptimalkan kualitas sampel melalui augmentasi berbasis semantik inti, DAFCS sangat mengurangi kebutuhan akan pelabelan data yang ekstensif, mempercepat pengembangan alat *code search* untuk DSL.
:::