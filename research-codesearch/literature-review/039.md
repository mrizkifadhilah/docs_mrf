---
title: Review Paper - Code Search Berbasis Generative Adversarial Game
description: Rangkuman paper tentang metode code search berbasis strategi Generative Adversarial Game untuk representasi kode (Journal of Software, 2024).
head:
  - - meta
    - name: keywords
      content: code search, generative adversarial game, code representation, approximate sampling, GAN
---

# 039 - 基于生成对抗策略的代码搜索 (Code Search with Generative Adversarial Game)
Tautan (DOI) [10.13328/j.cnki.jos.007067](http://www.jos.org.cn/1000-9825/7067.htm)

**Penulis:** **张祥平** $^{1,2}$, **刘建勋** $^{1,2*}$, **扈海泽** $^{1,2}$, **刘益** $^{1,2}$ (ZHANG Xiang-Ping$^{1,2}$, LIU Jian-Xun$^{1,2*}$, HU Hai-Ze$^{1,2}$, LIU Yi$^{1,2}$)

**Afiliasi:**
* $^1$ Layanan Komputasi dan Teknologi Perangkat Lunak Baru Laboratorium Kunci Provinsi Hunan (Key Lab for Services Computing and Novel Software Technology (Hunan University of Science and Technology), Xiangtan 411201, China)
* $^2$ Fakultas Ilmu Komputer dan Teknik, Universitas Sains dan Teknologi Hunan (School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan 411201, China)

**Kronologi:** Received: 2023-01-25 • Revised: 2023-04-17 • Accepted: 2023-10-10 • Available Online: 2024-02-09

<a href="https://www.scimagojr.com/journalsearch.php?q=19913&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=19913" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** 软件学报 (Journal of Software), 2024, 35(12): 5382-5396<br>• **Fokus:** Mengatasi kurangnya pertimbangan terhadap **distribusi probabilitas relevansi nyata** antara kode dan deskripsi dalam model *code search* berbasis *deep learning*.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Metode *deep learning* yang ada (misalnya, DeepCS) mengandalkan *loss function* triplest (*triplet loss*) dan fitur yang diekstraksi model, mengabaikan **distribusi probabilitas korelasi** yang sebenarnya ada dalam *dataset* "kode-deskripsi".<br>• **Solusi:** Mengusulkan metode *code search* berbasis **Generative Adversarial Game (GAG)**. Metode ini mengintegrasikan **distribusi probabilitas relevansi** dari model probabilistik klasik dengan ekstraksi fitur dalam *Vector Space Model*. GAG menggunakan Generator dan Discriminator dalam pelatihan bergantian untuk: (1) Mengoptimalkan *Code Encoder* dan *Description Encoder* secara simultan. (2) Memaksa model untuk memperhatikan **perbedaan yang lebih halus** antara pasangan kode positif dan negatif yang sangat mirip.<br><br>**Contoh Penerapan:**<br>• Dievaluasi pada *dataset* publik Java skala besar (lebih dari 18 juta pasangan kode-deskripsi) yang digunakan oleh DeepCS.<br><br>**Metodologi:**<br>• **Ekstraksi Fitur:** Kode dipecah menjadi tiga bagian (Nama Metode, API Sequence, Token), yang masing-masing dienkode menggunakan RNN/MLP dan *maxpooling*. Deskripsi dienkode menggunakan RNN dan *maxpooling*. Hasilnya digabungkan menjadi vektor $\mathbf{c}$ dan $\mathbf{d}$.<br>• **GAN Framework:** Menggunakan strategi *minimax* antara **Generator (G)** dan **Discriminator (D)**. **D** adalah *cosine similarity* $f_{\phi}(\mathbf{d}, \mathbf{c}) = \cos(\mathbf{d}, \mathbf{c})$ diikuti oleh $\sigma$. **G** dimodelkan dengan strategi **Approximate Sampling** dari *dataset* alih-alih menghasilkan sekuens diskrit, menghindari masalah gradien pada teks. Fungsi utilitas G adalah $\log(1+\exp(f_{\phi}(\mathbf{d}, \mathbf{c})))$.<br>• **Temperature Control Mechanism ($\tau$):** Diperkenalkan untuk mengontrol fokus Generator, terutama pada sampel negatif yang paling dekat dengan sampel positif (ketika $\tau$ rendah).<br>• **Optimasi:** Menggunakan *Policy Gradient* untuk memperbarui Generator, dengan *reward* dari Discriminator.<br><br>**Temuan Kunci:**<br>1. **Kinerja SOTA:** Model yang diusulkan jauh melampaui DeepCS, CARLCS, dan SAN-CS di semua metrik. Peningkatan tertinggi (dibanding DeepCS): **Recall@10** ($+8.4\%$), **MRR@10** ($+32.5\%$), dan **NDCG@10** ($+24.3\%$).<br>2. **Peran Temperature:** Semakin rendah parameter $\tau$, semakin baik kinerja model, karena Generator fokus pada sampel negatif yang paling mendekati sampel nyata.<br>3. **Struktur Kode:** Kombinasi ketiga fitur (Nama Metode, API, Token) memberikan hasil terbaik. Secara individu, fitur Token memberikan kontribusi tertinggi (karena panjangnya), diikuti oleh Nama Metode (karena semantik fungsionalnya).<br><br>**Kontribusi Utama:**<br>• Pertama kali mengusulkan metode *code search* berdasarkan strategi **Generative Adversarial**.<br>• Menggabungkan distribusi probabilitas relevansi dengan ekstraksi fitur vektor.<br>• Mengusulkan **Approximate Sampling Strategy** dan **Temperature Control Mechanism** untuk mengatasi diskretisasi teks dan meningkatkan fokus Generator.<br><br>**Dampak:**<br>• Model ini menghasilkan representasi kode dan deskripsi yang berkualitas tinggi dengan mempertimbangkan distribusi data yang tersembunyi, secara signifikan meningkatkan akurasi dan metrik peringkat untuk tugas *code search*. |

## 1. Pendahuluan & Masalah

*Code search* adalah aktivitas rutin yang penting bagi pengembang perangkat lunak, secara signifikan meningkatkan efisiensi dan penggunaan ulang kode. Penelitian *code search* terbagi menjadi metode berbasis *Information Retrieval* (IR) dan metode berbasis *Deep Learning* (DL).

Metode IR berfokus pada pencocokan kata kunci di permukaan, gagal menjembatani **kesenjangan semantik** antara kueri bahasa alami dan kode sumber. Metode DL mengatasi hal ini dengan memetakan kueri dan kode ke dalam ruang vektor bersama (*Vector Space Model*) untuk mengukur kesamaan (seperti DeepCS, CARLCS, dan SAN-CS).

Meskipun model DL telah mencapai peningkatan, mereka memiliki kelemahan mendasar:
1.  **Mengabaikan Distribusi Probabilitas Relevansi:** Metode yang ada sangat bergantung pada kemampuan ekstraksi fitur jaringan saraf dan *loss function* triplest, mengabaikan **distribusi probabilitas korelasi nyata** ($p_{true}(\mathbf{c}|\mathbf{d}, r)$) yang ada antara kode ($\mathbf{c}$) dan deskripsi ($\mathbf{d}$) dalam *dataset*.
2.  **Keterbatasan Triplet Loss:** *Triplet loss* memiliki kecepatan konvergensi yang lambat dan rentan terhadap *overfitting* karena bergantung pada nilai *margin* ($\epsilon$) yang dipilih secara manual.

::: tip Solusi yang Diusulkan
Kami mengusulkan metode *code search* berbasis **Generative Adversarial Game (GAG)**. Metode ini mengintegrasikan distribusi probabilitas relevansi dari model probabilistik klasik dengan ekstraksi fitur dari *Vector Space Model*. GAG menggunakan Generator dan Discriminator dalam pelatihan bergantian dengan **Approximate Sampling** dan **Temperature Control** untuk mengoptimalkan *encoder* dan menghasilkan representasi berkualitas tinggi.
:::

## 2. Metodologi

Model GAG terdiri dari tiga bagian utama: (1) Ekstraksi Fitur Kode dan Deskripsi, (2) Strategi *Generative Adversarial*, dan (3) Pemanfaatan Hasil untuk *Code Search*.

### A. Ekstraksi Fitur Kode dan Deskripsi
Model GAG menggunakan arsitektur *encoder* yang mirip dengan DeepCS, mempertimbangkan **tiga aspek** kode:
*   **Nama Metode (M):** Dipecah dan dienkode menggunakan **RNN** dan **Maxpooling** ($\mathbf{m}$).
*   **API Sequence (A):** Diekstrak dan dienkode menggunakan **RNN** dan **Maxpooling** ($\mathbf{a}$).
*   **Token Sequence (T):** Diekstrak, dibersihkan (dihapus *stop-word* dan duplikat), dan dienkode menggunakan **MLP** dan **Maxpooling** ($\mathbf{t}$).
*   **Code Representation ($\mathbf{c}$):** Ketiga vektor fitur tersebut dijumlahkan, kemudian dilewatkan ke lapisan *Fully Connected*: $\mathbf{c} = \tanh(W^{\mathbf{C}}[\mathbf{m} + \mathbf{a} + \mathbf{t}])$.
*   **Description Representation ($\mathbf{d}$):** Deskripsi dienkode menggunakan **RNN** dan **Maxpooling** ($\mathbf{d}$).

### B. Strategi Generative Adversarial Game
Model GAG menggunakan strategi *minimax* antara Generator (G) dan Discriminator (D) untuk mengoptimalkan *encoder* kode dan deskripsi.

1.  **Discriminator ($f_{\phi}$):** Berfungsi sebagai *binary classifier* untuk membedakan sampel nyata (pasangan $\mathbf{c}, \mathbf{d}$) dan sampel palsu (dihasilkan G). D diimplementasikan sebagai **Cosine Similarity** antara $\mathbf{d}$ dan $\mathbf{c}$, yang kemudian dilewatkan ke fungsi $\sigma$:
    $$ D(\mathbf{c}|\mathbf{d}) = \sigma(f_{\phi}(\mathbf{d}, \mathbf{c})), \text{ di mana } f_{\phi}(\mathbf{d}, \mathbf{c})=\cos(\mathbf{d}, \mathbf{c}) $$
    Tujuan D adalah memaksimalkan log-likelihood untuk mengidentifikasi sampel nyata dan meminimalkan untuk sampel palsu.

2.  **Generator ($p_{\theta}$):** Bertujuan menghasilkan distribusi probabilitas $p_{\theta}(\mathbf{c}|\mathbf{d}, r)$ yang paling mendekati distribusi nyata. Karena kode adalah data diskrit, masalah gradien diatasi dengan **Approximate Sampling Strategy** dan *Policy Gradient*.

    *   **Approximate Sampling:** G tidak secara eksplisit menghasilkan sekuens kode, tetapi **mengambil sampel K sampel negatif** dari *dataset* yang paling mirip dengan sampel positif, meniru proses G.
    *   **Generator Utility:** G dimaksimalkan menggunakan fungsi utilitas (yang merupakan *reward* dari D): $J^{\mathbf{G}}(\mathbf{d})=\mathbb{E}_{\mathbf{c} \sim p_{\theta}(\mathbf{c}|\mathbf{d}, r)}[\log(1+\exp(f_{\phi}(\mathbf{d}, \mathbf{c})))]$.

3.  **Temperature Control Mechanism ($\tau$):** Diperkenalkan pada probabilitas sampling Generator:
    $$ p_{\theta}(\mathbf{c}_k|\mathbf{d}, r)=\frac{\exp(g_{\theta}(\mathbf{d}, \mathbf{c}_k)/\tau)}{\sum_{i=1}^{N}\exp(g_{\theta}(\mathbf{d}, \mathbf{c}_i)/\tau)} $$
    Di mana $g_{\theta}(\mathbf{d}, \mathbf{c}_k)$ adalah *cosine similarity*. Parameter $\tau$ yang lebih rendah **memaksa G untuk fokus pada sampel negatif yang paling dekat** dengan sampel positif, yang meningkatkan kemampuan Discriminator untuk membedakan perbedaan yang halus, sehingga mengoptimalkan *encoder* secara lebih efektif.

## 3. Detail Pengujian

### Dataset
*   **Dataset Java Skala Besar:** Lebih dari $18$ juta pasangan kode-deskripsi Java yang dikumpulkan dari GitHub (sama dengan yang digunakan DeepCS).
    *   Set Pelatihan: $18,233,872$
    *   Set Pengujian: $10,000$

### Baseline
*   **DeepCS:** Baseline DL pertama (menggunakan *triplet loss* dan RNN).
*   **CARLCS:** Menggunakan CNN dan *co-attention* untuk peningkatan.
*   **SAN-CS:** Menggunakan *Self-Attention Networks* (dianggap cepat dan SOTA pada saat itu).

### Metrik Evaluasi
Tiga metrik pencarian standar digunakan:

1.  **Recall@k:**
    $$ Recall(\mathbf{Q}@k)=\frac{1}{|\mathbf{Q}|}\sum_{j=1}^{|\mathbf{Q}|}\epsilon(FRank_{Q_{j}}\le k) $$
    Di mana $\epsilon$ adalah fungsi indikator, dan $FRank$ adalah peringkat pertama hasil yang benar.
2.  **Mean Reciprocal Rank (MRR@k):**
    $$ MRR(\mathbf{Q}@k)=\frac{1}{|\mathbf{Q}|}\sum_{j=1}^{|\mathbf{Q}|}1/FRank_{Q_{j}} $$
3.  **Normalized Discounted Cumulative Gain (NDCG@k):**
    $$ NDCG(\mathbf{Q}@k)=\frac{1}{|\mathbf{Q}|}\sum_{j=1}^{k}\frac{2^{r_{j}}-1}{\log_{2}(1+j)} $$

## 4. Hasil Eksperimen

### Efektivitas Model (RQ1)
Model GAG yang diusulkan mencapai kinerja terbaik secara signifikan pada semua metrik.

| Model | Recall@10 (%) | MRR@10 (%) | NDCG@10 (%) |
| :--- | :--- | :--- | :--- |
| DeepCS | 81.0 | 55.3 | 61.7 |
| CARLCS | 78.2 | 53.5 | 59.2 |
| SAN-CS | 80.1 | 56.5 | 62.3 |
| **Ours (GAG)** | **87.8** | **73.3** | **76.7** |
| **Peningkatan vs. DeepCS** | **+8.4%** | **+32.5%** | **+24.3%** |

**Analisis:** Peningkatan terbesar terlihat pada **MRR@10** ($+32.5\%$), menunjukkan bahwa representasi yang dihasilkan GAG memungkinkan hasil pencarian yang benar pertama kali muncul jauh lebih tinggi dalam peringkat. Hal ini membuktikan bahwa strategi adversarial berhasil mengekstrak fitur yang lebih diskriminatif.

**Efisiensi:** GAG memiliki kecepatan pelatihan ($9.52 \text{ sample/s}$) dan pengujian ($37.7 \text{ query/s}$) yang lebih tinggi daripada DeepCS, karena GAG menghindari perhitungan *loss* triplest yang memakan waktu pada setiap *epoch* dan mengoptimalkan representasi negatif dalam kerangka *approximate sampling*.

### Dampak Hyperparameter (RQ2)

1.  **Negative Sample Size (K):** K=3 memberikan hasil terbaik. K=1 terlalu mudah untuk Discriminator. K>3 tidak meningkatkan kinerja karena keterbatasan daya diskriminasi *classifier* sederhana yang digunakan.
2.  **Temperature ($\tau$):** Kinerja model **menurun** seiring dengan **peningkatan $\tau$** (Gambar 6). Nilai $\tau$ yang rendah ($\tau=0.1$) memaksa Generator untuk memberikan *reward* tinggi hanya pada sampel negatif yang paling dekat, yang secara efektif menguatkan pelatihan Discriminator pada batas keputusan yang paling menantang.

### Dampak Struktur Kode (RQ3)
Menganalisis kontribusi fitur kode secara individu dan kombinasi:

| Model Struktur | MRR@10 (%) | NDCG@10 (%) |
| :--- | :--- | :--- |
| Ours (M - Nama Metode) | 58.4 | 63.0 |
| Ours (A - API Sequence) | 49.4 | 54.0 |
| Ours (T - Token Sequence) | 62.0 | 66.0 |
| Ours (MT - Metode + Token) | 71.1 | 74.8 |
| **Ours (M+A+T)** | **73.3** | **76.7** |

**Analisis:**
1.  **Token Sequence (T)** memberikan hasil individu terbaik, karena mengandung simbol terbanyak. **API Sequence (A)** memberikan kontribusi terlemah.
2.  Kombinasi **Metode (M)** dan **Token (T)** (Ours(MT)) memberikan hasil kombinasi terbaik kedua.
3.  Penggunaan **ketiga fitur** menghasilkan kinerja puncak. Meskipun API Sequence memberikan peningkatan marginal, kombinasi fitur tetap yang paling efektif.

## 5. Kesimpulan

Paper ini berhasil menyajikan **GAG** sebagai metode *code search* baru yang secara efektif menggabungkan distribusi probabilitas relevansi dengan ekstraksi fitur, mengatasi kelemahan *loss function* triplest tradisional. Melalui **Approximate Sampling** dan **Temperature Control**, model GAG menghasilkan representasi kode yang lebih berkualitas dan diskriminatif, yang dibuktikan dengan peningkatan signifikan pada metrik pencarian (khususnya MRR@10 naik $+32.5\%$ dibandingkan DeepCS).

Di masa depan, penelitian akan fokus pada adopsi arsitektur *encoder* yang lebih baik (seperti Transformer) dan pengurangan ruang pencarian untuk lebih meningkatkan efisiensi.

::: info Dampak Praktis
Metode GAG menyediakan kerangka pelatihan yang kuat untuk menghasilkan representasi kode dan deskripsi yang sangat akurat, memungkinkan *code search* yang lebih efisien dan relevan. Strategi *adversarial learning* dengan *approximate sampling* yang diusulkan dapat digunakan untuk meningkatkan kualitas pelatihan model *cross-modal* lain yang berhadapan dengan data diskrit.
:::