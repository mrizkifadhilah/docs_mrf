---
title: Review Paper - Efisiensi Pencarian Kode Mendalam Berbasis Klastering
description: Rangkuman paper tentang peningkatan efisiensi model Deep Code Search menggunakan algoritma klastering (Concurrency and Computation- Practice and Experience, 2024).
head:
  - - meta
    - name: keywords
      content: clustering algorithm, code search, code search efficiency, deep learning, K-Means, DeepCS
---

# 028 - Deep code search efficiency based on clustering
Tautan (DOI) [10.1002/cpe.8027](https://doi.org/10.1002/cpe.8027)

**Penulis:** **Kun Liu** ¹ , **Jianxun Liu** ¹*, **Haize Hu** ¹*

**Afiliasi:**
* ¹ School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan, China

**Kronologi:** Received: 27 May 2023 • Revised: 11 October 2023 • Accepted: 9 January 2024 • Available Online: March 2024

<a href="https://www.scimagojr.com/journalsearch.php?q=27871&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=27871" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Concurrency and Computation: Practice and Experience 36, 13 (2024), e8027<br>• **Topik:** Mengatasi masalah efisiensi rendah dalam model *deep learning*-based *code search* dengan memperkenalkan klastering untuk mengurangi waktu pencarian.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Model *deep learning* untuk *code search* (seperti DeepCS) berfokus hampir secara eksklusif pada akurasi. Selama pencarian *online*, kueri dicocokkan satu per satu dengan **semua** vektor kode dalam basis data (*code vector base*). Basis kode yang besar menyebabkan waktu pencarian yang lama karena banyaknya pencocokan vektor yang tidak relevan, mengabaikan efisiensi yang krusial bagi produktivitas pengembang.<br>• **Solusi:** Mengusulkan model **Clustering-based Deep Code Search (C-DCS)**, yang mengintegrasikan algoritma klastering **K-Means** ke dalam fase pencarian. K-Means membagi basis vektor kode menjadi $K$ klaster. Saat pencarian, vektor kueri dicocokkan terlebih dahulu dengan $K$ vektor pusat klaster (*centroid vectors*) untuk memilih klaster yang paling relevan, dan pencocokan detail hanya dilakukan di dalam klaster tersebut.<br><br>**Contoh Penerapan:**<br>• C-DCS diuji pada tugas pencarian kode Java terhadap basis kode yang berisi **250.000** *snippet* kode, menggunakan arsitektur DeepCS sebagai dasar untuk *data characterization model*.<br><br>**Metodologi:**<br>• **Model Training:** Menggunakan arsitektur *joint embedding* (berbasis RNN/MLP) DeepCS untuk mengubah *triplet* <code, positive description, negative description> menjadi vektor $c$ dan $d$, di mana: $c = \tanh(W^{C}[m; a; t])$, dengan $m$ (nama metode), $a$ (urutan API), dan $t$ (token) disandikan terpisah. Model dioptimalkan agar $\cos(c, d^+) > \cos(c, d^-)$.<br>• **Code Vector Base Clustering:** Setelah pelatihan, semua vektor kode dikluster menggunakan **K-Means** berbasis *cosine similarity* menjadi $K$ klaster, dan vektor pusat $D_j$ dihitung.<br>• **Code Search (Optimized):** Kueri $\rightarrow$ Vektor Kueri ($d_q$). $d_q$ dicocokkan dengan $D_1, \dots, D_K$. Klaster terbaik dipilih. Pencocokan akhir (pemeringkatan) hanya dilakukan di dalam klaster terpilih.<br>• **Optimasi Stabilitas:** Mengoptimalkan K-Means dengan memperkenalkan kontrol **$size\_{min}$** untuk ukuran klaster, memastikan klaster lebih stabil dan tidak mengorbankan akurasi.<br><br>**Temuan Kunci:**<br>1. **Efisiensi Superior:** C-DCS menghemat $\mathbf{92.2\%}$ waktu pencarian rata-rata (*Mean Search Time*, MST) dibandingkan DeepCS ($4.2425 \text{s}$ menjadi $0.3311 \text{s}$).<br>2. **Akuntabilitas Akurasi:** Nilai FRank, Success Rate@k (R@k), Precision@k (P@k), dan MRR **tetap sama** dengan DeepCS (MRR $\mathbf{0.60}$), membuktikan klastering tidak memengaruhi akurasi pemeringkatan.<br>3. **Optimasi K-Means:** Nilai $K$ optimal ditemukan pada $\mathbf{K=500}$ (untuk $n=250.000$) berdasarkan rumus $K \approx \sqrt{n}$ dan verifikasi MST terendah.<br>4. **Peningkatan Stabilitas:** Mengontrol $size\_{min}$ klaster hingga $\mathbf{50\%}$ dari $n/K$ lebih lanjut mengurangi MST menjadi $\mathbf{0.2632 \text{s}}$ (pengurangan $\mathbf{93.8\%}$ dari *baseline*) tanpa memengaruhi akurasi.<br><br>**Kontribusi Utama:**<br>• Model C-DCS yang secara eksplisit menargetkan dan sangat meningkatkan efisiensi *deep code search* menggunakan klastering K-Means.<br>• Memperkenalkan metrik **Mean Search Time (MST)** untuk mengukur efisiensi *code search*.<br>• Mengoptimalkan algoritma K-Means dengan variabel kontrol $size\_{min}$ untuk meningkatkan stabilitas klaster dan efisiensi lebih lanjut.<br><br>**Dampak:**<br>• Pengurangan waktu pencarian yang signifikan secara langsung meningkatkan efisiensi pengembangan perangkat lunak dan membuat model *deep code search* lebih praktis untuk basis kode skala besar. |

## 1. Pendahuluan & Masalah

*Code search* adalah tugas penting dalam *software engineering* yang bertujuan membantu pengembang menemukan dan menggunakan kembali *snippet* kode yang relevan dari repositori publik. Kecepatan dan akurasi pencarian secara langsung memengaruhi efektivitas pekerjaan pengembang.

Model *code search* tradisional berbasis *Information Retrieval* (IR) dibatasi oleh kesenjangan semantik (*semantic gap*) antara kueri bahasa alami dan kode. Munculnya model *deep learning* (DL), seperti DeepCS, berhasil menjembatani kesenjangan ini dengan secara otomatis mempelajari representasi vektor semantik dari kode dan teks.

Namun, fokus utama riset *deep learning* *code search* adalah **akurasi** dan kualitas hasil. Efisiensi pencarian sering diabaikan. Dalam model *deep learning* yang khas, vektor kueri harus dicocokkan satu per satu dengan **semua** vektor kode dalam basis data. Untuk basis kode skala besar, proses ini memakan waktu yang sangat lama karena sebagian besar kode yang dicocokkan tidak relevan, yang pada akhirnya mengurangi efisiensi pengembangan perangkat lunak.

::: tip Solusi yang Diusulkan
Diusulkan model **Clustering-based Deep Code Search (C-DCS)**. Model ini menggunakan algoritma klastering **K-Means** untuk mengelompokkan vektor kode yang serupa ke dalam klaster sebelum pencarian. Saat pencarian, vektor kueri dicocokkan hanya dengan vektor pusat klaster (*centroid*) untuk mengidentifikasi klaster yang paling relevan, dan pemeringkatan detail hanya dilakukan di dalam klaster tersebut, sehingga secara drastis mengurangi waktu pencarian vektor yang tidak relevan.
:::

## 2. Metodologi

C-DCS dibangun berdasarkan tiga fase: *Model Training*, *Code Vector Base Clustering*, dan *Code Search*.

### A. Model Training (Heterogeneous Data Characterization Model)

Fase ini menggunakan arsitektur *joint embedding* (berdasarkan DeepCS) untuk melatih model representasi data heterogen.

1.  **Code Embedding:** *Snippet* kode ($C = [M, A, \Gamma]$) dipecah menjadi tiga aspek:
    *   *Method Name* ($M$): Di-*-embed* menggunakan RNN dengan *maxpooling* menjadi vektor $m$.
        $$ m = \text{maxpooling}([h_1, \dots, h_{N_M}]) $$
    *   *API Sequence* ($A$): Di-*-embed* menggunakan RNN dengan *maxpooling* menjadi vektor $a$.
        $$ a = \text{maxpooling}([h_1, \dots, h_{N_A}]) $$
    *   *Tokens* ($\Gamma$): Di-*-embed* menggunakan MLP (*multilayer perceptron*) dan *maxpooling* menjadi vektor $t$.
        $$ t = \text{maxpooling}([h_1, \dots, h_{N_\Gamma}]) $$
    Ketiga vektor tersebut digabungkan (*fused*) melalui lapisan terhubung penuh (*fully connected layer*):
    $$ c = \tanh(W^C[m; a; t]) $$

2.  **Description Embedding:** Deskripsi/komentar ($D$) di-*-embed* menggunakan RNN dengan *maxpooling* menjadi vektor $d$.

3.  **Similarity Computation:** *Cosine similarity* digunakan untuk mengukur relevansi antara vektor kode ($c$) dan deskripsi ($d$):
    $$ \cos(c,d)=\frac{c^{T}d}{||c||||d||} $$
    Model dilatih menggunakan *triplet* $<C, D^+, D^->$ untuk memastikan $\cos(c, d^+) > \cos(c, d^-)$.

### B. Code Vector Base Clustering

Setelah pelatihan, semua *snippet* kode di basis data pencarian dikonversi menjadi vektor kode dan dikelompokkan menggunakan algoritma **K-Means** dengan *cosine similarity* sebagai ukuran jarak.

1.  **Inisialisasi:** $K$ vektor pusat klaster ($D_1, \dots, D_K$) dipilih secara acak.
2.  **Penugasan:** Setiap vektor data ($x_i$) ditugaskan ke klaster yang memiliki *centroid* ($D_j$) dengan *cosine similarity* tertinggi.
3.  **Pembaruan Centroid:** $D_j$ baru ($D_j^*$) dihitung sebagai rata-rata semua vektor dalam klaster.

### C. Code Search (Online)

Fase pencarian dioptimalkan dengan mekanisme dua langkah:

1.  Vektor kueri ($d_q$) yang dihasilkan dari *Query Statement* dicocokkan dengan **$K$ *centroid* klaster** ($D_1, \dots, D_K$).
2.  Klaster yang paling mirip (*Most Similar Cluster*) dipilih.
3.  $d_q$ hanya dicocokkan dengan **semua vektor kode di dalam klaster terpilih** untuk mendapatkan *snippet* kode yang paling relevan.

## 3. Detail Pengujian

### Dataset
*   **Training Dataset:** Dibuat dari $\mathbf{20.825.872}$ metode Java beranotasi yang memiliki *documentation comments* dari proyek GitHub yang populer (memiliki bintang), diekstrak menjadi *tuple* <method name, API sequence, tokens, comment>.
*   **Code Search Base (Testing):** $\mathbf{250.000}$ *snippet* kode Java beranotasi yang semantik jelas, dikumpulkan dan dicek manual dari StackOverflow.
*   **Benchmark Query Base:** $\mathbf{30}$ kueri bahasa alami unik yang berasal dari *documentation comments* pada basis kode pencarian, yang mewakili tugas pemrograman Java spesifik.

### Baseline Model
Model **DeepCS** digunakan sebagai *baseline* komparatif, karena merupakan arsitektur representatif dalam penelitian *neural code search*.

### Metrik Evaluasi
Metrik akurasi standar dan metrik efisiensi baru digunakan:
*   **FRank** (*First Rank*): Peringkat hasil yang benar pertama.
*   **Success Rate@k** (R@k): Persentase kueri yang memiliki setidaknya satu hasil benar di $k$ hasil teratas.
    $$ \text{SuccessRate@}k=\frac{1}{|Q|}\sum_{q=1}^{Q}\tilde{\delta}(\text{FRank}_{q}<k) $$
*   **Precision@k** (P@k): Persentase hasil relevan di $k$ hasil teratas.
    $$ \text{Precision@}k = \frac{\text{\#relevant results}}{k} $$
*   **Mean Reciprocal Rank (MRR):** Rata-rata dari kebalikan peringkat hasil benar pertama.
    $$ MRR=\frac{1}{|Q|}\sum_{q=1}^{Q}\frac{1}{\text{FRank}_{q}} $$
*   **Mean Search Time (MST):** **Metrik efisiensi baru** yang mengukur rata-rata waktu pencarian untuk mengambil hasil yang benar untuk semua kueri.
    $$ MST=\frac{1}{|Q|}\sum_{q=1}^{Q}t_{q} $$

## 4. Hasil Eksperimen

### Performa C-DCS (K-Means Standar, $size\_{min}=0\%$)

| Model Train | Code Search | MST/s | R@1 | R@5 | R@10 | P@1 | P@5 | P@10 | MRR |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| DeepCS | DeepCS | 4.2425 | 0.46 | 0.76 | 0.86 | 0.46 | 0.50 | 0.49 | 0.60 |
| DeepCS | **C-DCS** | **0.3311** | 0.46 | 0.76 | 0.86 | 0.46 | 0.50 | 0.49 | 0.60 |

*   **Efisiensi (MST):** C-DCS secara drastis mengurangi waktu pencarian dari $4.2425 \text{ s}$ menjadi $0.3311 \text{ s}$. Ini setara dengan **pengurangan sebesar $92.2\%$** dalam waktu pencarian.
*   **Akurasi:** Semua metrik akurasi (R@k, P@k, MRR, dan FRank individual) **tetap identik** dengan *baseline* DeepCS. Ini memvalidasi bahwa klastering yang efisien tidak mengorbankan kualitas pemeringkatan.

### Peningkatan Stabilitas Klaster (Kontrol $size\_{min}$)

Untuk meningkatkan stabilitas dan efisiensi lebih lanjut, K-Means dioptimalkan dengan kontrol $size\_{min}$ (ukuran minimum klaster relatif terhadap ideal $n/K$).

| $size\_{min}$ | MST/s | R@1 | R@5 | R@10 | P@1 | P@5 | P@10 | MRR |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 0% ($n/K$) | 0.3311 | 0.46 | 0.76 | 0.86 | 0.46 | 0.50 | 0.49 | 0.60 |
| **50% ($n/2K$)** | **0.2632** | **0.46** | **0.76** | **0.86** | **0.46** | **0.50** | **0.49** | **0.60** |
| 75% ($n/K$) | 0.1913 | 0.46 | 0.73 | 0.80 | 0.45 | 0.49 | 0.49 | 0.58 |
| 100% ($n/K$) | 0.1159 | 0.43 | 0.68 | 0.71 | 0.42 | 0.44 | 0.46 | 0.53 |

*   **Optimal $size\_{min}$:** Mengatur $size\_{min}$ ke $\mathbf{50\%}$ dari $n/K$ (yaitu $n/2K$) lebih lanjut mengurangi MST menjadi $\mathbf{0.2632 \text{ s}}$ (pengurangan total $\mathbf{93.8\%}$ dari DeepCS) sambil mempertahankan akurasi penuh.
*   **Kerusakan Akurasi:** Ketika $size\_{min}$ terlalu besar ($75\%$ atau $100\%$ dari $n/K$), akurasi model mulai menurun secara signifikan (MRR turun menjadi $0.53$), karena vektor kode yang tidak terkait dipaksa berada dalam klaster yang sama.

### Penentuan Parameter Klastering

*   **Jumlah Klaster ($K$):** Untuk meminimalkan total waktu pencocokan ($\mathcal{O}(K + n/K)$), nilai $K$ yang optimal secara teoritis adalah $K = \sqrt{n}$. Dengan $n=250.000$, $K$ optimal diatur ke $\mathbf{500}$. Hasil eksperimen memvalidasi bahwa MST mencapai nilai minimum tepat pada $K=500$, sementara akurasi (diukur dengan *Mean Similarity*, MS) tetap tidak berubah untuk semua $K$.
*   **Maksimum Iterasi ($max\_{iter}$):** Nilai optimal ditemukan antara 1995 dan 2000; ditetapkan $\mathbf{max\_{iter}=2000}$ untuk memastikan klastering mencapai keadaan stabil.

## 5. Kesimpulan

Paper ini berhasil mengatasi masalah efisiensi dalam model *deep code search* yang ada dengan mengusulkan model **C-DCS** yang berbasis klastering K-Means. C-DCS secara signifikan mengurangi waktu pencarian (hingga $93.8\%$ dibandingkan *baseline* DeepCS) tanpa mengorbankan akurasi. Selain itu, optimalisasi algoritma K-Means melalui pengenalan kontrol $size\_{min}$ memastikan klastering yang stabil dan efisiensi yang lebih tinggi.

::: info Dampak Praktis
C-DCS membuat model *deep code search* menjadi lebih efisien dan *scalable*, sangat relevan untuk konteks *big code* di mana basis kode berjumlah jutaan baris. Peningkatan efisiensi pencarian ini secara langsung diterjemahkan menjadi peningkatan produktivitas pengembang dan efisiensi pengembangan perangkat lunak secara keseluruhan.
:::