---
title: Review Paper - CMCS untuk Code Search
description: Rangkuman paper tentang Contrastive-Metric Learning dengan Vector-Level Sampling dan Augmentation untuk Code Search (Scientific Reports, 2024).
head:
  - - meta
    - name: keywords
      content: code search, contrastive learning, metric learning, hard negative sample, K-means, vector-level augmentation
---

# 022 - CMCS: contrastive-metric learning via vector-level sampling and augmentation for code search
Tautan (DOI) [10.1038/s41598-024-64205-2](https://doi.org/10.1038/s41598-024-64205-2)

**Penulis:** **Qihong Song** ¹'², **Haize Hu** ¹'² & **Tebo Dai** ¹

**Afiliasi:**
* ¹ School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan, China
* ² Key Lab. of Knowledge Processing and Networked Manufacturing, Hunan University of Science and Technology, Xiangtan, Hunan, China

**Kronologi:** Received: 3 March 2024 • Accepted: 6 June 2024 • Available Online: 24 June 2024

<a href="https://www.scimagojr.com/journalsearch.php?q=21100200805&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21100200805" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Scientific Reports 14 (2024) 14549<br>• **Topik:** Peningkatan kinerja *code search* berbasis *deep learning* dengan berfokus pada kualitas data pelatihan, khususnya sampel negatif keras (*hard negative samples*), melalui pembelajaran gabungan *metric* dan *contrastive*.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Model *deep learning* untuk *code search* mengabaikan peran penting data pelatihan dalam *minibatch*, terutama kekurangan **sampel negatif keras** (*hard negative samples*) yang efektif. *Random sampling* menghasilkan sampel negatif yang mudah dibedakan, menghambat optimasi model yang optimal.<br>• **Solusi:** Mengusulkan **CMCS** (*Contrastive-Metric Learning for Code Search*) yang menggunakan (1) Metode *sampling* berbasis **K-means** dan (2) Metode **Augmentasi Level Vektor yang Kekerasannya Dapat Dikontrol** untuk menghasilkan sampel positif dan negatif keras yang efektif.<br><br>**Contoh Penerapan:**<br>• **Pencarian Kode Semantik:** Meningkatkan akurasi dan efisiensi model dalam menemukan *snippet* kode yang relevan dengan kueri bahasa alami dari *codebase* yang besar.<br><br>**Metodologi:**<br>• **Sampling Negatif Keras:** Menggunakan algoritma **K-means** untuk mengelompokkan vektor kode yang direpresentasikan dari *multimodal features*. Sampel dari kluster yang sama dianggap sebagai negatif keras, karena memiliki vektor yang mirip tetapi semantik yang berbeda.<br>• **Augmentasi Level Vektor:** Menggunakan empat teknik (Linear Interpolation, Stochastic Perturbation, Binary Interpolation, Gaussian Scaling) yang diringkas menjadi fungsi $\mathbf{A}(\theta)$, di mana $\theta$ (*hardness*) mengontrol tingkat gangguan untuk menghasilkan sampel positif ($\theta$ besar) dan negatif keras ($\theta$ sedang).<br>• **Pembelajaran Gabungan (CML):** Fungsi *loss* gabungan dari **Metric Learning (ML)** untuk pemadanan kueri-kode, dan **Multimodal Contrastive Learning (CL)** yang mengeksplorasi lima modalitas fitur kode (Token, AST, CFG, DFG) dan kueri secara individual.<br><br>**Temuan Kunci:**<br>1. **Peningkatan Kinerja:** CMCS secara signifikan meningkatkan MRR *baseline* rata-rata, misalnya, $59.12\%$ pada TabCS dan $1.40\%$ pada CoCoSoDa (model terkuat). MRR rata-rata mencapai $\mathbf{0.794}$.<br>2. **Efisiensi Pelatihan:** CMCS secara signifikan mengurangi waktu konvergensi (misalnya, hanya $\mathbf{8.5}$ jam pada dataset Java) dibandingkan dengan model *baseline* canggih lainnya (misalnya, CodeBERT $11.8$ jam), berkat sampel negatif keras.<br>3. **Parameter Optimal:** *Batch size* optimal adalah $\mathbf{32}$, jumlah *cluster* optimal $\mathbf{K=44}$ (memilih $\mathbf{K=32}$ untuk menyeimbangkan waktu), rasio sampel negatif keras dalam *batch* adalah $\mathbf{1/2}$, dan *hardness* optimal untuk sampel positif $\mathbf{\theta=0.94}$ dan negatif keras $\mathbf{\theta=0.70}$.<br><br>**Kontribusi Utama:**<br>• Mengusulkan metode *sampling* berbasis K-means dan metode augmentasi level vektor yang dapat dikontrol *hardness*-nya untuk memperoleh sampel positif dan negatif keras.<br>• Merancang **CMCS**, pembelajaran gabungan *Contrastive-Metric Learning* yang memanfaatkan *multimodal features* kode (Token, AST, CFG, DFG) dengan sampel negatif keras.<br>• Mendemonstrasikan secara ekstensif bahwa CMCS meningkatkan efisiensi pelatihan dan kinerja pencarian secara substansial pada berbagai model *state-of-the-art*.<br><br>**Dampak:**<br>• Mengoptimalkan pelatihan model *deep learning* untuk tugas *code search* dengan memecahkan masalah kekurangan sampel negatif keras, menghasilkan model yang lebih cepat konvergen dan memiliki kemampuan pemadanan semantik yang lebih akurat. |

## 1. Pendahuluan & Masalah

*Code search*, yaitu mengambil *snippet* kode yang benar dan relevan secara semantik dengan kueri bahasa alami, merupakan komponen penting dalam pengembangan perangkat lunak untuk meningkatkan efisiensi dan pengelolaan kode. Penelitian awal mengandalkan teknik *Information Retrieval* (IR) berdasarkan kemiripan teks, tetapi terbatas oleh kesenjangan semantik antara bahasa pemrograman dan bahasa alami.

Model *Deep Learning* (DL) yang muncul berupaya menyelaraskan *snippet* kode dan kueri dalam ruang vektor dimensi tinggi, sehingga mengurangi kesenjangan semantik tersebut. Model-model ini sebagian besar didasarkan pada *Metric Learning*, yang bertujuan mengurangi jarak antara kueri (*anchor*) dan sampel kode positif, sambil memperbesar jarak dengan sampel kode negatif.

Namun, efektivitas pelatihan DLM sangat bergantung pada kualitas data dalam *minibatch*. Secara spesifik, model cenderung mengabaikan **sampel negatif keras** (*hard negative samples*)—sampel negatif yang secara vektor dekat dengan sampel *anchor* tetapi memiliki semantik yang berbeda. Sampel ini sangat penting untuk **mempercepat koreksi kesalahan** model. Karena *minibatch* biasanya diperoleh melalui *random sampling*, sampel negatif keras sangat langka, mengakibatkan model terlatih secara suboptimal.

::: tip Solusi yang Diusulkan
Untuk menggabungkan keunggulan *Metric Learning* dan *Contrastive Learning*, serta memaksimalkan penggunaan sampel negatif keras dan fitur multimodal kode, diusulkan **CMCS** (*Contrastive-Metric Learning for Code Search*) yang didasarkan pada metode *sampling* berbasis **K-means** dan metode **Augmentasi Level Vektor yang Kekerasannya Dapat Dikontrol** ($\mathbf{\theta}$) untuk menghasilkan sampel positif dan negatif keras.
:::

## 2. Metodologi

Arsitektur CMCS mengintegrasikan *sampling*, representasi multimodal, augmentasi, dan pembelajaran gabungan (*Contrastive-Metric Learning* - CML) untuk mengoptimalkan pelatihan model *code search*.

### A. Sampling Sampel Negatif Keras

1.  **Representasi Vektor Kode:** Model yang sudah di-*fine-tune* (*pre-trained*) digunakan untuk merepresentasikan semua *snippet* kode dalam *training set* sebagai vektor ($\mathbf{V_C}$) dengan menggabungkan fitur multimodal.
2.  **K-means Clustering:** Algoritma **K-means** digunakan untuk mengelompokkan vektor kode menjadi $\mathbf{K}$ kluster. Kode dalam kluster yang sama dianggap sebagai **negatif keras** satu sama lain karena mereka memiliki vektor yang relatif dekat tetapi semantik yang berbeda (fungsi yang saling eksklusif).
3.  ***Mini-batch* Konstruksi:** *Mini-batch* dibangun dengan mengambil setengah ukuran *batch* dari kluster negatif keras yang relevan (memastikan adanya negatif keras) dan setengah lainnya melalui *random sampling* dari *codebase* (memastikan keragaman).

### B. Representasi Multimodal Input

CMCS memperluas modalitas kode untuk representasi yang lebih komprehensif. Kode dan kueri dianggap sebagai dua modalitas. Modalitas kode dipecah menjadi empat fitur:
*   **Semantic:** Urutan *token* kode ($\mathbf{V_t}$).
*   **Syntactic:** Urutan *tree* dari AST ($\mathbf{V_a}$).
*   **Control Flow:** Urutan alir kontrol dari CFG ($\mathbf{V_c}$).
*   **Data Flow:** Urutan alir data dari DFG ($\mathbf{V_d}$).
Kueri direpresentasikan sebagai urutan *token* ($\mathbf{V_Q}$). Fitur-fitur ini diperoleh melalui **Encoder** setelah proses *parsing* dan *serialization*.

### C. Metode Augmentasi Level Vektor yang Kekerasannya Dapat Dikontrol

Augmentasi Level Vektor lebih efisien daripada level teks karena langsung memanipulasi vektor. Empat metode augmentasi vektor utama (Linear Interpolation, Stochastic Perturbation, Binary Interpolation, Gaussian Scaling) diringkas ke dalam fungsi augmentasi umum:
$$ V_{i}^{*}(\theta)=\theta V_{i}(e)+\xi(1-\theta)V_{j}(e) $$
Di sini, $\theta \in (0, 1.0]$ adalah parameter **hardness** yang mengontrol tingkat gangguan dan, oleh karena itu, kemiripan vektor yang dihasilkan terhadap sampel *anchor* ($\mathbf{V_i}$).
*   **Sampel Positif:** Dihasilkan dengan $\theta$ yang besar (vektor sangat mirip).
*   **Sampel Negatif Keras:** Dihasilkan dengan $\theta$ yang menengah (vektor mirip, tetapi tidak terlalu mirip).

Strategi **Fine-grained Random Augmentation** diterapkan, di mana salah satu dari empat metode dipilih secara acak untuk setiap augmentasi, dengan jumlah gangguan acak dalam rentang yang ditentukan oleh $\theta$, untuk meningkatkan keragaman fitur dan mengurangi *overfitting*.

### D. Pembelajaran Gabungan Kontrastif-Metrik (CML)

Fungsi *loss* total ($\mathbf{L}$) menggabungkan *Metric Learning* dan *Multimodal Contrastive Learning*.

1.  ***Multimodal Contrastive Learning* (CL):**
    CL dilakukan secara individual untuk setiap lima modalitas fitur. Kerugian CL untuk modalitas tertentu ($\mathbf{V_i}$) memastikan vektor modalitas lebih dekat ke sampel positif yang diaugmentasi ($\mathbf{V_{i+}}$) dan lebih jauh dari sampel negatif keras yang diaugmentasi ($\mathbf{V_{Hi}}$) dan sampel negatif *minibatch* lainnya ($\mathbf{V_j}$):
    $$ L_{i}^{C} = -\log\frac{\sum_{m=1}^{M1} \exp(\mathbf{V}_{i} \cdot \mathbf{V}_{i+}^{m})}{\sum_{m=1}^{M1} \exp(\mathbf{V}_{i} \cdot \mathbf{V}_{i+}^{m}) + \sum_{k=1}^{M2} \exp(\mathbf{V}_{i} \cdot \mathbf{V}_{Hi}^{k}) + \sum_{j=1, j\ne i}^{B} \exp(\mathbf{V}_{i} \cdot \mathbf{V}_{j})} $$
    Ini mencakup $L_{Q}^{C}$, $L_{t}^{C}$, $L_{a}^{C}$, $L_{c}^{C}$, dan $L_{d}^{C}$.
2.  ***Metric Learning* (ML):**
    Fitur multimodal kode digabungkan menjadi vektor kode lengkap ($\mathbf{V_C}$) menggunakan *Fusion module*. Kerugian ML bertujuan untuk memadankan $\mathbf{V_C}$ dengan vektor kueri ($\mathbf{V_Q}$) dan memisahkan $\mathbf{V_Q}$ dari $\mathbf{V_{HC}}$ (negatif keras kode yang diaugmentasi) dan $\mathbf{V_C}$ lainnya:
    $$ L_{i}^{M} = -\log\frac{\exp(\mathbf{V}_{Qi} \cdot \mathbf{V}_{Ci})}{\exp(\mathbf{V}_{Qi} \cdot \mathbf{V}_{Ci}) + \sum_{k=1}^{M2} \exp(\mathbf{V}_{Qi} \cdot \mathbf{V}_{HCk}) + \sum_{j=1, j\ne i}^{B} \exp(\mathbf{V}_{Qj} \cdot \mathbf{V}_{Ci})} $$
3.  **Total *Loss***:
    $$ L = \sum_{i=1}^{B}(L_{Qi}^{M} + L_{Qi}^{C} + L_{ti}^{C} + L_{ai}^{C} + L_{ci}^{C} + L_{di}^{C}) $$

## 3. Detail Pengujian

### Dataset
*   **CodeSearchNet:** Dataset skala besar yang telah difilter dan diproses sebelumnya (menghapus data berkualitas rendah, kode terlalu panjang/pendek) untuk enam bahasa pemrograman (Python, PHP, Go, Java, JavaScript, Ruby).

### Baseline Models
Tujuh model canggih digunakan sebagai *baseline*, mewakili model berbasis CL (SyncoBERT, CodeRetriever, CoCoSoDa), model multimodal (MRCS, TabCS), dan model *pre-trained* (*fine-tuned* CodeBERT, GraphCodeBERT).

### Metrik Evaluasi
Tiga metrik yang paling umum digunakan untuk *code search* digunakan:
1.  **Mean Reciprocal Rank (MRR):** Mengukur peringkat kode target pertama yang paling relevan.
    $$ \mathbf{MRR} = \frac{1}{|Q|}\sum_{j=1}^{|Q|}\frac{1}{Rank_{j}} $$
2.  **Normalized Discounted Cumulative Gain (NDCG):** Mengukur kesamaan antara daftar rekomendasi yang dikembalikan model dengan daftar ideal, mempertimbangkan peringkat keseluruhan.
    $$ \mathbf{NDCG} = \frac{1}{|Q|}\sum_{j=1}^{k}\frac{2^{r_{j}}-1}{\log_{2}(1+j)} $$
    Di mana $r_j$ adalah relevansi kode pada posisi $j$.
3.  **SuccessRate@k (SR@k):** Mengukur probabilitas kode yang paling relevan berada di *top-k* dari daftar yang dikembalikan.

## 4. Hasil Eksperimen

### RQ1: Efektivitas CMCS

| Model | MRR Rata-rata | NDCG Rata-rata | SR@1 Rata-rata |
| :--- | :--- | :--- | :--- |
| **CMCS** | **0.794** | **0.809** | **0.803** |
| CoCoSoDa | 0.783 | 0.806 | 0.797 |
| CodeRetriever | 0.761 | 0.758 | 0.779 |
| SyncoBERT | 0.735 | 0.808 | 0.750 |
| GraphCodeBERT | 0.712 | 0.735 | 0.726 |
| CodeBERT | 0.674 | 0.695 | 0.687 |
| MRCS | 0.567 | 0.596 | 0.583 |
| TabCS | 0.499 | 0.533 | 0.517 |

**Analisis:** CMCS secara konsisten mengungguli tujuh *baseline* pada enam bahasa pemrograman. Peningkatan MRR rata-rata terhadap *baseline* terbaik (CoCoSoDa) adalah $\mathbf{1.40\%}$, dan terhadap TabCS adalah $\mathbf{59.12\%}$. Visualisasi vektor menunjukkan bahwa pelatihan dengan CMCS merenggangkan distribusi vektor kode dan kueri, membuat pemadanan semantik lebih jelas.

### RQ2: Efisiensi Pelatihan CMCS

| Model | Waktu Konvergensi (jam) | Rasio Perubahan (Dibanding CMCS) |
| :--- | :--- | :--- |
| **CMCS** | **8.5** | — |
| TabCS | 8.1 | 14.7% (Lebih Cepat) |
| MRCS | 10.2 | 120.0% (Lebih Lambat) |
| CodeBERT | 11.8 | 138.8% (Lebih Lambat) |
| GraphCodeBERT | 13.5 | 158.8% (Lebih Lambat) |
| SyncoBERT | 15.6 | 183.5% (Lebih Lambat) |
| CodeRetriever | 13.5 | 158.8% (Lebih Lambat) |
| CoCoSoDa | 14.5 | 170.6% (Lebih Lambat) |

**Analisis:** CMCS secara signifikan meningkatkan efisiensi pelatihan model (*deep learning*) lainnya, mencapai waktu konvergensi $\mathbf{8.5}$ jam. Meskipun sedikit lebih lambat dari TabCS (yang menggunakan jaringan yang jauh lebih sederhana), CMCS mempertahankan kinerja pencarian yang superior. Peningkatan efisiensi ini disebabkan oleh sampel negatif keras yang memandu model untuk **mengoreksi kesalahan lebih cepat** selama pelatihan.

### RQ3: Rasionalitas Arsitektur CMCS (Ablasi)

| Komponen Dihapus | MRR Rata-rata (Penurunan) |
| :--- | :--- |
| CMCS (Lengkap) | **0.794** |
| -ML (*Metric Learning*) | 0.743 (Menurun $6.4\%$) |
| -CL (*Contrastive Learning*) | 0.683 (Menurun $14.0\%$) |
| -MCL (*Multimodal CL*) | 0.705 (Menurun $11.1\%$) |
| -Hard (*Hard Negative*) | 0.764 (Menurun $3.8\%$) |

**Analisis:**
*   **CL** (khususnya Multimodal CL) menunjukkan peran yang sangat penting dalam kemampuan model untuk belajar fitur kode dan kueri.
*   **ML** juga esensial untuk pembelajaran hubungan pemadanan kueri-kode yang akurat.
*   **Sampel Negatif Keras (-Hard)** menyumbang $3.8\%$ peningkatan kinerja, membuktikan bahwa keberadaannya (melalui *sampling* dan *augmentation*) bermanfaat untuk kinerja pelatihan.

### RQ5: Parameter Optimal

| Parameter | Nilai Optimal |
| :--- | :--- |
| **Batch Size** | $\mathbf{32}$ |
| **Jumlah Cluster (K)** | $\mathbf{44}$ (Dipilih $\mathbf{32}$ untuk efisiensi) |
| **Rasio Negatif Keras dalam Batch** | $\mathbf{1/2}$ (50\% dari *batch* adalah Negatif Keras hasil *sampling*) |
| **Hardness ($\theta$) Sampel Positif** | $\mathbf{0.94}$ (Untuk kemiripan vektor tinggi) |
| **Hardness ($\theta$) Sampel Negatif Keras** | $\mathbf{0.70}$ (Untuk kemiripan vektor menengah) |
| **Count Augmentasi ($M_1$, $M_2$)** | $\mathbf{M_1=5}$, $\mathbf{M_2=5}$ |

**Analisis:** Pemilihan parameter yang cermat, terutama rasio $\mathbf{1/2}$ negatif keras yang *disampling*, memastikan model memanfaatkan manfaat sampel negatif keras tanpa menimbulkan ketidakseimbangan data atau *overfitting*. *Hardness* optimal $\mathbf{\theta=0.70}$ memvalidasi bahwa sampel negatif keras harus memiliki kemiripan vektor menengah untuk menjadi efektif.

## 5. Kesimpulan

CMCS adalah pendekatan *Contrastive-Metric Learning* yang efisien untuk *code search* yang mengatasi tantangan utama kekurangan sampel negatif keras. Dengan menggunakan *sampling* berbasis K-means dan augmentasi level vektor yang kekerasannya dapat dikontrol, CMCS berhasil menghasilkan sampel yang efektif untuk mengoptimalkan pelatihan. Hasil ekstensif pada CodeSearchNet membuktikan bahwa CMCS secara signifikan meningkatkan kinerja pencarian (MRR rata-rata $\mathbf{0.794}$) dan efisiensi pelatihan ($8.5$ jam konvergensi), melebihi model-model *state-of-the-art*.

::: info Dampak Praktis
CMCS memberikan kerangka kerja yang kuat untuk mengembangkan model *code search* di masa depan. Dengan menyediakan metode yang lebih efisien dan akurat untuk menyelaraskan kode dan kueri dalam ruang vektor, CMCS secara langsung mendukung peningkatan produktivitas pengembang, mempercepat *coding*, dan memfasilitasi penggunaan kembali kode yang lebih efektif dalam rekayasa perangkat lunak.
:::