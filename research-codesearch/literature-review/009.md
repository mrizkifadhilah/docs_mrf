---
title: Review Paper - CoCoHaNeRe Hard Negative Mining Code Search
description: Rangkuman paper tentang Hard Negative Mining Efektif untuk Code Search Berbasis Contrastive Learning (ACM Transactions on Software Engineering and Methodology, 2025).
head:
  - - meta
    - name: keywords
      content: Code Search, Contrastive Learning, Hard Negative Mining, Code Pre-trained Model, Semantic Similarity
---

# 009 - Effective Hard Negative Mining for Contrastive Learning-Based Code Search
[https://doi.org/10.1145/3695994]

**Penulis:** **Ye Fan** ᵃ, **Chuanyi Li** ᵃ*, **Jidong Ge** ᵃ*, **LiGuo Huang** ᵇ, **Bin Luo** ᵃ

**Afiliasi:**
* ᵃ National Key Laboratory for Novel Software Technology at Nanjing University, Nanjing, China
* ᵇ Department of Computer Science, Southern Methodist University, Dallas, TX, USA

**Kronologi:** Received: 1 January 2024 • Revised: 10 August 2024 • Accepted: 12 August 2024 • Available Online: February 2025

<a href="https://www.scimagojr.com/journalsearch.php?q=18121&tip=sid&clean=0" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=18121" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** ACM Transactions on Software Engineering and Methodology, Vol 34, Isu 3, Artikel 76 (2025)<br>• **Penerbit:** ACM<br>• **Topik:** Peningkatan Efektivitas *Code Search* melalui *Hard Negative Mining* yang dapat dibedakan (*differentiable*) dalam kerangka *Contrastive Learning*.<br><br>**Masalah & Solusi:**<br>• **Masalah:** (1) Model *Contrastive Learning* (CL) yang ada (misalnya CoCoSoDa) gagal membedakan kode yang serupa (yang paling mungkin menyebabkan kesalahan, disebut **Hard Negatives**) karena pengambilan sampel negatif yang acak. (2) *Embedding* negatif dari *memory bank* yang ada tidak berpartisipasi dalam *gradient descent*, sehingga menghambat pembelajaran yang efektif dari informasi semantik negatif.<br>• **Solusi:** Mengusulkan **CoCoHaNeRe** (*Contrastive learning Code Search model with Hard Negative mining and Re-encoding*). Solusinya adalah: (1) Memperkenalkan **Hard Negative Examples** yang paling mirip dengan sampel positif ke dalam pelatihan kontrasif; dan (2) Menggunakan *Searchable and Updateable Memory Bank* dan **meng-*re-encode*** semua *Hard Negatives* yang diambil, sehingga mereka **sepenuhnya berpartisipasi dalam *gradient descent*** model.<br><br>**Contoh Penerapan:**<br>• **Pencarian Kode:** Mengambil $k$ tetangga terdekat dari *Memory Bank* sebagai *Hard Negatives* untuk kueri/kode saat ini. Contoh kueri "Adds a callback..." secara salah mengambil kode yang mengandung *keyword* serupa tetapi secara fungsional berbeda (Hard Negative Example). CoCoHaNeRe melatih model secara eksplisit untuk mengatasi ambiguitas ini.<br>• **Tugas Serupa:** Diterapkan pada tugas serupa seperti *Code Clone Detection* (POJ-104, BigCloneBench) dan *Code Question Answering* (CoSQA), menunjukkan portabilitas dan efektivitas fitur semantik yang dipelajari.<br><br>**Metodologi:**<br>• **Arsitektur:** Menggunakan *Code Pre-Trained Models* (PTM) berbasis *encoder* (misalnya, CodeT5+) sebagai *Shared Query/Code Encoder*.<br>• **Memory Bank:** Desain *Memory Bank* baru yang dapat **dicari (Searchable)** (untuk mencari $k$ tetangga terdekat) dan **diperbarui (Updateable)**.<br>• **Fungsi Rugi:** Menggunakan *Total Loss* $L = L^B + L^{HN}$, di mana $L^B$ adalah *Bimodal Contrastive Loss* dari *batch* saat ini, dan $L^{HN}$ adalah *Hard Negative Contrastive Loss* yang menggunakan $k$ *Hard Negatives* yang sudah di-*re-encode*.<br><br>**Temuan Kunci:**<br>1. **Kinerja SOTA:** CoCoHaNeRe mencapai SOTA pada *Code Search* di semua enam bahasa di CSN, melampaui SOTA sebelumnya (CoCoSoDa) rata-rata 4%.<br>2. **Peningkatan PTM:** Kerangka kerja ini secara signifikan meningkatkan kinerja PTM yang ada (misalnya, peningkatan Top-1 sebesar 20% pada ROBERTa).<br>3. **Efek Hard Negative:** *Hard Negative Contrastive Loss* ($L^{HN}$) berkontribusi lebih besar terhadap efektivitas model daripada *Bimodal Contrastive Loss* ($L^B$) saja.<br>4. **Skenario Sumber Daya Rendah (Zero-Shot):** Kinerja *zero-shot* CoCoHaNeRe melampaui kinerja model lain yang telah melalui *fine-tuning*.<br><br>**Kontribusi Utama:**<br>• Mengusulkan kerangka kerja CoCoHaNeRe dengan *Hard Negative Mining* yang dapat dibedakan (*differentiable*).<br>• Mendesain *Memory Bank* yang *Searchable* dan *Updateable* untuk mengambil *Hard Negatives* yang sesungguhnya.<br>• Mempercepat pelatihan dengan memaksa *Hard Negatives* berpartisipasi dalam *gradient descent* melalui *re-encoding*.<br>• Mencapai kinerja SOTA pada berbagai tugas *code retrieval* dan bahasa pemrograman. |

## 1. Pendahuluan & Masalah

*Code Search* bertujuan untuk menemukan potongan kode yang paling relevan dari *codebase* besar berdasarkan kueri bahasa alami (*Natural Language/NL*). Kualitas representasi semantik kode dan kueri sangat penting. Saat ini, metode *state-of-the-art* (SOTA) menggunakan paradigma *Contrastive Learning* (CL), yang bertujuan untuk memaksimalkan kesamaan antara pasangan positif (kode-kueri cocok) dan meminimalkan kesamaan antara pasangan negatif (kode-kueri tidak cocok). Untuk menghemat memori, pendekatan CL sebelumnya menggunakan *memory bank* (antrian besar) untuk menyimpan dan menggunakan kembali *embedding* negatif.

Namun, terdapat dua masalah utama yang membatasi efektivitasnya:
1.  **Kegagalan Membedakan Kode Serupa:** Karena pengambilan sampel negatif yang acak (atau kurang efektif), representasi semantik yang dipelajari oleh model yang ada tidak dapat membedakan dengan baik antara kode yang sangat mirip secara leksikal tetapi berbeda secara fungsional. Kasus-kasus ini dikenal sebagai **Hard Negative Examples** dan merupakan penyebab utama kesalahan model SOTA.
2.  **Pembelajaran Negatif yang Tidak Efektif:** *Embedding* dalam *memory bank* diambil dari inferensi sebelumnya dan digunakan langsung untuk perhitungan fungsi rugi tanpa *gradient descent*. Hal ini menghambat model untuk secara efektif mempelajari informasi semantik dari sampel negatif, terutama *Hard Negatives*.

::: tip Solusi yang Diusulkan
Kami mengusulkan **CoCoHaNeRe** (*Contrastive learning Code Search model with Hard Negative mining and Re-encoding*). Kerangka kerja ini secara eksplisit memperkenalkan **Hard Negative Examples**—yaitu, kode di *codebase* yang paling mirip dengan sampel positif—ke dalam pelatihan kontrasif. Untuk memastikan pembelajaran yang efektif, *Hard Negatives* ini **di-*re-encode* oleh *encoder*** di *batch* saat ini, sehingga sepenuhnya **berpartisipasi dalam *gradient descent***.
:::

## 2. Metodologi

CoCoHaNeRe adalah kerangka kerja CL yang diperluas untuk tugas *code search* dan *code similarity learning*. Ini terdiri dari empat komponen utama yang memungkinkan *Hard Negatives* berpartisipasi dalam pembelajaran:

### A. Searchable and Updateable Memory Bank
*   **Struktur:** Sebuah antrian *First-In-First-Out* (FIFO) berukuran tetap yang menyimpan pasangan $(DataID, Embedding)$ untuk Kueri dan Kode secara terpisah.
*   **Operasi Kunci:** Mendukung operasi **Search** (untuk mengambil $k$ tetangga terdekat (*$k$ nearest neighbors*) berdasarkan *cosine similarity*) dan **Update** (untuk mengganti *embedding* pada posisi tertentu, menjaga *memory bank* tetap terbaru).
*   **Implementasi:** Diimplementasikan pada memori GPU untuk meningkatkan efisiensi akses.

### B. Shared Query/Code Encoder
Menggunakan *encoder* PTM kode yang ada (seperti CodeT5+) sebagai *backbone*.

*   **Proses Re-Encoding:** *Embedding* dari *Hard Negatives* yang diambil dari *Memory Bank* **tidak digunakan secara langsung**. Sebaliknya, $DataID$ yang diambil digunakan untuk mengambil **teks asli** dari *Hard Negatives* dari *dataset* pelatihan. Teks ini kemudian **di-*re-encode*** oleh *Shared Encoder* yang dapat dilatih.
*   **Differentiable Negatives:** Proses *re-encoding* ini memastikan bahwa semua sampel negatif yang digunakan dalam *loss* ($\mathcal{L}^{HN}$) berpartisipasi penuh dalam *gradient descent* model.

### C. Bimodal Contrastive Loss (BCL)
$\mathcal{L}^B$ dihitung murni berdasarkan pasangan ($q_i, c_i$) di *batch* saat ini, di mana kode dari sampel lain dalam *batch* bertindak sebagai negatif.

$$L_{q_{i}}^{B}=-log\frac{exp(v_{q_{i}}\cdot v_{c_{i}})}{\sum_{j=1}^{n}exp(v_{q_{i}}\cdot v_{c_{j}})}$$
$$L_{c_{i}}^{B}=-log\frac{exp(v_{c_{i}}\cdot v_{q_{i}})}{\sum_{j=1}^{n}exp(v_{c_{i}}\cdot v_{q_{j}})}$$

Di mana $n$ adalah ukuran *batch*, dan $v$ adalah *embedding* dari *encoder*.

### D. Hard Negative Contrastive Loss (HNCL)
$\mathcal{L}^{HN}$ dihitung dengan menggabungkan pasangan positif dari *batch* saat ini dengan $k$ *Hard Negatives* yang diambil dari *Memory Bank* dan telah di-*re-encode*. *Hard Negatives* diambil menggunakan strategi *bi-knn* (mencari kode serupa untuk kueri $q_i$, dan kueri serupa untuk kode $c_i$).

$$L_{q_{i}}^{HN}=-log\frac{exp(v_{c_{i}}\cdot v_{q_{i}})}{exp(v_{c_{i}}\cdot v_{q_{i}})+\sum_{j=1}^{K}exp(v_{q_{i}}\cdot v_{c_{j}})}$$
$$L_{c_{i}}^{HN}=-log\frac{exp(v_{c_{i}}\cdot v_{q_{i}})}{exp(v_{c_{i}}\cdot v_{q_{i}})+\sum_{j=1}^{k}exp(v_{c_{i}}\cdot v_{q_{j}})}$$

Total *Loss* model adalah jumlah dari kedua kerugian:
$$L = L^{B} + L^{HN}$$

## 3. Detail Pengujian

### Dataset
*   **Code Search:** **CodeSearchNet (CSN)** (enam bahasa: Ruby, Java, Python, JavaScript, Golang, PHP), dan **XLCOST** (data dunia nyata, untuk validasi skenario nyata).
*   **Tugas Serupa:** **CoSQA** (*Code Question Answering*), **BigCloneBench** dan **POJ-104** (*Code Clone Detection*).

### Baseline
Metode berbasis IR (BOW, TF-IDF, Jaccard), dan PTM canggih (ROBERTa, CodeBERT, GraphCodeBERT, CodeT5, UniXcoder, SYNCOBERT, PLBART, SPT-Code, dan SOTA CL sebelumnya **CoCoSoDa**).

### Metrik Evaluasi
*   **Code Search (CSN, XLCOST):** **Mean Reciprocal Rank (MRR)** dan **Top-K Precision (R@K, K=1, 5, 10)**.

$$MRR=\frac{1}{|D|}\sum_{i=1}^{|D|}\frac{1}{Rank_{i}}$$
$$R@K=\frac{1}{|D|}\sum_{l=1}^{|D|}I(Rank_{l}\le K)$$

*   **Code Clone Detection:** **F1-score**, **Precision**, **Recall** (BigCloneBench), dan **Mean Average Precision (MAP@R)** (POJ-104).
*   **Code Question Answering:** **Accuracy** (CoSQA).

### Setting
*   **Backbone:** CodeT5+ (untuk hasil SOTA di CSN). UniXCoder (untuk XLCOST dan studi portabilitas).
*   **Hyperparameter:** Ukuran *Memory Bank* $8,096$, $k=10$ tetangga terdekat, *batch size* $32$, dan *learning rate* $3e^{-5}$.

## 4. Hasil Eksperimen

### Efektivitas CoCoHaNeRe (RQ1)
CoCoHaNeRe melampaui semua *baseline* SOTA di CSN.

| Model | Java | Python | PHP | JS | Ruby | Go | Avg (MRR) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| CodeBERT | 0.677 | 0.672 | 0.626 | 0.621 | 0.679 | 0.885 | 0.693 |
| UniXcoder | 0.688 | 0.715 | 0.650 | 0.644 | 0.708 | 0.903 | 0.718 |
| CoCoSoDa | 0.718 | 0.719 | 0.671 | 0.676 | 0.736 | 0.914 | 0.739 |
| **CoCoHaNeRe** | **0.764** | **0.756** | **0.711** | **0.714** | **0.755** | **0.927** | **0.771 (14.35% $\uparrow$ dari PTM Terburuk)** |

**Analisis:** CoCoHaNeRe mencapai MRR rata-rata **0.771**, melampaui SOTA sebelumnya (CoCoSoDa) rata-rata **4%**. Peningkatan terbesar terlihat pada dataset Java (6.41% $\uparrow$ dari CoCoSoDa), menunjukkan bahwa CoCoHaNeRe sangat efektif pada bahasa dengan kompleksitas kode yang lebih tinggi. Peningkatan yang lebih besar pada Top-1 ($R@1$) dibandingkan $R@10$ menegaskan bahwa model memprioritaskan penempatan hasil yang benar di posisi teratas.

### Studi Ablasi (RQ3)
Mempelajari kontribusi dari komponen *Loss* dan strategi pengambilan sampel *Hard Negative*.

| Metode | MRR (Java) | R@1 (Java) | Avg MRR |
| :--- | :--- | :--- | :--- |
| **bi-knn Full (CoCoHaNeRe)** | **0.749** | **0.663** | **0.747** |
| bi-knn -w/o BCL ($\mathcal{L}^{HN}$ Saja) | 0.733 | 0.645 | 0.726 |
| uni-knn Full | 0.732 | 0.645 | 0.722 |
| -w/o HNCL ($\mathcal{L}^B$ Saja) | 0.691 | 0.593 | 0.696 |

**Analisis:**
1.  **Kontribusi $\mathcal{L}^{HN}$:** Kerugian $\mathcal{L}^{HN}$ memiliki kontribusi yang jauh lebih besar dan lebih stabil daripada $\mathcal{L}^B$. Menghapus $\mathcal{L}^{HN}$ (-w/o HNCL) mengakibatkan penurunan signifikan, kembali mendekati *baseline* CodeT5+.
2.  **Strategi Sampling:** Strategi **bi-knn** (*searching code for query* dan *query for code*) secara konsisten lebih unggul daripada *uni-knn* (mencari kode serupa untuk kode), mendukung hipotesis bahwa distribusi *embedding* kode dan teks tidak selaras sempurna dan perlu dicari secara **bimodal**.

### Kinerja Tugas Retrieval Lain (RQ5)
RFMC-CS menunjukkan portabilitas yang kuat pada tugas *code retrieval* dan *similarity*.

| Model | POJ-104 (MAP@R) | BigCloneBench (F1-score) | CoSQA (Accuracy) |
| :--- | :--- | :--- | :--- |
| UniXcoder | 90.52 | 95.2 | 70.1 |
| CoCoSoDa | 91.29 | 95.0 | 75.0 |
| **CoCoHaNeRe** | **91.74** | **95.4** | **75.2** |

**Analisis:** CoCoHaNeRe unggul di CoSQA (Code Question Answering), dengan akurasi 75.2%, menunjukkan pembelajaran pencocokan semantik kode-teks yang kuat. Meskipun peningkatannya lebih kecil pada tugas *Code Clone Detection* (yang terutama melibatkan pencocokan kode-ke-kode), kinerja SOTA tetap dicapai, menegaskan bahwa pembelajaran *Hard Negatives* dapat ditransfer.

### Kinerja Zero-Shot (RQ7)
Menguji kemampuan model untuk memprediksi tanpa *fine-tuning* pada dataset bahasa tunggal.

| Model | Ruby | JS | Go | Python | Java | Php | Avg (MRR) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| CodeT5+ | 0.613 | 0.494 | 0.701 | 0.506 | 0.522 | 0.436 | 0.543 |
| CoCoSoDa | 0.706 | 0.609 | 0.831 | 0.642 | 0.693 | 0.599 | 0.680 |
| **CoCoHaNeRe** | **0.741** | **0.662** | **0.910** | **0.712** | **0.730** | **0.675** | **0.738 (8.57% $\uparrow$)** |

**Analisis:** Kinerja *zero-shot* CoCoHaNeRe (MRR rata-rata 0.738) **melampaui kinerja *fine-tuned* dari banyak *baseline* PTM** (misalnya, CodeBERT $0.693$ dan UniXcoder $0.718$). Ini menunjukkan bahwa pelatihan CL yang ditingkatkan dengan *Hard Negative Mining* telah mengajarkan model distribusi sampel uni-modal dan bimodal yang lebih terpadu, menjadikannya sangat efektif dalam skenario sumber daya rendah.

## 5. Kesimpulan

CoCoHaNeRe adalah kerangka kerja *Contrastive Learning* berbasis *Hard Negative Mining* yang sangat efektif untuk *Code Search*. Dengan mengganti penggunaan *embedding* *memory bank* yang tidak dapat dibedakan dengan *re-encoding Hard Negatives* yang diambil, CoCoHaNeRe memastikan bahwa model secara eksplisit dilatih untuk membedakan sampel semantik yang paling membingungkan. Hasilnya, model mencapai kinerja *state-of-the-art* baru, melampaui *baseline* terkuat rata-rata 4% dan menunjukkan portabilitas yang kuat di berbagai bahasa dan tugas.

::: info Dampak Praktis
CoCoHaNeRe sangat cocok untuk skenario *code retrieval* dengan **redundansi data tinggi** (misalnya, repositori kode perusahaan besar dengan banyak kode serupa). Model ini juga dapat digunakan dalam **skenario sumber daya rendah (zero-shot)**, di mana ia memberikan kinerja yang melampaui model lain yang telah di-*fine-tune*. Ini akan secara signifikan meningkatkan akurasi *code search* di lingkungan yang menantang.
:::