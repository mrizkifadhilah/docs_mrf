---
title: Review Paper - EXCS Mempercepat Pencarian Kode dengan Ekspansi Kode
description: Rangkuman paper tentang Percepatan Pencarian Kode menggunakan Ekspansi Kode (Scientific Reports, 2024).
head:
  - - meta
    - name: keywords
      content: code search, code expansion, retrieval efficiency, neural ranking, CodeEx, ExCS, BM25
---

# 019 - EXCS: accelerating code search with code expansion
Tautan (DOI) [10.1038/s41598-024-73907-6](https://doi.org/10.1038/s41598-024-73907-6)

**Penulis:** **Siwei Huang** ¹², **Bo Cai** ¹²*, **Yaoxiang Yu** ¹², **Jian Luo** ¹²

**Afiliasi:**
* ¹ School of Cyber Science and Engineering, Wuhan University, Wuhan 430072, China
* ² Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, Wuhan 430072, China

**Kronologi:** Received: 29 May 2024 • Accepted: 23 September 2024 • Available Online: 25 November 2024

<a href="https://www.scimagojr.com/journalsearch.php?q=21100200805&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=21100200805" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Scientific Reports 14 (2024) 29166<br>• **Topik:** Peningkatan efisiensi *code search* model *deep learning* tanpa mengorbankan akurasi.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Model *neural ranking* (terutama yang berbasis interaksi seperti SANCS/TabCS) sangat lambat dalam *online retrieval* pada *codebases* besar karena harus menghitung kesamaan atau interaksi dengan setiap dokumen kode. Ini memicu pertukaran (*trade-off*) antara akurasi tinggi (*deep learning*) dan kecepatan (*IR* tradisional).<br>• **Solusi:** Memperkenalkan **ExCS**, sebuah alat dua tahap yang menggabungkan: (1) **CodeEx** (model S-to-S untuk memperkaya kode di *offline phase* dengan memprediksi kueri potensial), dan (2) **IR-based filtering** (menggunakan BM25 pada kode yang diperluas) untuk membatasi *codebase* menjadi kandidat kecil, diikuti dengan *neural re-ranking* yang cepat di fase *online*.<br><br>**Contoh Penerapan:**<br>• **Akselerasi Pencarian:** Mengintegrasikan ExCS dengan model *baseline* (DeepCS, SANCS, TabCS, CARLCS-CNN) untuk mengurangi waktu pencarian pada *dataset* Java CodeSearchNet.<br>• **Ekspansi Kode:** Menggunakan model CodeEx untuk menghasilkan ekspansi *Natural Language* (NL) seperti: "This Java method, playVoice, randomly plays an audio clip from a library $\vert$ music song sound soundtrack" untuk fragmen kode `playVoice` yang diberikan.<br><br>**Metodologi:**<br>• **Model CodeEx:** Jaringan S-to-S berbasis CodeT5 yang melakukan **Ekspansi Keseluruhan** (*Overall Expansion*, Code-to-NL) dan **Ekspansi Kata Kunci** (*Keyword Expansion*, Code-to-Code) dengan *Homonym Search* dan *Global Attention* untuk menghasilkan ekspansi kode yang kaya semantik.<br>• **Kerangka ExCS:** Fase **Offline** menghasilkan ekspansi kode dan mengindeksnya menggunakan IR/BM25. Fase **Online** menggunakan BM25 pada indeks untuk mendapatkan $\mathbf{Top-k}$ kandidat, yang kemudian **dire-rank** menggunakan model *neural ranking* yang sudah dilatih sebelumnya.<br><br>**Temuan Kunci:**<br>1. **Efisiensi:** ExCS mencapai rata-rata $\mathbf{87.0\%}$ reduksi waktu pencarian (dibawah 100 ms/kueri) dibandingkan model *baseline* asli (1100 ms/kueri untuk DeepCS).<br>2. **Akurasi:** ExCS mempertahankan atau meningkatkan akurasi: DeepCS+ExCS meningkat **15.0%** MRR. CARLCS-CNN+ExCS meningkat **10.3%** MRR. Untuk model yang sangat akurat (SANCS), akurasi sedikit menurun (1.1% MRR) sebagai *trade-off* yang diperlukan untuk kecepatan.<br>3. **Komponen CodeEx:** Kombinasi istilah **disalin** (*copied*) dan **baru** (*new*) memberikan MRR tertinggi, menunjukkan bahwa kedua jenis istilah tersebut saling melengkapi dalam memperkaya kode.<br><br>**Kontribusi Utama:**<br>• Mengusulkan **CodeEx**, model *deep neural network* baru untuk memperkaya kode dengan urutan *Natural Language* yang relevan, memprediksi kueri potensial.<br>• Merancang **ExCS**, alat dua tahap yang memadukan CodeEx dan IR untuk meningkatkan efisiensi model *deep learning* yang ada secara dramatis.<br>• Mendemonstrasikan resolusi signifikan terhadap *trade-off* efisiensi-akurasi dalam *code search* skala besar.<br><br>**Dampak:**<br>• Memungkinkan model *neural ranking* yang kompleks dan akurat untuk digunakan secara praktis dalam *codebases* besar (seperti GitHub) dengan biaya waktu yang minimal, sehingga meningkatkan produktivitas pengembang. |

## 1. Pendahuluan & Masalah

Pencarian kode (*code search*) adalah tugas mendasar dalam pengembangan perangkat lunak, tetapi menghadapi kesulitan utama akibat **disparitas semantik** antara kueri bahasa alami dan kode sumber. Meskipun metode *deep learning* (*neural ranking models*) unggul dalam mengatasi celah semantik ini dan menawarkan akurasi superior, mereka memiliki kelemahan serius dalam **efisiensi *retrieval* online** pada *codebases* yang besar.

Model *deep learning*, khususnya yang **berbasis interaksi** (seperti TabCS dan SANCS), memerlukan perhitungan interaksi atau kesamaan vektor dengan **setiap** potongan kode dalam korpus untuk setiap kueri. Misalnya, model DeepCS dengan dimensi vektor 512 memerlukan sekitar $\mathbf{1}$ **miliar** perkalian dan penjumlahan untuk pemindaian linier tunggal pada korpus 1 juta *snippet*. Kebutuhan komputasi yang tinggi ini membuat *retrieval* menjadi jauh lebih lambat daripada teknik *Information Retrieval* (IR) tradisional.

::: tip Solusi yang Diusulkan
Kami memperkenalkan **ExCS** (*accelerating code search with code expansion*), sebuah alat dua tahap inovatif. ExCS menggunakan model **CodeEx** untuk memperkaya kode di fase *offline* (dengan memprediksi kueri potensial), dan kemudian menggunakan metode IR berbasis BM25 yang cepat untuk menyaring kumpulan kandidat yang ringkas di fase *online*, sebelum akhirnya menggunakan model *neural ranking* yang mahal hanya untuk *re-ranking* kandidat yang telah diperkecil. Tujuannya adalah mempercepat proses pencarian secara drastis tanpa mengorbankan akurasi.
:::

## 2. Metodologi

Kerangka kerja ExCS (Gambar 3) dirancang sebagai proses dua tahap: **Offline** (Persiapan dan Ekspansi Kode) dan **Online** (Penyaringan Cepat dan *Re-ranking*).

### A. Model Ekspansi Kode (CodeEx)

**CodeEx** adalah model *sequence-to-sequence* (S-to-S) yang didasarkan pada **CodeT5** (model *encoder-decoder* yang sadar akan pengidentifikasi) dan bertujuan untuk memperkaya kode dengan urutan bahasa alami (NL) yang relevan, memprediksi kueri yang mungkin.

$$E = RD([E_{o}:E_{k}])$$

Di mana $E$ adalah ekspansi keluaran, $E_{o}$ adalah ekspansi keseluruhan, dan $E_{k}$ adalah ekspansi kata kunci. $RD()$ menghilangkan istilah yang berulang.

1.  **Ekspansi Keseluruhan ($E_{o}$):** Tugas *cross-modal* (Code-to-NL). CodeT5 digunakan untuk mengambil seluruh token kode sebagai masukan dan menghasilkan $k$ kemungkinan urutan NL yang mencocokkan semantik kode.
    $$[s_{1}:...:s_{k}] = \text{Sample}(\text{CodeT5}(c), k)$$
2.  **Ekspansi Kata Kunci ($E_{k}$):** Tugas *code-to-code* yang melengkapi $E_{o}$. Ini melibatkan:
    *   **Ekstraksi Kata Kunci:** Mengekstrak nama metode, API, dan variabel. Skor relevansi ($R$) dihitung antara token-token ini ($T$) dan sampel NL terbaik ($s_1$) menggunakan mekanisme **Global Attention**:
        $$R=\sum(\text{softmax}(\frac{Q_{t}\cdot K_{s}^{T}}{\sqrt{d}}))$$
    *   **Pencarian Homonim:** Menggunakan representasi vektor (mirip word2vec) untuk menemukan istilah terdekat secara semantik (*homonyms*) dari kata kunci yang diekstrak.

*Loss Function* gabungan digunakan untuk pelatihan, mencakup *Cross-Entropy* (untuk kebenaran tata bahasa) dan **BLEU-N** (untuk cakupan istilah kueri):
$$L = k_{1}L_{1} + k_{2}L_{2}$$
Di mana $L_{1}$ adalah $BLEU-N$ dan $L_{2}$ adalah $CrossEntropy$.

### B. Kerangka ExCS (Dua Tahap)

1.  **Fase Offline:**
    *   ExCS menerapkan **CodeEx** pada korpus kode untuk mendapatkan kode yang diperluas ($\hat{C}$).
    *   Ekspansi ini ditambahkan sebagai anotasi pada potongan kode (meningkatkan semantik tanpa mengubah struktur).
    *   Kode yang diperluas disaring (menghapus *stop words* atau istilah yang tidak bermanfaat) untuk mendapatkan $\overline{C}$.
    *   $\overline{C}$ diindeks menggunakan **BM25** untuk *fast retrieval*, dan vektor kode disimpan untuk model *Siamese* (*DeepCS*).
2.  **Fase Online:**
    *   **IR-based Filtering:** Kueri NL ($q$) dimasukkan ke mesin pencari berbasis BM25 untuk mengambil $\mathbf{Top-k}$ hasil sebagai kandidat ($C_{k}$). (Optimal $k=1000$ dipilih berdasarkan *trade-off* akurasi-waktu).
    *   **Deep Learning-based Re-ranking:** Model *neural ranking* (Siamese atau Interaksi) hanya beroperasi pada $C_{k}$ yang ukurannya jauh lebih kecil.
        *   Untuk model **Siamese**, vektor kueri ($q$) disematkan dan kesamaan kosinus dihitung terhadap vektor kode kandidat yang sudah disimpan.
        *   Untuk model **Interaksi** (misalnya SANCS), fitur kode kandidat di-*embed* dan interaksi ($F$) dihitung bersama dengan kueri, lalu skor kesamaan dihitung.

## 3. Detail Pengujian

### Dataset
*   **Dataset:** Dataset **Java** dari **CodeSearchNet (CSN)**. Dataset pelatihan asli 394,471 disaring menjadi 192,031 data poin berkualitas tinggi.

### Baselines
*   **Model IR:** BM25.
*   **Model *Siamese*:** DeepCS.
*   **Model Berbasis Interaksi:** CARLCS-CNN, TabCS, SANCS.

### Metrik Evaluasi
*   **Akurasi:** *Success Rate* di $k$ (SR@k) dan *Mean Reciprocal Rank* (MRR).
    $$ \text{Success Rate}@k = \frac{1}{|Q|}\sum_{i=1}^{|Q|}\delta(FRank_{Q_{i}}\le k) $$
    $$ MRR=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{FRank_{Q_{i}}} $$
    Di mana $Q$ adalah kumpulan kueri, dan $FRank_{Q_{i}}$ adalah peringkat jawaban yang relevan untuk kueri ke-$i$.
*   **Efisiensi:** *Average Search Time* (ms/query).

## 4. Hasil Eksperimen

### RQ1: Akurasi dan Efisiensi ExCS

| Model | SR@1 | SR@5 | SR@10 | MRR | Waktu Pencarian | Peningkatan Waktu |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| DeepCS (Baseline) | 0.4125 | 0.5214 | 0.6173 | 0.4072 | 1100 ms/kueri | - |
| **ExCS + DeepCS** | **0.4712 (↑14.2%)** | **0.6061 (↑15.2%)** | **0.7037 (↑14.1%)** | **0.4685 (↑15.0%)** | **110 ms/kueri** | **$\mathbf{\sim 90.0\%}$** |
| SANCS (Baseline) | 0.6628 | 0.7509 | 0.8369 | 0.6435 | 500 ms/kueri | - |
| **ExCS + SANCS** | 0.6537 (↓1.1%) | 0.7341 (↓2.2%) | 0.8280 (↓1.2%) | 0.6367 (↓1.1%) | **70 ms/kueri** | **$\mathbf{\sim 86.0\%}$** |

**Analisis:**
*   **Efisiensi:** ExCS secara konsisten mengurangi waktu pencarian rata-rata hingga $\mathbf{86\%}$ sampai $\mathbf{90\%}$. Peningkatan efisiensi ini disebabkan oleh pengurangan basis kode yang harus diproses oleh model *neural ranking* (hanya 1000 kandidat).
*   **Akurasi:** Untuk model *Siamese* (DeepCS), ExCS **meningkatkan** akurasi secara signifikan (MRR $\mathbf{15.0\%}$ $\uparrow$), membuktikan bahwa pengayaan semantik kode dengan CodeEx menutup kesenjangan semantik. Untuk model yang sudah sangat kuat (SANCS), akurasi sedikit menurun ($\sim \mathbf{1.1\%}$ MRR $\downarrow$), karena tidak semua jawaban benar tercakup dalam 1000 kandidat Top-k IR.

### RQ2: Dampak Komponen ExCS

*   **Jumlah Kandidat ($k$):** Peningkatan $k$ (dari 100 hingga 1000) meningkatkan $Recall@k$ secara cepat (dari 0.738 menjadi 0.925), yang mengarah pada peningkatan MRR pada ExCS. Namun, peningkatan lebih lanjut (di atas $k=1000$) menghasilkan peningkatan MRR yang lambat tetapi biaya waktu yang terus meningkat. Nilai $\mathbf{k=1000}$ dipilih sebagai titik keseimbangan.
*   **Jenis Ekspansi:** Ekspansi dengan istilah **baru** (*new terms*) yang dihasilkan oleh CodeEx (misalnya, sinonim) lebih meningkatkan kinerja daripada hanya dengan istilah **disalin** (*copied terms*) (misalnya, nama variabel yang di-*re-weight*), tetapi kinerja terbaik dicapai ketika **keduanya** digabungkan (CSN+all).

## 5. Kesimpulan

Kami memperkenalkan **ExCS**, sebuah kerangka kerja dua tahap yang menggabungkan ekspansi kode *offline* (CodeEx) dan penyaringan IR *online* untuk mempercepat pencarian kode berbasis *deep learning*. ExCS berhasil memecahkan *trade-off* efisiensi-akurasi yang lazim, mencapai pengurangan waktu *retrieval* yang luar biasa sambil mempertahankan atau bahkan meningkatkan akurasi model *baseline* (seperti DeepCS).

::: info Dampak Praktis
ExCS menjadikan model *neural ranking* yang kompleks dan akurat dapat digunakan secara **praktis** pada *codebases* skala besar. Dengan mengurangi waktu pencarian rata-rata hingga di bawah 100 ms/kueri, ExCS secara langsung mengatasi hambatan komputasi terbesar dalam adopsi teknologi *deep learning* untuk *code search* di lingkungan industri.
:::