---
title: Review Paper - Codee Skema Tensor Embedding untuk Pencarian Kode Biner
description: Rangkuman paper tentang Codee, skema tensor embedding tak terawasi untuk pencarian kode biner yang efisien dan akurat (IEEE Transactions on Software Engineering, 2022).
head:
  - - meta
    - name: keywords
      content: binary code search, tensor embedding, tSVD, unsupervised learning, cross-architecture, basic block embedding
---

# 064 - Codee: A Tensor Embedding Scheme for Binary Code Search
Tautan (DOI) [https://doi.org/10.1109/TSE.2021.3056139]

**Penulis:** **Jia Yang** $^{1*}$, **Cai Fu** $^{1}$, **Xiao-Yang Liu** $^{2}$, **Heng Yin** $^{3}$, **Pan Zhou** $^{1}$

**Afiliasi:**
* $^{1}$ School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Hubei Engineering Research Center on Big Data Security, Wuhan 430074, China.
* $^{2}$ Electrical Engineering Department, Columbia University, New York, NY 10027, USA.
* $^{3}$ Department of Computer Science and Engineering, University of California, Riverside, CA 92521, USA.

**Kronologi:** Received: 10 Apr. 2020 • Revised: 16 Dec. 2020 • Accepted: 28 Jan. 2021 • Available Online: 2 Feb. 2021

<a href="https://www.scimagojr.com/journalsearch.php?q=18711&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=18711" alt="SCIMago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** IEEE Transactions on Software Engineering, Vol. 48, No. 7, Juli 2022<br>• **Topik:** Mengatasi tantangan variasi arsitektur CPU dan level optimasi *compiler* dalam pencarian kesamaan fungsi kode biner dengan skema *tensor embedding* tak terawasi.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Pencarian kode biner yang akurat dan efisien terhambat oleh variasi besar dari *compiler tool-chains*, opsi optimasi, dan arsitektur CPU. Skema yang ada menghadapi masalah seperti analisis berbasis teks yang tidak akurat, pencocokan grafik yang lambat, atau proses *deep learning* terawasi yang kompleks dan rentan *overfitting*.<br>• **Solusi:** Mengusulkan **Codee**, skema *tensor embedding* tak terawasi yang efisien dan akurat. Codee memadukan: (1) *Semantic-aware token embedding* (NLP-based); (2) *Basic block embedding* yang menangkap semantik instruksi dan struktur *Control Flow Graph* (CFG); dan (3) **Tensor Singular Value Decomposition (tSVD)** untuk mengkompresi vektor fitur fungsi variabel-panjang menjadi vektor tetap-panjang yang ringkas dan toleran terhadap ketidaksejajaran (*misalignment*).<br><br>**Contoh Penerapan:**<br>• Diuji pada empat *dataset* pustaka biner besar: **OpenSSL, Coreutils, libgmp, dan libcurl**, dikompilasi dengan berbagai arsitektur (x86-64, ARM, MIPS), *compiler* (GCC5.4.0, CLANG3.8.0), dan level optimasi (O0-O3).<br><br>**Metodologi:**<br>• **Token Embedding:** Menggunakan model *skip-gram* dengan *negative sampling* pada urutan token yang dihasilkan dari *random walk* pada **ICFG** (*Inter-procedural Control Flow Graph*) untuk mendapatkan representasi *semantic-aware*.<br>• **Basic Block Embedding:** Dimodelkan sebagai masalah *network representation learning*. Fungsi *loss* menggabungkan *Proximity* Orde Kedua (*CFG structural information*) dan *Loss* Dekomposisi Matriks Simetris (*basic block feature vector similarity*). Diselesaikan menggunakan **ADMM** (*Alternating Direction Method of Multipliers*).<br>• **Function Embedding:** Vektor fitur fungsi dikumpulkan ke dalam tensor $\mathcal{F}$ dan dikompresi menggunakan **tSVD** untuk menghasilkan *embedding* vektor fungsi tetap-panjang yang ringkas. tSVD secara alami mengatasi masalah *misalignment* berkat operasi *circular convolution*.<br>• **Pencarian:** Menggunakan **Locality Sensitive Hash (LSH)** untuk pencarian $O(1)$ yang cepat.<br><br>**Temuan Kunci:**<br>1. **Akurasi Terbaik:** Codee mengungguli skema SOTA seperti Asm2Vec, DeepBinDiff, Gemini, dan Safe dalam rata-rata akurasi pencarian di berbagai skenario (*cross-architecture* dan *cross-optimization-level*). Rata-rata *Recall* $\mathbf{82.5\%}$ (O0 vs O3) dan $\mathbf{92.4\%}$ (O1 vs O2) pada *cross-optimization*.<br>2. **Efisiensi Cepat:** Waktu generasi *embedding* rata-rata $\mathbf{5}$ hingga $\mathbf{10}$ kali lebih cepat daripada Gemini dan Asm2Vec, sebagian besar berkat sifat komputasi paralel dari tSVD dan tidak adanya pelatihan *deep learning* yang kompleks dan berulang.<br>3. **Vektor Ringkas:** Menghasilkan vektor fitur yang lebih pendek, yang memfasilitasi pencarian dan penyimpanan yang efisien.<br><br>**Kontribusi Utama:**<br>• Skema *tensor embedding* pertama yang diterapkan pada pencarian kode biner.<br>• Algoritma *basic block embedding* baru yang secara bersamaan menangkap semantik instruksi dan struktur CFG.<br>• Penggunaan **tSVD** untuk kompresi *function embedding* yang mengatasi variasi panjang dan *misalignment* fungsi. Mengusulkan algoritma *Dynamic Tensor Compression* untuk pembaruan *database* inkremental.<br><br>**Dampak:**<br>• Memberikan metode yang lebih cepat, lebih akurat, dan lebih tangguh untuk pencarian kode biner di lingkungan perangkat lunak yang beragam dan tidak transparan, sangat penting untuk analisis keamanan, deteksi plagiarisme, dan penyelesaian masalah hak cipta. |

## 1. Pendahuluan & Masalah

Pencarian kode biner (*binary code search*) bertujuan untuk menemukan fungsi biner yang serupa di repositori. Tantangan utama terletak pada pencapaian **akurasi** dan **efisiensi** di tengah variasi besar yang ditimbulkan oleh level optimasi *compiler* dan arsitektur CPU yang berbeda (*cross-platform* dan *cross-optimization level*).

Skema *embedding* yang ada, yang memetakan fungsi biner ke vektor numerik agar kode yang setara memiliki vektor yang berdekatan, terbagi dua:
1.  **Metode Berbasis *Deep Learning* (Gemini, Safe):** Membutuhkan pengumpulan data pelatihan berlabel berkualitas tinggi dalam jumlah besar dan rentan terhadap masalah *overfitting* atau proses pelatihan yang memakan waktu.
2.  **Metode Berbasis NLP (Asm2Vec, DeepBinDiff):** Secara langsung menerapkan teknik NLP pada kode biner, mengabaikan ketergantungan *control flow* dan *data flow* yang ketat yang membuat kode lebih terstruktur daripada bahasa alami, sehingga akurasi pencarian terdegradasi.

::: tip Solusi yang Diusulkan
Codee adalah skema *tensor embedding* tak terawasi yang efisien dan akurat. Codee menggunakan pemrosesan bahasa alami (NLP) untuk mendapatkan semantik instruksi, *network representation learning* untuk menangkap struktur CFG pada level *basic block*, dan memanfaatkan **Tensor Singular Value Decomposition (tSVD)** untuk kompresi *function embedding* yang ringkas, mengatasi variasi panjang dan ketidaksejajaran fungsi.
:::

## 2. Metodologi

Codee terdiri dari empat langkah utama: (1) Generasi *Token Embedding*, (2) Generasi *Basic Block Embedding* berbasis Model *Network Representation*, (3) Generasi *Function Embedding* berbasis Tensor, dan (4) Pencarian Kode Biner.

### A. Token Embedding Generation (NLP-Based)

Tujuannya adalah untuk menghasilkan *token embedding* (*opcode* dan *operand*) yang sadar semantik (*semantic-aware*).

1.  **Ekstraksi Urutan Token:** Menggunakan metode **node2vecWalk** (*2nd-order random walk*) pada **ICFG** (*Inter-procedural Control Flow Graph*) seluruh program. Ini menghasilkan urutan instruksi yang mencakup dependensi *control flow* dan informasi kontekstual instruksi.
2.  **Normalisasi:** Kode yang diserialisasi dinormalisasi (misalnya, nilai segera/imm, alamat memori dasar/mem, register umum, *pointer*).
3.  **Pelatihan:** Urutan instruksi yang dinormalisasi diumpankan ke model **skip-gram dengan *negative sampling***. Token (sebagai *node*) dilatih untuk menangkap semantik kontekstual dari urutan *random walk* ICFG. Proses ini hanya upaya sekali jalan (*one-time effort*) dan tidak memerlukan pengetahuan awal tentang bahasa *assembly*.

### B. Basic Block Embedding Generation

Setelah mendapatkan *token embedding*, vektor fitur *basic block* ($B$) dihitung dengan menggabungkan *opcode embedding* dengan rata-rata *operand embedding* untuk mendapatkan *instruction embedding*, yang kemudian dijumlahkan untuk mendapatkan vektor fitur *basic block*.

Model ini dirumuskan sebagai masalah *network representation learning* untuk menangkap fitur *intra-* dan *inter-basic-block*:

$$\min_{C} \sum_{i=1}^{n} \|S_i - C^H C_i\|_2^2 + \lambda \left(-\sum_{j \in N(i)} a_{ij} \log p(j|i)\right)$$

di mana:
*   $\sum_{i=1}^{n} \|S_i - C^H C_i\|_2^2$ adalah *loss* **Dekomposisi Matriks Simetris** (*Symmetric Matrix Decomposition*). $S$ adalah matriks afinitas kemiripan kosinus dari vektor fitur *basic block* ($B$), mewakili **semantik** *basic block*. $C$ adalah matriks *basic block embedding* yang dicari.
*   $\lambda \left(-\sum_{j \in N(i)} a_{ij} \log p(j|i)\right)$ adalah *loss* **Proximity Orde Kedua** (diadopsi dari LINE), mewakili **informasi struktural** (probabilitas transisi) dari CFG.
*   Diselesaikan menggunakan algoritma **ADMM** (*Alternating Direction Method of Multipliers*) untuk mencapai konvergensi yang cepat.

### C. Tensor-Based Function Embedding Generation

1.  **Representasi Tensor:** Semua *basic block embedding* ($C$) dalam suatu fungsi diratakan dan di-*padding* menjadi vektor fitur fungsi $f$ dengan panjang $n_1$ yang tetap. Semua vektor fitur fungsi dari $n_2$ program dan $n_3$ fungsi per program diatur menjadi tensor $\mathcal{F} \in \mathbb{R}^{n_1 \times n_2 \times n_3}$.
2.  **Kompresi tSVD:** tSVD (*Tensor Singular Value Decomposition*) digunakan untuk mengkompresi tensor $\mathcal{F}$ menjadi tensor $\mathcal{R}$ yang lebih ringkas dan tetap-panjang ($\mathcal{R} \in \mathbb{R}^{n_4 \times n_2 \times n_3}$, $n_4 \ll n_1, n_2$).
    $$\mathcal{F} = \mathcal{U} * \mathcal{S} * \mathcal{V}^{\dagger}$$
    Komputasi tSVD melibatkan operasi *circular convolution* yang secara inheren dapat mengatasi masalah **ketidaksejajaran** (*misalignment*) urutan *basic block* dalam fungsi yang berbeda, sambil mengekstrak fitur utama dan mengabaikan *noise*.
3.  **Pembaruan Dinamis:** Algoritma **Dynamic Tensor Compression** diusulkan untuk memperbarui *database embedding* secara inkremental tanpa menghitung ulang seluruh tensor.

## 3. Detail Pengujian

### Dataset
*   **Sumber:** Pustaka **OpenSSL, Coreutils, libgmp, dan libcurl**.
*   **Variasi:** Dikompilasi dengan arsitektur (x86-64, ARM, MIPS), *compiler* (GCC5.4.0, CLANG3.8.0), dan level optimasi (O0-O3).
*   **Ukuran:** Total $257.681$ fungsi *assembly*.
*   **Set Khusus:** *MixedOpenSSL Dataset* (*cross-architecture* dan *cross-optimization*) dan *x86-64CrossOptimizations Dataset* (*cross-optimization*).
*   **Ground Truth:** Ditetapkan menggunakan simbol *debug* keluaran *compiler*.

### Baseline
*   **Asm2Vec:** Berbasis NLP PV-DM model.
*   **Gemini:** Berbasis *Structure2Vec* NN (*Graph Embedding*).
*   **Safe:** Berbasis *Self-Attentive NN* dan *Bi-directional RNN* (i2v model).
*   **DeepBinDiff:** Berbasis *word2vec* dan TADW (*Text-associated DeepWalk*).
*   **Order Matters:** (Disebutkan, tetapi sulit direproduksi karena ketergantungan BERT/CNN yang kompleks dan data berlabel).

### Metrik Evaluasi
*   **ROC (Receiver Operating Characteristics):** Plot *True Positive Rate* (Recall) terhadap *False Positive Rate* (FPR).
*   **K-Recall:** Recall ketika memilih *top K* hasil.
*   **Rata-rata Recall dan Rata-rata Presisi:** Mengukur persentase pasangan fungsi yang benar dicocokkan antara dua program biner (misalnya, O0 vs O3).
*   **F1-Score:** Mengukur akurasi dan recall: $\text{F1-score} = \frac{2 \times \text{precision} \times \text{recall}}{\text{precision} + \text{recall}}$

## 4. Hasil Eksperimen

### A. Pencarian Kode *Cross-Optimization Levels* (O0 vs O3, O1 vs O2)

| | **O0 versus O3** (Rata-rata Recall) | **O1 versus O2** (Rata-rata Recall) |
| :--- | :--- | :--- |
| **Codee** | $\mathbf{0.825}$ | $\mathbf{0.924}$ |
| Asm2Vec | 0.748 | 0.893 |
| DeepBinDiff | 0.709 | 0.845 |
| Gemini | 0.779 | 0.899 |
| Safe | 0.817 | 0.922 |

**Analisis:**
*   **Kinerja Terbaik:** Codee mencapai *Recall* terbaik secara konsisten, bahkan dalam perbandingan yang paling sulit (O0 vs O3). Codee secara rata-rata lebih unggul dari Asm2Vec (7.7\% lebih tinggi) dan Gemini (4.6\% lebih tinggi) pada O0 vs O3.
*   **Toleransi Optimasi:** Perbandingan O1 vs O2 menghasilkan *recall* yang lebih tinggi untuk semua skema karena lebih banyak kesamaan yang dipertahankan. Codee tetap memimpin dengan *Recall* $\mathbf{92.4\%}$.

### B. Pencarian Kode *Cross-Architecture* (ARM vs x86-64, MIPS vs x86-64)

| | **ARM versus x86-64** (Rata-rata Recall) | **MIPS versus x86-64** (Rata-rata Recall) |
| :--- | :--- | :--- |
| **Codee** | $\mathbf{0.851}$ | $\mathbf{0.799}$ |
| Gemini | 0.683 | 0.708 |
| Safe | 0.810 | - |

**Analisis:** Codee menunjukkan ketahanan yang unggul terhadap variasi arsitektur, mengalahkan Gemini dan Safe dengan margin yang signifikan (Codee 85.1\% vs Gemini 68.3\% pada ARM vs x86-64). Hal ini menyoroti keefektifan *token embedding* multi-arsitektur dan operasi *circular convolution* tSVD yang menangani *misalignment* struktural yang disebabkan oleh arsitektur yang berbeda.

### C. Efisiensi Generasi Embedding

| Skema | Waktu Generasi Fitur Fungsi (Rata-rata) |
| :--- | :--- |
| Codee | **Paling Cepat** ($< 0.043$ detik per fungsi) |
| Gemini | $\approx 0.1764$ detik (100 *epochs*) |
| Asm2Vec | $\approx 2$ detik |
| DeepBinDiff | $\approx 1.97$ detik |

**Analisis:** Codee adalah skema yang paling efisien, berjalan rata-rata $\mathbf{5}$ kali lebih cepat daripada Gemini dan $\mathbf{10}$ kali lebih cepat daripada Asm2Vec. Kecepatan ini berasal dari sifat tak terawasi Codee (menghindari pelatihan berulang yang kompleks) dan sifat komputasi paralel dari tSVD.

## 5. Kesimpulan

Codee berhasil menyajikan skema *tensor embedding* tak terawasi yang secara signifikan meningkatkan akurasi dan efisiensi pencarian kode biner, terutama dalam skenario *cross-optimization* dan *cross-architecture* yang menantang. Dengan memadukan semantik instruksi melalui NLP, struktur CFG melalui *network representation learning*, dan mengatasi variasi serta *misalignment* melalui kompresi tSVD, Codee menetapkan *state-of-the-art* baru.

::: info Dampak Praktis
Codee memberikan solusi yang lebih cepat dan lebih akurat untuk tugas-tugas kritis seperti menemukan kerentanan *n-day* (ditunjukkan dalam studi kasus Heartbleed dan Shellshock), deteksi *clone code*, dan analisis keamanan. Metode ini memvalidasi penggunaan teknik analisis data berbasis tensor dalam analisis kesamaan kode biner.
:::