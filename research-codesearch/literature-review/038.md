---
title: Review Paper - GraphCS Code Search Berbasis RGCN dengan Fine-Grained Matching
description: Rangkuman paper tentang metode code search berbasis Relational Graph Convolutional Network (RGCN) dan fine-grained matching (Journal of Software, 2024).
head:
  - - meta
    - name: keywords
      content: code search, relational graph convolutional network, fine-grained matching, graph embedding, DeepCS, GraphSearchNet
---

# 038 - 基于关系图卷积网络的代码搜索方法 (Code Search Method Based on Relational Graph Convolutional Network)
Tautan (DOI) [10.13328/j.cnki.jos.006910](http://www.jos.org.cn/1000-9825/6910.htm)

**Penulis:** **周光有** $^{1*}$, **谢琦** $^{1}$, **余啸** $^{2}$ (ZHOU Guang-You$^{1*}$, XIE Qi$^{1}$, YU Xiao$^{2}$)

**Afiliasi:**
* $^1$ 华中师范大学计算机学院 (School of Computer Science, Central China Normal University, Wuhan 430079, China)
* $^2$ 武汉理工大学计算机与人工智能学院 (School of Computer Science and Artificial Intelligence, Wuhan University of Technology, Wuhan 430070, China)

**Kronologi:** Received: 2022-03-24 • Revised: 2022-06-14, 2022-11-03 • Accepted: 2023-01-22 • Available Online: 2023-07-13

<a href="https://www.scimagojr.com/journalsearch.php?q=19913&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=19913" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** 软件学报 (Journal of Software), 2024, 35(6): 2863-2879<br>• **Fokus:** Mengembangkan model *code search* yang mampu menangkap **semantik mendalam** dan melakukan **pencocokan fine-grained** antara kueri teks dan kode sumber.<br><br>**Masalah & Solusi:**<br>• **Masalah 1 (Semantik Dangkal):** Metode berbasis sekuens (misalnya, DeepCS) tidak mampu menangkap semantik mendalam dan fitur dependensi jarak jauh (*long-range dependency*) dari kode sumber yang kompleks.<br>• **Masalah 2 (Kurangnya Fine-Grained Matching):** Metode berbasis *graph embedding* yang lebih baru (misalnya, GraphSearchNet) tidak melakukan operasi pencocokan (*matching*) interaktif *fine-grained* pada tingkat *node* antara *code graph* dan *text graph*.<br>• **Masalah 3 (Mengabaikan Hubungan Global):** GraphSearchNet mengabaikan hubungan global antar-graf (*graph-level global relationship*) dari *code graph* dan *text graph* secara keseluruhan.<br>• **Solusi:** Mengusulkan **GraphCS** (*Code Search Method Based on Relational Graph Convolutional Network*). GraphCS melakukan **pencocokan *fine-grained* tingkat *node*** menggunakan *Multi-View Matching Function* dan menangkap **hubungan global** menggunakan *Neural Tensor Networks* (NTN) setelah mengodekan *Text Graph* dan *Code Graph* menggunakan **RGCN** (*Relational Graph Convolutional Network*).<br><br>**Contoh Penerapan:**<br>• Evaluasi pada dua *dataset* publik: **FB-Java** (kode Java dari proyek Android Facebook) dan **CSN-Python** (sub-dataset Python dari CodeSearchNet Corpus).<br><br>**Metodologi:**<br>• **Representasi Data:** Mengubah kueri teks menjadi *Text Graph* (berbasis *Phrase Parsing Tree* & urutan kata) dan kode sumber menjadi *Code Graph* (berbasis AST yang diperkuat dengan *Child*, *NextToken*, dan *LastLexicalUse* *edge*).<br>• **Graph Embedding:** Menggunakan **RGCN** dengan *weight sharing* untuk mendapatkan *node embedding* awal dari kedua graf.<br>• **Semantic Matching:** **Node-level matching** (fine-grained) menggunakan *Multi-View Matching Function* ($f_m$) untuk menginteraksikan dan memperbarui *node embedding*. **Graph-level matching** (global) menggunakan *Attention Mechanism* untuk mendapatkan *global context-aware graph embedding* ($h_p, h_q$), yang kemudian dimasukkan ke **NTN** untuk mendapatkan vektor similaritas global.<br>• **Fungsi Loss:** Menggunakan *margin loss* untuk mengoptimalkan model.<br><br>**Temuan Kunci:**<br>1. **Akurasi SOTA:** GraphCS secara konsisten melampaui *baseline* SOTA (DeepCS dan GraphSearchNet) di semua metrik (MRR dan S@k) pada kedua *dataset*.<br>2. **Keunggulan Fine-Grained Matching:** Strategi pencocokan *Node-level* (berbasis $f_m$) menyumbang peningkatan kinerja yang lebih besar dibandingkan strategi *Graph-level* (berbasis NTN).<br>3. **Kinerja Stabil:** Model menunjukkan kinerja yang stabil dan kuat terhadap perubahan ukuran kandidat kode (hingga C=500), dengan S@5 dan S@10 konsisten di atas $95\%$ pada data uji.<br><br>**Kontribusi Utama:**<br>• Mengintegrasikan RGCN untuk pengodean graf dengan struktur relasional yang kaya pada kode dan teks.<br>• Mengusulkan strategi pencocokan *Multi-View* pada tingkat *node* untuk interaksi *fine-grained* lintas-modalitas.<br>• Menerapkan NTN untuk secara eksplisit menangkap hubungan global tingkat-graf.<br><br>**Dampak:**<br>• Secara signifikan meningkatkan akurasi *code search* dengan menjembatani kesenjangan semantik yang kompleks antara bahasa alami dan kode melalui pemodelan struktur graf yang kaya dan mekanisme pencocokan yang cermat. |

## 1. Pendahuluan & Masalah

*Code search* adalah bidang interdisipliner penting antara *Natural Language Processing* (NLP) dan *Software Engineering* yang bertujuan menemukan *snippet* kode yang relevan dari repositori besar berdasarkan kueri bahasa alami. Kemampuan ini sangat penting untuk meningkatkan penggunaan ulang kode dan efisiensi pengembang.

Metode awal berbasis *sequence model* seperti DeepCS, meskipun menunjukkan hasil yang menjanjikan, tidak dapat menangkap **semantik mendalam** atau fitur dependensi jarak jauh pada kode karena struktur data dan aliran kontrolnya yang kompleks. Untuk mengatasi ini, metode yang lebih baru seperti GraphSearchNet menggunakan *Graph Neural Networks* (GNN) untuk menangkap semantik mendalam kode. Namun, GraphSearchNet masih memiliki dua kelemahan krusial:
1.  **Kurangnya Fine-Grained Matching:** Ia mengabaikan pencocokan interaktif (*cross-graph matching*) antara *node* dari *code graph* dan *text graph*, yang penting untuk menyelaraskan dua modalitas yang berbeda secara sintaksis dan semantik.
2.  **Mengabaikan Hubungan Global:** Ia tidak secara eksplisit membandingkan atau mencocokkan informasi kontekstual global dari kedua graf pada tingkat-graf.

::: tip Solusi yang Diusulkan
Studi ini mengusulkan model **GraphCS** berbasis **Relational Graph Convolutional Network (RGCN)**. GraphCS menerapkan: (1) **RGCN** untuk pengodean *Text Graph* dan *Code Graph* yang kaya relasi. (2) **Pencocokan Fine-Grained Tingkat-Node** menggunakan *Multi-View Matching Function* untuk interaksi lintas-graf. (3) **Pencocokan Tingkat-Graf Global** menggunakan **Neural Tensor Network (NTN)** untuk secara eksplisit menangkap hubungan global.
:::

## 2. Metodologi

Model GraphCS terdiri dari tiga tahap utama: (1) *Graph Construction* dan *Graph Embedding*, (2) *Semantic Matching* (tingkat *node* dan *graph*), dan (3) *Similarity Search*.

### A. Graph Construction dan RGCN Embedding
Kedua modalitas data diubah menjadi *Multi-Relational Graph* untuk memanfaatkan RGCN.
*   **Code Graph ($G_p$):** Dibangun berdasarkan *Abstract Syntax Tree* (AST) dan diperkaya dengan tiga jenis *edge* yang kaya relasi: **Child** (*edge* AST), **NextToken** (mempertahankan urutan sekuensial program), dan **LastLexicalUse** (menghubungkan variabel dengan penggunaan leksikal terbarunya).
*   **Text Graph ($G_q$):** Dibangun berdasarkan *Phrase Parsing Tree* (struktur sintaksis bahasa alami) yang diperkaya dengan *edge* urutan kata.

Setelah konstruksi, **RGCN** digunakan untuk mengodekan kedua graf. RGCN dipilih karena kemampuannya memodelkan data multi-relasional (graf dengan berbagai jenis *edge*). Kedua RGCN *encoder* berbagi parameter (*weight sharing*), yang membantu generalisasi dan mengurangi *overfitting*.

$$ h_{i}^{(l+1)}=\sigma(W_{0}^{(l)}h_{i}^{(l)}+\sum_{r\in\mathcal{R}}\sum_{j\in N_{i}^{r}}\frac{1}{|N_{i}^{r}|}W_{r}^{(l)}h_{j}^{(l)}) $$

Di mana $h_{i}^{(l+1)}$ adalah *hidden state* baru untuk *node* $i$, $r$ adalah jenis relasi, $\mathcal{R}$ adalah himpunan jenis relasi, dan $W_r^{(l)}$ adalah matriks bobot yang spesifik untuk relasi $r$.

### B. Node-Level Matching Strategy (Fine-Grained)
Strategi ini mengatasi kelemahan Mismatching Problem dengan melakukan operasi *cross-graph matching* sebelum agregasi akhir.

1.  **Cross-Graph Attention:** Untuk setiap *node* kueri $q_i$, skor perhatian dihitung dengan semua *node* kode $p_j$ menggunakan *cosine similarity*:
    $$ \alpha_{i,j}=cos(q_{i},p_{j}),\forall j=1,...,N $$
2.  **Aggregasi Embeding Lintas-Graf:** Bobot $\alpha_{i,j}$ digunakan untuk menghitung rata-rata tertimbang dari semua *node* kode ($p_j$), menghasilkan representasi graf kode keseluruhan ($\tilde{\vec{h}}_{p}^{i}$) dari perspektif *node* kueri tertentu $q_i$:
    $$ \tilde{h}_{p}^{i}=\frac{1}{N}\sum_{j}^{N}\alpha_{i,j}p_{j},p_{j}\in\mathcal{V}_{p} $$
3.  **Multi-View Matching Function ($f_m$):** $f_m$ kemudian diterapkan untuk menyelaraskan *node* kueri $q_i$ dengan representasi $\tilde{\vec{h}}_{p}^{i}$ yang baru diagregasi. Ini menghasilkan representasi *node* kueri yang diperbarui ($\hat{q}_i$) yang telah berinteraksi secara *fine-grained* dengan graf kode.
    $$ \hat{q}_{i}=\hat{f}_{m}(q_{i},\tilde{\vec{h}}_{p}^{i},w_{m}),q_{i}\in\mathcal{V}_{q} $$
    Fungsi $f_m$ ini menggunakan *element-wise multiplication* ($\odot$) dengan vektor bobot ($\vec{w}_k$) di berbagai pandangan (*k views*), mirip dengan *Multi-Head Attention* tetapi dengan parameter yang lebih sedikit, untuk mengukur relevansi.

Setelah pembaruan *node* ($\hat{q}_i$ dan $\hat{p}_j$), representasi graf akhir ($S_q, S_p$) diperoleh melalui operasi **FCMax** (*Full-Connected + Maxpooling*), yang fokus pada fitur yang paling signifikan. Skor similaritas ($sim_1$) dihitung menggunakan *cosine similarity* dari $S_q$ dan $S_p$.

### C. Graph-Level Matching Strategy (Global)
Strategi ini mengatasi kelemahan mengabaikan hubungan global dengan menggunakan **NTN** pada *initial node embedding*.

1.  **Global Context-Aware Embedding:** Representasi graf global ($h_p, h_q$) dihitung menggunakan mekanisme *attention* sederhana pada *initial node embedding* ($H_p, H_q$) untuk mendapatkan representasi yang lebih bermakna.
    $$ h_{p}=\sum_{j=1}^{N}(a_{j}\cdot p_{j}), \text{ di mana } a_{j}=Sigmoid(p_{j}^{T}\cdot C) $$
2.  **Neural Tensor Network (NTN):** NTN digunakan untuk membandingkan $h_p$ dan $h_q$ pada $k$ dimensi berbeda, yang menghasilkan vektor similaritas global ($NTN_{(h_p, h_q)}$) yang menangkap berbagai pola kesamaan.
    $$ NTN_{(h_{i},h_{j})}=\sigma(h_{i}^{T}\cdot W^{[1\dots k]}\cdot h_{j}+V[\begin{matrix}h_{i}\\ h_{j}\end{matrix}]+b) $$
    Vektor ini kemudian dilewatkan melalui jaringan *Fully Connected* untuk mendapatkan skor similaritas global ($sim_2$).

### D. Model Training
Skor similaritas akhir adalah rata-rata tertimbang dari skor *Node-level* ($sim_1$) dan *Graph-level* ($sim_2$):
$$ score(q,p)=F(sim_{1},sim_{2})=\sum_{i=1}^{2}a_{i}\cdot sim_{i} $$
Model dioptimalkan menggunakan fungsi **margin loss**:
$$ \mathcal{L}(\theta)=\sum_{<q,p,p^{-}>\in\mathbb{T}}max(0,\delta-score(q,p)+score(q,p^{-})) $$
Di mana $\delta$ adalah nilai *margin* ($0.5$).

## 3. Detail Pengujian

### Dataset
*   **FB-Java:** $216,259$ data pelatihan, $9,000$ validasi, $1,000$ uji (Java).
*   **CSN-Python:** $312,189$ data pelatihan, $17,215$ validasi, $1,000$ uji (Python).
*   **Real Query Test:** $50$ kueri dari CodeSearch Challenge pada kode repositori CodeSearch Challenge yang besar ($1.15$ juta *snippet* kode).

### Baseline
Tujuh model *deep learning* SOTA dipilih, termasuk:
*   NBOW, BiRNN, ID-CNN, Self-Attention (Model dasar sekuensial)
*   UNIF (Model *word embedding* yang ditingkatkan)
*   **DeepCS** (Baseline sekuensial berbasis LSTM)
*   **GraphSearchNet** (Baseline berbasis GNN)

### Metrik Evaluasi
Dua metrik utama dari *Information Retrieval* digunakan:
1.  **Mean Reciprocal Rank (MRR):** Mengukur kualitas *ranking* pada hasil pencarian.
    $$ MRR=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{1}{FRank_{q}} $$
    Di mana $FRank_q$ adalah peringkat hasil yang benar pertama untuk kueri $q$.
2.  **Success Rate at $k$ (S@k):** Persentase kueri yang memiliki setidaknya satu hasil benar di antara $k$ hasil teratas.
    $$ S@k=\frac{1}{|Q|}\sum_{q=1}^{|Q|}(FRank_{q}\le k) $$

## 4. Hasil Eksperimen

### Perbandingan dengan Baseline (Pada Test Set)
GraphCS menunjukkan kinerja SOTA yang signifikan di kedua *dataset*:

| Model | MRR (%) | S@1 (%) | S@5 (%) | S@10 (%) |
| :--- | :--- | :--- | :--- | :--- |
| **FB-Java** | | | | |
| DeepCS | 78.9 | 70.6 | 89.6 | 94.2 |
| GraphSearchNet | 71.3 | 64.5 | 88.6 | 89.6 |
| **GraphCS** | **87.1** | **80.1** | **95.2** | **96.6** |
| **CSN-Python** | | | | |
| DeepCS | 64.4 | 52.2 | 78.2 | 88.3 |
| GraphSearchNet | 73.9 | 65.3 | 84.2 | 89.1 |
| **GraphCS** | **88.3** | **80.6** | **97.7** | **98.8** |

**Analisis:** GraphCS meningkatkan MRR secara substansial, terutama pada CSN-Python (meningkat dari $73.9\%$ menjadi $88.3\%$ dibandingkan GraphSearchNet). S@1 (probabilitas *Top 1* benar) GraphCS mencapai lebih dari $80\%$, jauh lebih tinggi daripada DeepCS ($52.2\%$) atau GraphSearchNet ($65.3\%$ pada Python). Ini menunjukkan akurasi *fine-grained* yang jauh lebih baik.

### Pengaruh Semantic Matching (Ablation Study)
Studi ablasi menguji kontribusi komponen pencocokan (Tabel 7):
*   **RGCN:** Hanya menggunakan RGCN tanpa strategi pencocokan. (MRR $75.5\%$ di Java)
*   **Node-level:** Hanya strategi pencocokan *Node-level* ($sim_1$). (MRR $84.4\%$ di Java)
*   **Graph-level:** Hanya strategi pencocokan *Graph-level* ($sim_2$). (MRR $71.2\%$ di Java)
*   **GraphCS:** Kombinasi keduanya ($sim_1$ dan $sim_2$). (MRR $87.1\%$ di Java)

**Analisis:**
1.  Model sederhana **RGCN** masih lebih kuat dari banyak *baseline*, memvalidasi penggunaan *Graph Structure* dan RGCN.
2.  Strategi **Node-level** memberikan kontribusi kinerja paling besar (MRR naik dari $75.5\%$ ke $84.4\%$ di Java), membuktikan bahwa pencocokan *fine-grained* menggunakan *Multi-View Matching Function* adalah komponen yang paling efektif.
3.  **GraphCS** (kombinasi) mencapai hasil terbaik, menunjukkan kedua strategi pencocokan bersifat komplementer.

### Uji Kueri Dunia Nyata (FRank)
Pengujian pada 50 kueri nyata menunjukkan bahwa GraphCS memiliki lebih sedikit kasus kegagalan pencarian (NF) (7 kasus) dibandingkan GraphSearchNet (11 kasus), dan sebagian besar hasil benarnya memiliki peringkat ($FRank$) yang lebih kecil (lebih tinggi).

## 5. Kesimpulan

Model **GraphCS** berhasil mengatasi keterbatasan model *code search* berbasis sekuens dan berbasis GNN sebelumnya dengan mengintegrasikan **RGCN** untuk pengodean struktur yang kaya relasi, dan memperkenalkan dua strategi pencocokan: **Multi-View Matching Function** untuk *fine-grained* *node-level matching* dan **Neural Tensor Network** untuk *global* *graph-level matching*.

Hasil eksperimen yang ekstensif menunjukkan bahwa GraphCS mencapai akurasi pencarian SOTA dan stabil terhadap berbagai ukuran kandidat, yang membuktikan efektivitas strateginya dalam menjembatani kesenjangan semantik yang kompleks antara bahasa alami dan kode.

::: info Dampak Praktis
GraphCS memberikan peningkatan yang signifikan dalam akurasi *code search*, terutama dalam menemukan hasil yang benar di peringkat teratas (*Top 1*). Strategi pencocokan *fine-grained* yang diusulkan dapat diadopsi oleh model *cross-modal* lain untuk meningkatkan interaksi representasi pada tingkat yang lebih detail, yang sangat penting untuk aplikasi perangkat lunak cerdas.
:::