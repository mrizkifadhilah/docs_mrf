---
title: Review Paper - Fine-Tuning CodeBERT untuk Pencarian Kode Smart Contract
description: Rangkuman paper tentang pendekatan fine-tuning CodeBERT untuk menjembatani semantic gap dalam pencarian kode smart contract (Wuhan University Journal of Natural Sciences, 2023).
head:
  - - meta
    - name: keywords
      content: code search, smart contract, pre-trained code models, CodeBERT, fine-tuning, program analysis, machine learning
---

# 050 - Fine-Tuning Pre-Trained CodeBERT for Code Search in Smart Contract
Tautan (DOI) [https://doi.org/10.1051/wujns/2023283237]

**Penulis:** **JIN Huan** ᵃ, **LI Qinying** ᵃ

**Afiliasi:**
* ᵃ Information Engineering College, Jiangxi University of Technology, Nanchang 330000, Jiangxi, China

**Kronologi:** Received: 2022-09-23 • Revised: [Tidak Ada Data] • Accepted: [Tidak Ada Data] • Available Online: [Tidak Ada Data]

<a href="https://www.scimagojr.com/journalsearch.php?q=26195&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=26195" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Wuhan University Journal of Natural Sciences, Vol. 28, No. 3, Halaman 237–245 (2023)<br>• **Topik:** Pemanfaatan model bahasa pra-terlatih (*pre-trained*) CodeBERT untuk pencarian kode semantik pada *smart contract* (Solidity) menggunakan kueri bahasa alami.<br><br>**Masalah & Solusi:**<br>• **Masalah:** *Smart contract* memerlukan keamanan dan konsumsi gas yang rendah, sehingga menuntut alat pencarian kode semantik yang efisien. Model pencarian kode yang ada menghadapi **kesenjangan semantik** (*semantic gap*) antara kode program (PL) dan kueri bahasa alami (NL), dan model pra-terlatih seperti CodeBERT belum dilatih pada bahasa *smart contract* (misalnya Solidity).<br>• **Solusi:** Mengusulkan pendekatan **fine-tuning** pada model pra-terlatih **CodeBERT** menggunakan pasangan <komentar, *code snippet*> Solidity yang dikumpulkan dari Etherscan.io. Model yang telah di-*fine-tune* kemudian digunakan untuk membangun mesin pencari kode khusus *smart contract*, menjembatani kesenjangan semantik dan meningkatkan akurasi.<br><br>**Contoh Penerapan:**<br>• Pengembangan mesin pencari kode khusus untuk *smart contract* Solidity, memungkinkan pengembang mencari *snippet* kode yang aman dan berbiaya rendah menggunakan kueri bahasa alami.<br><br>**Metodologi:**<br>• **Koleksi Data:** Mengumpulkan $\mathbf{80.723}$ pasangan <komentar, *code snippet*> dari $\mathbf{30.844}$ berkas kontrak Solidity terpercaya dari Etherscan.io.<br>• **Pemrosesan Data:** Tokenisasi komentar (NL) dan *code snippet* fungsi (PL) menjadi ID token, sambil menghapus komentar di dalam badan fungsi untuk menjaga semantik kode.<br>• **Fine-Tuning:** Melakukan pelatihan inkremental pada kerangka CodeBERT (bertujuan *Masked Language Modeling*, MLM, dan *Replaced Token Detection*, RTD) menggunakan data Solidity dengan perbandingan 8:1:1 untuk data *fine-tuning*, validasi, dan pengujian.<br>• **Pencarian Kode:** Menggunakan CodeBERT yang telah di-*fine-tune* untuk menghasilkan vektor kueri ($Vector_Q$) dan vektor *code snippet* ($Vector_{C_i}$), kemudian menghitung kesamaan (*similarity*) dan memeringkat hasilnya (*Top-k*).<br><br>**Temuan Kunci:**<br>1. **Efektivitas Fine-Tuning Skala Kecil:** Bahkan dengan hanya $\mathbf{1\%}$ data *fine-tuning*, kinerja model CodeBERT meningkat secara dramatis (kenaikan MRR sebesar $\mathbf{0.3307}$ dan kenaikan Recall@k $\mathbf{0.2109-0.3551}$ dari model pra-terlatih).<br>2. **Performa Superior:** CodeBERT yang di-*fine-tune* ($\mathbf{100\%}$ data) secara signifikan mengungguli model tradisional (BM25, Word2vec) dan CodeBERT pra-terlatih, mencapai Recall@100 hampir $\mathbf{0.97}$ dan MRR $\mathbf{0.6515}$.<br>3. **Kesenjangan Semantik Teratasi:** Hasil Recall@1 yang tinggi ($\mathbf{0.6237}$) menunjukkan model efektif merekomendasikan kode yang benar bahkan dalam kasus yang paling sulit.<br>4. **Kegagalan Word2vec:** Word2vec menunjukkan kinerja terburuk karena kegagalannya memahami hubungan NL-PL akibat kurangnya data pelatihan (dibandingkan dengan model pra-terlatih).<br><br>**Kontribusi Utama:**<br>• Mengusulkan dan memvalidasi pendekatan fine-tuning CodeBERT sebagai solusi untuk pencarian kode Solidity/Smart Contract.<br>• Menyediakan dataset pasangan <komentar, kode> Solidity yang masif dan terverifikasi dari Etherscan.io.<br>• Mengembangkan mesin pencari kode *smart contract* berbasis CodeBERT yang menunjukkan kinerja superior terhadap model *state-of-the-art* lainnya.<br><br>**Dampak:**<br>• Memfasilitasi praktik *code reuse* yang lebih aman dan efisien bagi pengembang *smart contract*, yang pada akhirnya mengurangi kerentanan dan biaya transaksi (*gas*). |

## 1. Pendahuluan & Masalah

*Smart contract*, program yang berjalan secara otomatis pada platform terdesentralisasi seperti Ethereum, memerlukan tingkat **keamanan tinggi** dan **konsumsi gas** (biaya transaksi) yang rendah. Mengingat kerentanan pada kontrak dapat menyebabkan kerugian ekonomi yang parah (seperti kasus DAO tahun 2016), pengembang sangat membutuhkan alat untuk mendaur ulang (*reuse*) *snippet* kode yang telah terbukti aman dan berbiaya rendah dari *codebase* skala besar (seperti Etherscan dan Open Zeppelin).

Kebutuhan ini mendorong permintaan akan mesin pencari kode yang efektif yang dapat mencocokkan kueri **bahasa alami (NL)** dengan kode program (**PL**) yang relevan. Namun, metode pencarian kode tradisional (*information retrieval*, *word embedding*) menghadapi masalah **kesenjangan semantik** (*semantic gap*) antara NL dan PL, seringkali membutuhkan *dataset* yang sangat besar. Meskipun model bahasa pra-terlatih (*pre-trained*) seperti **CodeBERT** dapat menjembatani kesenjangan ini, CodeBERT yang ada saat ini tidak dilatih pada bahasa *smart contract* seperti **Solidity**.

::: tip Solusi yang Diusulkan
Kami mengusulkan pendekatan **fine-tuning** pada model **CodeBERT** yang telah pra-terlatih menggunakan dataset pasangan <komentar, *code snippet*> yang dikumpulkan secara khusus dari *smart contract* Solidity di Etherscan.io. Model yang telah di-*fine-tune* ini digunakan untuk membangun mesin pencari kode khusus *smart contract* yang akurat, memanfaatkan kemampuan *few-shot learning* dari model pra-terlatih.
:::

## 2. Metodologi

Metode ini melibatkan empat langkah utama: Koleksi Data, Pemrosesan Data, *Fine-Tuning* CodeBERT, dan Konstruksi Mesin Pencari.

### A. Koleksi dan Pemrosesan Dataset

Dataset dikumpulkan dari $\mathbf{40.302}$ berkas kontrak Solidity (*.sol) yang telah diverifikasi di Etherscan.io. Setelah menghilangkan berkas yang tidak dapat dikompilasi oleh alat Slither, tersisa $\mathbf{30.844}$ berkas terpercaya.

Kami mengekstrak pasangan <komentar, *code snippet*> untuk setiap fungsi yang memiliki badan (*body*) dan komentar. Pasangan yang identik dihapus untuk menjamin keaslian evaluasi, menghasilkan total $\mathbf{80.723}$ pasangan.

### B. Tokenisasi dan Pemetaan ID

Untuk memasukkan data ke model, komentar (NL) dan *code snippet* (PL) diubah menjadi bilangan matematis (*token ids*).

1.  **Tokenisasi Komentar:** Komentar (NL) dipecah langsung berdasarkan spasi.
2.  **Tokenisasi Kode:** Komentar di dalam badan fungsi dihilangkan untuk menjaga semantik kode. Kode kemudian dipecah berdasarkan spasi, mempertahankan simbol khusus (seperti `[`, `]`, `;`) karena simbol tersebut mengandung semantik kode.
3.  **Pemetaan ID:** *Tokenizer* dari CodeBERT dasar (berisi 50.265 pemetaan) digunakan untuk memetakan setiap token ke ID unik. Urutan ID diisi (*padded*) atau dipotong hingga panjang maksimum yang ditentukan ($N$) menggunakan token khusus.
### C. CodeBERT Fine-Tuning

CodeBERT mengikuti arsitektur Transformer bidireksional multi-lapisan, dilatih menggunakan dua tujuan: *Masked Language Modeling* (MLM) dan *Replaced Token Detection* (RTD).

1.  **MLM:** Memprediksi token asli yang telah ditutupi (*masked*) dari pasangan NL-PL yang dimasukkan. Fungsi kerugiannya adalah:
    $$Loss_{MLM}(\theta)=\sum_{i\in m^{w}\cup m^{c}}-log~p^{D_1}(x_{i}|w^{masked},c^{masked})$$
    di mana $p^{D_1}$ adalah diskriminator yang memprediksi token dari kosakata yang luas.
2.  **RTD:** Dilatih untuk menentukan apakah sebuah token yang rusak (*corrupted*) adalah token asli atau token yang diganti, yang merupakan masalah klasifikasi biner. Fungsi kerugiannya adalah:
    $$Loss_{RTD}(\theta)=\sum_{i=1}^{|x|}\{\delta(i)log~p^{D_2}(x^{corrupt},i)+[1-\delta(i)][1-log p^{D_2} ([x^{corrupt} ], i)]\}$$
    di mana $\delta(i)$ adalah fungsi indikator yang bernilai 1 jika token tersebut asli ($x_i^{corrupt}=x_i$) dan 0 jika sebaliknya.

Data $\mathbf{80.723}$ pasangan dibagi menjadi 8:1:1 untuk *fine-tuning* ($\mathbf{64.579}$ pasangan), validasi ($\mathbf{8.072}$ pasangan), dan pengujian ($\mathbf{8.072}$ pasangan). Selama *fine-tuning*, vektor NL dan PL dihitung, skor kesamaan dihitung, dan parameter model diperbarui berdasarkan *loss* yang dihitung.

### D. Konstruksi Mesin Pencari Kode

CodeBERT yang telah di-*fine-tune* digunakan untuk mencari *snippet* kode yang paling cocok untuk suatu kueri.

1.  Semua *code snippet* di *code base* diubah menjadi ID token dan dimasukkan ke dalam CodeBERT untuk mendapatkan vektor kode $Vector_{C_1}, \dots, Vector_{C_n}$.
2.  Kueri diubah menjadi ID token untuk mendapatkan vektor kueri $Vector_Q$.
3.  Kesamaan ($similarity$) antara $Vector_Q$ dan matriks vektor kode ($M$) dihitung.
4.  Hasil diperingkat, dan $\mathbf{Top-k}$ *code snippet* yang memiliki skor tertinggi dipilih sebagai hasil pencarian.

## 3. Detail Pengujian

### Parameter
*   **GPU:** NVIDIA GeForce RTX 3090
*   **Epoch:** 10
*   **Panjang Maks PL:** 256; **Panjang Maks NL:** 128
*   **Tingkat Pembelajaran:** 2E-5; **Batch Size Pelatihan:** 32; **Batch Size Evaluasi:** 64
*   **Optimizer:** AdamW; **Fungsi Loss:** CrossEntropyLoss()

### Baseline
1.  **BM25:** Metode *information retrieval* tradisional. Diimplementasikan menggunakan Python package $\texttt{gensim.summarization.bm25.BM25}$.
2.  **Word2vec:** Metode *word embedding* yang dilatih pada *dataset fine-tuning* Solidity. Vektor dihitung dengan merata-ratakan dan menjumlahkan vektor token, kemudian kesamaan dihitung menggunakan **cosine similarity**.
3.  **Pre-trained CodeBERT:** Model CodeBERT asli tanpa *fine-tuning* pada data Solidity.

### Metrik Evaluasi
1.  **Recall@k ($Recall@k$):** Persentase item yang relevan yang ditemukan dalam $\mathbf{Top-k}$ hasil pencarian. Nilai yang lebih tinggi menunjukkan kemampuan pencarian yang lebih baik.
    $$Recall@k=\frac{|R_k|}{|R_t|}$$
    di mana $R_k$ adalah jumlah item yang relevan di *Top-k* hasil, dan $R_t$ adalah jumlah total item yang relevan.
2.  **Mean Reciprocal Rank ($MRR$):** Mengukur posisi urutan hasil yang direkomendasikan. Nilai yang lebih tinggi menunjukkan bahwa jawaban yang benar muncul lebih dekat ke peringkat teratas. $MRR$ dihitung pada $k=10$.
    $$MRR=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{Rank_{Q_i}}$$
    di mana $|Q|$ adalah jumlah kueri dan $Rank_{Q_i}$ adalah peringkat hasil benar pertama untuk kueri $Q_i$.

## 4. Hasil Eksperimen

### Evaluasi dengan Data Fine-Tuning Terbatas

| Metrics | Pre-trained CodeBERT | Fine-tuned CodeBERT-1 | Fine-tuned CodeBERT-5 | Fine-tuned CodeBERT-10 | Fine-tuned CodeBERT-20 | Fine-tuned CodeBERT-50 | Fine-tuned CodeBERT-100 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Recall@1 | 0.1876 | 0.5427 | 0.5886 | 0.6096 | 0.6131 | 0.6213 | **0.6237** |
| Recall@10 | 0.4469 | 0.7441 | 0.8018 | 0.8455 | 0.8688 | 0.8709 | **0.8723** |
| MRR | 0.2637 | 0.5942 | 0.6247 | 0.6346 | 0.6481 | 0.6502 | **0.6515** |

*   **Peningkatan Dramatis:** Hanya dengan $\mathbf{1\%}$ data *fine-tuning*, Recall@k dan MRR model meningkat tajam (MRR naik $\mathbf{0.3305}$).
*   **Kecukupan Data:** Ketika data *fine-tuning* melebihi $\mathbf{10\%}$, Recall@1 mencapai lebih dari $\mathbf{0.6}$, menunjukkan bahwa sejumlah kecil data sudah cukup untuk adaptasi tugas spesifik.

### Perbandingan dengan Model Tradisional

| Metrics | BM25 | Word2vec | Pre-trained CodeBERT | Fine-tuned CodeBERT-100 |
| :--- | :--- | :--- | :--- | :--- |
| Recall@1 | 0.2427 | 0.1176 | 0.1876 | **0.6237** |
| Recall@10 | 0.5041 | 0.2469 | 0.4469 | **0.8723** |
| Recall@100 | 0.7148 | 0.3439 | 0.7039 | **0.9698** |
| MRR | 0.2642 | 0.1237 | 0.2637 | **0.6515** |

*   **Performa Superior:** CodeBERT yang di-*fine-tune* secara signifikan mengungguli semua *baseline*. Recall@100 mendekati $\mathbf{0.97}$ berarti jawaban yang benar hampir selalu ada di antara 100 hasil teratas. Recall@1 sebesar $\mathbf{0.62}$ dan MRR $\mathbf{0.65}$ menunjukkan pemeringkatan jawaban yang sangat efektif.
*   **Kinerja Word2vec:** Word2vec menunjukkan kinerja terburuk, kemungkinan besar karena kekurangan data pelatihan untuk memahami hubungan NL-PL yang kompleks.

## 5. Kesimpulan

Penelitian ini berhasil menunjukkan bahwa pendekatan *fine-tuning* pada model pra-terlatih **CodeBERT** menggunakan dataset spesifik *smart contract* Solidity adalah metode yang sangat efektif untuk pencarian kode semantik. Pengumpulan $\mathbf{80.723}$ pasangan <komentar, kode> dari Etherscan.io dan aplikasinya dalam *fine-tuning* telah secara efektif menjembatani kesenjangan semantik antara kueri bahasa alami dan kode Solidity.

Hasil eksperimen mengkonfirmasi bahwa model yang di-*fine-tune* memiliki kinerja yang jauh lebih unggul, bahkan dengan jumlah data yang relatif sedikit, dibandingkan dengan model tradisional (BM25, Word2vec) dan CodeBERT tanpa *fine-tuning*.

::: info Dampak Praktis
Metode *fine-tuning* ini membuka jalan bagi pembangunan mesin pencari kode yang sangat efisien dan akurat, secara langsung mendukung pengembang *smart contract* untuk mengidentifikasi dan menggunakan kembali *snippet* kode yang **aman dan berbiaya rendah**. Keberhasilan dalam tugas pencarian kode juga mengindikasikan potensi yang besar untuk memperluas metode *fine-tuning* CodeBERT ini ke tugas-tugas Solidity lainnya, seperti deteksi klon dan peringkasan kode.
:::