---
title: Review Paper - JSTTR Model untuk Code Search
description: Rangkuman paper tentang model pra-pemrosesan kode JSTTR (Joint AST Statement Tree and Token Common Representation) untuk pencarian kode (Cluster Computing, 2025).
head:
  - - meta
    - name: keywords
      content: Code Search, Pre-processing, AST Statement Tree, ST-Tree, Feature information, Joint Representation
---

# 003 - Effective code pre-processing model for code search

**Penulis:** **Mengge Fang** ᵃ, **Haize Hu** ᵃ,*, **Silun Liao** ᵃ,*

**Afiliasi:**
* ᵃ School of Computer Science and Engineering, Guangxi Normal University, Yucai Road, Guilin 541000, Guangxi, China

**Kronologi:** Received: 9 September 2024 • Revised: 13 June 2025 • Accepted: 2 July 2025 • Published online: 29 September 2025

<a href="https://www.scimagojr.com/journalsearch.php?q=24596&tip=sid&clean=0" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=24596" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Cluster Computing, Vol 28, No 930 (2025)<br>• **Penerbit:** Springer Science+Business Media, LLC<br>• **Topik:** Pra-pemrosesan kode sumber, Peningkatan akurasi pencarian kode.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Terjadi *semantic gap* yang signifikan antara kueri bahasa alami (ambigu) dan kode sumber (terstruktur). Metode pra-pemrosesan kode yang ada (seperti ASTNN, Token+Path/SBT) cenderung kehilangan informasi sintaksis atau semantik penting.<br>• **Solusi:** Mengusulkan **JSTTR** (*Joint AST Statement Tree and Token Common Representation*), sebuah model pra-pemrosesan baru yang menggabungkan representasi **ST-Tree** (untuk sintaksis) dan **Token** (untuk semantik) untuk menangkap fitur kode secara komprehensif.<br><br>**Contoh Penerapan (Input $\to$ Proses $\to$ Output):**<br>• *Input:* Kueri ("how to get free disk space") $\to$ Potongan Kode Java (`private static String getFreeDiskSpace(String volume) { ... }`).<br>• *Proses JSTTR:* Kode dipecah menjadi *Statement Trees* (ST) $\to$ Kata dikonversi menjadi Token $\to$ Keduanya digabungkan (*Joint Embedding*) $\to$ Diberi skor kesamaan dengan kueri (menggunakan BERT).<br>• *Output:* Potongan kode yang paling relevan (*ranked*).<br><br>**Metodologi:**<br>• **Arsitektur:** JSTTR memproses kode menjadi *Statement Tree Vector* dan *Token Vector*, yang kemudian digabungkan untuk menghasilkan *Code Vector*. Model representasi heterogen (BERT/CodeBERT) digunakan untuk *embedding* dan pelatihan.<br>• **Pengujian:** Data Java dan Python dari CodeSearchNet. Baseline: Token+Path, Token+SBT, ASTNN.<br><br>**Temuan Kunci:**<br>1. **Kinerja Superior (Java):** JSTTR mencapai MRR **0.8431**, mengungguli baseline utama (Token+Path, Token+SBT, ASTNN) dengan peningkatan masing-masing 6.45%, 3.12%, dan 3.18%.<br>2. **Sinergi Optimal:** Studi ablasi mengonfirmasi bahwa struktur internal JSTTR, yang menggabungkan ST-Tree (sintaksis) dan Token (semantik), adalah yang paling optimal.<br><br>**Kontribusi Utama:**<br>• Integrasi pertama pohon pernyataan AST (*AST statement trees* atau ST-Tree) ke dalam penelitian *code search*.<br>• Mengembangkan model JSTTR yang mengintegrasikan sintaksis (via ST-Tree) dan semantik (via Token) secara sistematis.<br><br>**Dampak:**<br>• **Akurasi Pencarian:** Secara langsung meningkatkan akurasi sistem *code search* dengan menyediakan representasi fitur kode yang lebih tepat dan komprehensif.<br>• **Arah Riset Baru:** Menetapkan arah riset baru yang menjanjikan dalam bidang pra-pemrosesan kode sumber untuk tugas *code search*.<br><br>**Tautan (DOI):** 10.1007/s10586-025-05644-y |

## 1. Pendahuluan & Masalah

Pencarian kode (*code search*) merupakan tugas penting dalam pengembangan perangkat lunak modern, yang memungkinkan pengembang mencari kode yang relevan dengan memasukkan deskripsi fungsionalitas dalam bahasa alami. Tantangan utamanya adalah menjembatani **kesenjangan semantik** antara kueri bahasa alami yang ambigu dan kode sumber yang formal serta terstruktur. Meskipun model *deep learning* telah banyak digunakan untuk *embedding* (*heterogeneous representations*), langkah **pra-pemrosesan kode sumber** sering kali diabaikan, padahal ini krusial untuk ekstraksi fitur yang akurat. Pendekatan yang ada, seperti yang hanya mengandalkan *word-based* atau yang membuang banyak node AST (seperti SST), cenderung kehilangan hubungan sintaksis atau detail leksikal.

::: tip Solusi yang Diusulkan
Model **JSTTR** (*Joint AST Statement Tree and Token Common Representation*) diusulkan sebagai model pra-pemrosesan kode yang pertama kali mengintegrasikan *AST Statement Tree* (ST-Tree) untuk menangkap **struktur sintaksis** bersama dengan representasi *token* untuk menangkap **informasi semantik** leksikal, memastikan ekstraksi fitur kode yang komprehensif.
:::

## 2. Metodologi

Model JSTTR memproses potongan kode sumber melalui dua jalur paralel sebelum digabungkan menjadi vektor akhir.

### A. Konstruksi Statement Tree (ST-Tree)

Metode ini didasarkan pada *AST parsing* (Pohon Sintaksis Abstrak). Alih-alih memproses seluruh kode menjadi satu pohon utuh (AST tradisional), pra-pemrosesan **ST-Tree** membagi kode sumber menjadi beberapa pernyataan (*statement*), di mana setiap pernyataan menjadi unit pemrosesan yang disebut *Statement Tree* (ST) sub-pohon. ST-Tree bertujuan menyederhanakan struktur pohon AST sambil tetap mempertahankan integritas struktur sintaksis kode secara efektif.

### B. Konstruksi Token

Pra-pemrosesan *token* membagi kode menjadi unit-unit dasar leksikal (kata atau token). Proses ini melibatkan penghapusan simbol dan spasi, pemisahan kata majemuk (*camel case*), dan bertujuan menangkap informasi semantik leksikal.

### C. Joint Embedding dan Pelatihan

*   **Penggabungan:** *Statement Tree Vector* dan *Token Vector* (yang dihasilkan oleh *Heterogeneous Representation Model*) digabungkan (*concatenated*) untuk membentuk *Code Vector* akhir.
*   **Model:** Model *Bidirectional Encoder Representations from Transformers* (BERT), khususnya **CodeBERT**, digunakan sebagai model representasi heterogen karena kinerjanya yang unggul dalam tugas *code search*.
*   **Tujuan Pelatihan:** Memaksimalkan kesamaan kosinus antara *Code Vector* dan *Comments Vector* (kueri bahasa alami) menggunakan fungsi *loss* dengan mengimplementasikan *Masked Language Modeling* (MLM).

## 3. Detail Pengujian

### Dataset
Dataset yang digunakan adalah subset **Java** dan **Python** dari **CodeSearchNet**.
*   Java Train: 454.451 sampel, Test: 26.909 sampel.
*   Python Train: 412.178 sampel, Test: 22.176 sampel.

### Baseline Model
Untuk perbandingan:
*   **Token+Path** dan **Token+SBT**: Model optimal yang diajukan oleh Gu et al. (2021), menggabungkan token dengan struktur Simple Syntax Tree (SST) yang lebih sederhana.
*   **ASTNN**: Model optimal yang diajukan oleh Zhang et al. (2019), menggunakan ST-Tree.

### Metrik Evaluasi
Metrik yang digunakan untuk mengevaluasi efisiensi *code search* adalah:
*   **Mean Reciprocal Rank (MRR):** Mengukur posisi hasil relevan pertama.
*   **Normalized Discounted Cumulative Gain (NDCG):** Menggabungkan relevansi dan peringkat.
*   **Accuracy (ACC):** Tingkat kebenaran prediksi.
*   **Recall@k ($R@k$):** Proporsi hasil yang benar dalam $k$ hasil teratas.

Rumus MRR dan NDCG:

$$MRR = \frac{1}{|S|} \sum_{i=1}^{|S|} \frac{1}{rank_i}$$

$$NDCG = \frac{1}{|Q|}\sum_{j=1}^{k}\frac{2^{r_{j}}-1}{\log_{2}(1+j)}$$

## 4. Hasil Eksperimen

### Perbandingan dengan Metode Pra-pemrosesan Eksisting (Java)

Hasil menunjukkan JSTTR melampaui semua baseline pada hampir semua metrik, khususnya di dataset Java.

| Model | MRR | NDCG | ACC | R@1 | R@5 | R@10 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Token+Path | 0.7920 | 0.148 | 0.9196 | 0.7836 | 0.8830 | 0.9250 |
| Token+SBT | 0.8176 | 0.181 | 0.9276 | 0.8208 | 0.8988 | 0.9329 |
| ASTNN | 0.8171 | 0.107 | 0.9222 | 0.7962 | 0.8879 | 0.9273 |
| **JSTTR** | **0.8431** | 0.145 | **0.9360** | **0.8309** | **0.9060** | **0.9380** |

*   **Peningkatan MRR JSTTR (vs Baseline):** +6.45% (vs Token+Path), +3.12% (vs Token+SBT), dan +3.18% (vs ASTNN).
*   **Analisis:** Kinerja JSTTR yang superior didorong oleh kemampuan ST-Tree yang lebih efektif dalam mengkarakterisasi struktur sintaksis dibandingkan ASTNN, ditambah kompensasi semantik yang akurat dari *token*.

### Analisis Ablasi (JSTTR-ST vs JSTTR-TK)

Ablasi dilakukan dengan menghilangkan salah satu komponen inti JSTTR:
*   **JSTTR-ST:** Menghilangkan struktur Statement Tree.
*   **JSTTR-TK:** Menghilangkan struktur Token.

| Model | MRR | NDCG | ACC | R@1 | R@5 | R@10 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **JSTTR** | **0.8431** | **0.145** | **0.9336** | **0.8309** | **0.9060** | **0.9380** |
| JSTTR-ST | 0.8027 | 0.146 | 0.9054 | 0.8012 | 0.8784 | 0.9102 |
| JSTTR-TK | 0.8231 | 0.127 | 0.9176 | 0.8207 | 0.8992 | 0.9190 |

*   **Kesimpulan Ablasi:** Kinerja JSTTR-ST lebih buruk daripada JSTTR-TK, yang mengindikasikan bahwa **struktur Statement Tree memiliki dampak yang lebih signifikan** terhadap model JSTTR dibandingkan struktur Token. Hal ini menegaskan pentingnya menangkap struktur sintaksis secara optimal dalam tugas *code search*.

## 5. Kesimpulan

JSTTR adalah model pra-pemrosesan *code search* yang berhasil mengintegrasikan *AST Statement Tree* dan representasi *token* untuk secara komprehensif menangkap fitur sintaksis dan semantik kode sumber. Hasil eksperimen pada dataset Java dan Python (CodeSearchNet) mengonfirmasi bahwa JSTTR secara signifikan meningkatkan akurasi pencarian kode dibandingkan model-model baseline sebelumnya. Studi ablasi juga memvalidasi bahwa struktur internal JSTTR adalah optimal dan sinergis.

::: info Dampak Praktis
JSTTR menetapkan standar baru untuk pra-pemrosesan kode, membuktikan bahwa ekstraksi fitur kode yang tepat—melalui kombinasi representasi sintaksis terstruktur (ST-Tree) dan semantik leksikal (Token)—adalah kunci untuk menjembatani kesenjangan antara bahasa alami dan kode sumber, menghasilkan hasil *code search* yang lebih akurat.
:::