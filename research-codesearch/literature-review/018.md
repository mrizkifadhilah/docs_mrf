---
title: Review Paper - Model Ekstensi Umpan Balik yang Ditingkatkan Niat untuk Pencarian Kode
description: Rangkuman paper tentang Peningkatan Akurasi Pencarian Kode melalui Ekstensi Kueri Berbasis Niat (Information and Software Technology, 2025).
head:
  - - meta
    - name: keywords
      content: Code search, Query expansion, Intentional enhancement, Feedback mechanisms, DeepCS, UNIF
---

# 018 - An intent-enhanced feedback extension model for code search
[https://doi.org/10.1016/j.infsof.2024.107589]

**Penulis:** **Haize Hu** ᵃ*, **Mengge Fang** ᵃ, **Jianxun Liu** ᵇ

**Afiliasi:**
* ᵃ Guangxi Normal University, School of Computer Science and Engineering & School of Software, Guilin, 541001, Guangxi, China
* ᵇ Hunan University of Science and Technology, School of Computer Science and Engineering, Xiangtan, 411100, Hunan, China

**Kronologi:** Received: 4 November 2023 • Revised: 20 September 2024 • Accepted: 23 September 2024 • Available Online: 27 September 2024

<a href="https://www.scimagojr.com/journalsearch.php?q=18732&tip=sid" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=18732" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Information and Software Technology 177 (2025) 107589<br>• **Topik:** Peningkatan akurasi *code search* melalui **Ekstensi Kueri** yang memperhatikan Niat Pencari (*Searcher's Intent*).<br><br>**Masalah & Solusi:**<br>• **Masalah 1 (Semantic Gap):** Terdapat perbedaan semantik, sintaksis, dan struktural yang signifikan antara **Kueri** (*Query*) yang pendek (2–3 kata, dari Pencari) dan **Deskripsi** (*Description*) yang panjang (20–30 kata, dari Pengembang). Kueri seringkali tidak secara akurat menyampaikan niat yang diinginkan.<br>• **Masalah 2 (Fokus QE yang Ada):** Teknik *Query Expansion* (QE) yang ada sebagian besar hanya berfokus pada penambahan istilah tanpa secara memadai mempertimbangkan niat pencari.<br>• **Solusi:** Mengusulkan model **QEIEF** (*Query Expansion with Intent Enhancement Feedback*). QEIEF memanfaatkan hasil pencarian awal, mengidentifikasi **Deskripsi** dari kode yang paling relevan (Top-K) sebagai sumber *feedback*, dan menggabungkannya kembali dengan kueri awal untuk memperluas jangkauan semantik kueri secara iteratif, didorong oleh niat pencari.<br><br>**Contoh Penerapan:**<br>• **Pencarian Kode:** Menerapkan QEIEF pada model dasar *DeepCS* dan *UNIF* menggunakan dua *dataset* (CodeSearchNet dan CodesearchQE buatan sendiri).<br>• **Ekstensi Kueri:** Kueri awal "write chars" diperluas menggunakan deskripsi kode yang relevan (*feedback*) untuk meningkatkan akurasi *matching* dengan kode sumber.<br><br>**Metodologi:**<br>• **Dataset Kustom:** Membuat *dataset* CodesearchQE (Query-Code-Description) berbasis Stack Overflow untuk studi QE, berfokus pada Python dan Java.<br>• **Arsitektur Dasar:** Menggunakan *DeepCS* dan *UNIF* sebagai model dasar. *DeepCS* menggunakan **BiLSTM** untuk mengekstrak fitur kode (Methodname, API, Tokens, Description) dan memetakan kode serta deskripsi ke ruang vektor bersama.<br>• **Mekanisme QEIEF (Pencarian Online):** (1) Masukkan kueri awal ke model terlatih. (2) Hitung kesamaan kosinus dengan basis data vektor kode. (3) **Judgment Module** memeriksa apakah akurasi hasil pencarian saat ini telah meningkat. (4) Jika ya, ambil **Deskripsi** dari **Top-N** kode hasil terbaik sebagai umpan balik niat. (5) Gabungkan Deskripsi ini dengan kueri awal (*Concatenation*) untuk membentuk kueri yang diperluas. (6) Ulangi langkah (1) hingga (5) selama T kali iterasi, atau hingga akurasi tidak lagi meningkat.<br><br>**Temuan Kunci:**<br>1. **Gap Kueri vs Deskripsi:** Deskripsi menghasilkan hasil pencarian yang jauh lebih unggul (peningkatan R@1 hingga 613% pada DeepCS/Python) dibandingkan Kueri, memvalidasi adanya disparitas semantik yang besar.<br>2. **Efektivitas QEIEF:** QEIEF meningkatkan kinerja *code search* secara substansial: hingga $\mathbf{272\%}$ MRR pada DeepCS/Python (CodesearchQE) dan $\mathbf{23.53\%}$ MRR pada UNIF (CodeSearchNet) dibandingkan tanpa QEIEF.<br>3. **Keunggulan Kompetitif:** QEIEF mengungguli metode QE *baseline* lainnya (WordNet, FP, QECK, NQE) di sebagian besar metrik dan skenario.<br>4. **Keterbatasan QEIEF:** QEIEF **tidak cocok** diterapkan pada model *pre-trained* seperti GraphCodeBERT, karena menghasilkan ketidakcocokan pasangan input (Query-Code vs Description-Code) dan sensitivitas terhadap ukuran *dataset* yang terbatas.<br><br>**Kontribusi Utama:**<br>• Mengajukan model QE **QEIEF** yang unik, berpusat pada Niat Pencari dan mekanisme *feedback* berbasis Deskripsi Pengembang.<br>• Membangun dan merilis *dataset* CodesearchQE (Query-Code-Description) untuk memfasilitasi penelitian *query expansion*.<br>• Menunjukkan bahwa niat yang diekstrak dari deskripsi pengembang adalah sumber yang paling efektif untuk ekstensi kueri.<br><br>**Dampak:**<br>• Menyediakan kerangka kerja baru untuk mengatasi masalah utama dalam *code search* (disparitas semantik), yang secara signifikan meningkatkan akurasi *code search* dan efisiensi pengembang. |

## 1. Pendahuluan & Masalah

*Code search* telah menjadi bagian integral dari proses pengembangan perangkat lunak, dengan lebih dari $90\%$ pengembang mengandalkan pencarian kode di repositori *open-source* untuk modifikasi dan penggunaan ulang, yang secara langsung meningkatkan efisiensi pengembangan.

Pada tahap awal, teknik *Information Retrieval* tradisional hanya mengandalkan pencocokan kata, mengabaikan **kesenjangan semantik** antara bahasa kode dan bahasa alami. Meskipun model *Deep Learning* seperti **DeepCS** telah muncul untuk memetakan kedua bahasa ke ruang vektor bersama, akurasi *code search* tetap sangat bergantung pada kemampuan kueri untuk merepresentasikan kode yang diinginkan secara akurat.

Masalah utamanya adalah adanya **disparitas** yang melekat antara **Kueri** (*Query*) yang dimasukkan oleh pencari dan **Deskripsi** (*Description*) yang ditulis oleh pengembang:
1.  **Perbedaan Semantik/Sintaksis:** Deskripsi berasal dari pengembang (mencerminkan pemahaman kode), sedangkan Kueri berasal dari pencari (mencerminkan kebutuhan fungsional). Perspektif ini seringkali berbeda.
2.  **Perbedaan Panjang:** Kueri cenderung jauh lebih pendek (misalnya, 2–3 kata) dibandingkan Deskripsi (misalnya, 20–30 kata), sehingga Kueri pendek mungkin tidak secara tepat menyampaikan niat fungsional yang dimaksudkan.

Untuk mengatasi disparitas ini, teknik *Query Expansion* (QE) telah diperkenalkan. Namun, teknik QE yang ada memiliki tiga masalah utama: (1) Kurangnya *dataset* khusus QE (Query-Code-Description); (2) Disparitas antara Deskripsi (pemahaman pengembang) dan Kueri (pemahaman pencari); dan (3) QE yang ada mengabaikan **niat pencari** (*searcher's intent*).

::: tip Solusi yang Diusulkan
Kami mengusulkan model ekstensi kueri **QEIEF** (*Query Expansion with Intent Enhancement Feedback*). QEIEF mengatasi keterbatasan ini dengan membuat *dataset* CodesearchQE (Query-Code-Description), dan menggunakan mekanisme umpan balik niat, di mana hasil *code search* Top-K yang paling relevan digunakan untuk memperkaya kueri awal secara semantik, menyelaraskan kueri yang diperluas dengan niat pencari.
:::

## 2. Metodologi

Model QEIEF (Gambar 3) terdiri dari tiga modul: *Code Data*, *Offline Training*, dan *Online Searching* (yang mencakup mekanisme *Intentional Enhancement*). Model dasar yang digunakan adalah **DeepCS** dan **UNIF**.

### A. Offline Training

Tujuan utama pelatihan *offline* adalah mendapatkan parameter model melalui *joint embedding* Kode dan Deskripsi ke dalam ruang vektor bersama. DeepCS/QEIEF menggunakan arsitektur *Bi-directional Long-Short Memory Network* (**BiLSTM**) untuk ekstraksi fitur urutan, yang dianggap lebih baik untuk karakterisasi fitur kode (Gambar 5).

1.  **Data Serialization:** Kode sumber dipecah menjadi empat urutan: **Methodname** ($M$), **API** ($A$), **Tokens** ($T$), dan **Description** ($D$).
2.  **Feature Extraction:** BiLSTM digunakan untuk menghasilkan lapisan tersembunyi ($h_t$) dari setiap urutan. *Maximum pooling* diterapkan pada urutan lapisan tersembunyi untuk mendapatkan vektor fitur akhir untuk $M, A, T$, dan $D$.
$$h_{t}=\tanh(W^{M}[h_{t-1};m_{tM}])$$
$$m = \text{max pooling}([h_{1},h_{2},h_{3},...,h_{n}])$$
Vektor kode fragmen akhir ($c$) adalah konkatenasi dari fitur $M, A, T$: $c = \text{concat}(m, a, t)$.
3.  **Model Training:** Pelatihan dilakukan menggunakan pasangan tiga vektor $(c, d^{+}, d^{-})$, di mana $d^{+}$ adalah Deskripsi positif yang berkorelasi, dan $d^{-}$ adalah Deskripsi negatif. Fungsi *Loss* yang digunakan adalah *Margin Loss*:
$$\text{Loss}(\theta) = \sum_{(c,d^{+},d^{-})} \max (0,\epsilon - \cos(c,d^{+}) + \cos(c,d^{-}))$$
Di mana $\epsilon$ adalah *constant margin*.

### B. Intentionally Enhanced Feedback (QEIEF)

Mekanisme ini diimplementasikan selama fase *Online Searching* (Gambar 8) untuk memperluas kueri awal.

1.  **Pencarian Awal:** Kueri awal dimasukkan ke model terlatih untuk mendapatkan vektor kueri, yang dicocokkan dengan basis data vektor kode menggunakan *Cosine Similarity* untuk mendapatkan hasil peringkat awal.
2.  **Umpan Balik Niat Iteratif:**
    *   **Judgment Module** mengevaluasi hasil pencocokan.
    *   Jika akurasi hasil optimal saat ini meningkat, **Deskripsi** yang sesuai dengan **Top-N** kode vektor teratas dipilih (berdasarkan eksperimen, **N=3** dipilih).
    *   Deskripsi ini digabungkan (*Concatenation*) dengan kueri awal untuk menghasilkan **Kueri yang Diperluas**.
    *   Kueri yang diperluas diumpankan kembali ke model (*feedback*) untuk pencocokan berikutnya.
3.  **Penghentian:** Proses iteratif ini (dilakukan sebanyak **T** kali, dengan **T=2** dipilih) berlanjut hingga *Judgment Module* tidak lagi mendeteksi peningkatan akurasi.

Keuntungan utama: Sumber ekstensi kueri adalah **Deskripsi** yang ditulis oleh pengembang (dianggap sebagai representasi niat yang akurat) dan struktur kueri yang diperluas konsisten dengan bahasa alami yang digunakan selama pelatihan *offline*.

## 3. Detail Pengujian

### Dataset
1.  **CodeSearchNet:** Digunakan untuk pengujian komparatif umum (Python, Java).
2.  **CodesearchQE (Buatan Sendiri):** *Dataset* ternary (Query-Code-Description) yang dikumpulkan dari Stack Overflow (2013-2023) untuk Python (37,234) dan Java (31,297), total 68,531 item. Deskripsi adalah komentar yang diterima oleh penanya.

### Model Baseline dan Perluasan
*   **Model Dasar:** DeepCS, UNIF.
*   **Model Perluasan (QE Baseline):** WordNet, FP (*Frequent Itemsets*), QECK (*Keyword* dari StackOverflow), NQE (*Method Name* dari Kode).

### Metrik Evaluasi
Kami menggunakan **R@k** (*Recall at k*) dan **MRR** (*Mean Reciprocal Rank*), metrik standar dalam *code search*.

*   **R@k:**
$$R@k=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\delta(FRank_{q}\le k)$$
Di mana $Q$ adalah kumpulan kueri, dan $\delta()$ adalah fungsi indikator. $k=1, 5, 10$ digunakan.
*   **MRR:**
$$MRR=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{1}{FRank_{q}}$$

## 4. Hasil Eksperimen

### RQ1: Disparitas Kueri vs Deskripsi

| Model | Bahasa | Input | R@1 | R@5 | R@10 | MRR | Peningkatan MRR (D vs Q) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| DeepCS | Python | Query | 0.058 | 0.160 | 0.251 | 0.122 | **154.10%** |
| DeepCS | Python | Description | 0.204 | 0.424 | 0.533 | 0.310 | |
| UNIF | Java | Query | 0.176 | 0.360 | 0.477 | 0.269 | **74.72%** |
| UNIF | Java | Description | 0.365 | 0.595 | 0.684 | 0.470 | |

**Analisis:** Menggunakan **Deskripsi** sebagai masukan menghasilkan hasil pencarian yang secara substansial lebih baik daripada menggunakan **Kueri**. Peningkatan DeepCS/Python pada R@1 mencapai $\mathbf{251.72\%}$ dan MRR $\mathbf{154.10\%}$. Ini memvalidasi bahwa terdapat disparitas yang signifikan antara Kueri dan Deskripsi, menegaskan perlunya teknik *query expansion* yang efektif.

### RQ2: Efektivitas Ekstensi Kueri QEIEF

| Dataset | Model | Input | R@1 | R@5 | R@10 | MRR | Peningkatan MRR (QEIEF vs Query) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| CodeSearchNet | DeepCS | Query | 0.39 | 0.66 | 0.72 | 0.63 | **17.46%** |
| CodeSearchNet | DeepCS | **QEIEF** | 0.53 | 0.86 | 0.92 | 0.74 | |
| CodesearchQE | DeepCS/Python | Query | 0.045 | 0.168 | 0.259 | 0.116 | **272.41%** |
| CodesearchQE | DeepCS/Python | **QEIEF** | 0.321 | 0.499 | 0.657 | 0.432 | |

**Analisis:** Penerapan QEIEF secara konsisten dan substansial meningkatkan kinerja *code search* di kedua *dataset* dan model dasar. Peningkatan QEIEF pada DeepCS/Python (CodesearchQE) sangat dramatis, mencapai $\mathbf{613.33\%}$ pada R@1 dan $\mathbf{272.41\%}$ pada MRR, menunjukkan bahwa mekanisme *intent-enhanced feedback* sangat efektif dalam menutup kesenjangan antara kueri pendek dan deskripsi kode.

### RQ3: Perbandingan dengan Metode Ekstensi Lain (CodesearchQE)

| Model | Bahasa | Metode | R@1 | R@5 | R@10 | MRR | Peningkatan MRR (QEIEF vs SOTA) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| DeepCS | Python | NQE | 0.301 | 0.450 | 0.584 | 0.393 | **9.03%** |
| DeepCS | Python | **QEIEF** | 0.321 | 0.499 | 0.657 | 0.432 | |
| DeepCS | Java | NQE | 0.301 | 0.471 | 0.648 | 0.411 | **5.11%** |
| DeepCS | Java | **QEIEF** | 0.321 | 0.499 | 0.657 | 0.432 | |

**Analisis:** QEIEF secara umum mengungguli semua metode ekstensi *baseline* (WordNet, FP, QECK, NQE). Keunggulan kinerja ini membuktikan bahwa menggunakan Deskripsi pengembang yang relevan sebagai sumber umpan balik niat adalah strategi ekstensi yang lebih efektif daripada metode berbasis TF-IDF/sinonim (WordNet) atau ekstraksi kata kunci sederhana (QECK, NQE).

### RQ4: Dampak Parameter Model

*   **Jumlah Umpan Balik Niat (N):** Nilai optimal untuk N (jumlah Deskripsi yang diambil sebagai *feedback*) sebagian besar adalah **N=3** di sebagian besar skenario, menunjukkan bahwa mengambil Top-3 Deskripsi sudah cukup untuk memperkaya niat kueri.
*   **Siklus Umpan Balik (T):** Nilai optimal untuk T (jumlah iterasi *feedback*) sebagian besar adalah **T=2**, menunjukkan bahwa iterasi *feedback* kedua sering kali menghasilkan hasil terbaik, dan lebih banyak iterasi cenderung menyebabkan penurunan kinerja.

### RQ5: Kinerja QEIEF pada Model Pre-trained (GraphCodeBERT)

Ketika QEIEF dan *baseline* QE lainnya diterapkan pada model *pre-trained* seperti **GraphCodeBERT**, semua model ekstensi menghasilkan **penurunan akurasi** dibandingkan dengan model dasar GraphCodeBERT tanpa ekstensi.

**Kesimpulan:** *Query Expansion* **tidak cocok** untuk model *pre-trained* seperti CodeBERT/GraphCodeBERT berdasarkan *dataset* CodesearchQE. Alasannya meliputi: (1) Ketidakcocokan pasangan input, di mana model *pre-trained* dilatih pada [Description-Code], tetapi QEIEF menciptakan pasangan [Expanded Query-Code] yang memerlukan pembelajaran ulang pemetaan secara substansial. (2) Ukuran *dataset* CodesearchQE yang terbatas tidak memadai untuk melatih ulang model *pre-trained* yang sensitif terhadap data.

## 5. Kesimpulan

Paper ini berhasil memperkenalkan **QEIEF**, sebuah model *code search* baru yang berpusat pada **ekstensi kueri berbasis niat** menggunakan mekanisme *feedback*. Kami memvalidasi bahwa disparitas antara Kueri dan Deskripsi berdampak signifikan pada akurasi *code search*, dan bahwa QEIEF secara efektif menjembatani kesenjangan ini, menghasilkan peningkatan akurasi yang substansial dibandingkan dengan model dasar dan metode ekstensi *baseline*. Kami juga menyumbangkan *dataset* ternary **CodesearchQE** untuk penelitian QE di masa mendatang.

::: info Dampak Praktis
QEIEF memberikan fondasi teoritis dan model yang kuat untuk penelitian ekstensi kueri *code search*, terutama dengan menekankan pentingnya niat pencari yang diekstraksi dari deskripsi pengembang. Penerapan QEIEF pada model *code search* non-pre-trained dapat secara dramatis meningkatkan akurasi pencarian yang menghasilkan peningkatan efisiensi dan keandalan dalam proses pengembangan perangkat lunak.
:::