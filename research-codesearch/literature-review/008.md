---
title: Review Paper - RFMC-CS Multi-View Momentum Contrastive Learning
description: Rangkuman paper tentang kerangka kerja RFMC-CS untuk Code Search berbasis fusi representasi multi-view momentum contrastive learning (Automated Software Engineering, 2025).
head:
  - - meta
    - name: keywords
      content: Code search, Contrastive learning, Multi-modal models, Representation fusion, Momentum Contrastive Learning
---

# 008 - RFMC-CS: a representation fusion based multi-view momentum contrastive learning framework for code search
[https://doi.org/10.1007/s10515-025-00487-8]

**Penulis:** **Gong Chen** ᵃ, **Wenjie Liu** ᵃ, **Xiaoyuan Xie** ᵃ*

**Afiliasi:**
* ᵃ School of Computer Science, Wuhan University, Wuhan, Hubei, China

**Kronologi:** Received: 15 December 2024 • Accepted: 11 January 2025 • Published Online: 27 January 2025

<a href="https://www.scimagojr.com/journalsearch.php?q=24145&tip=sid&clean=0" target="_blank"><img src="https://www.scimagojr.com/journal_img.php?id=24145" alt="SCImago Journal & Country Rank" /></a>

| Resume Eksekutif |
| :--- |
| **Publikasi:**<br>• **Jurnal:** Automated Software Engineering, Vol 32, Isu 16 (2025)<br>• **Penerbit:** Springer Science+Business Media, LLC<br>• **Topik:** Peningkatan Pembelajaran Representasi Multi-Modal untuk *Code Search* menggunakan *Momentum Contrastive Learning* dan Fusi Fitur.<br><br>**Masalah & Solusi:**<br>• **Masalah:** Metode *code search* berbasis *Contrastive Learning* (CL) yang ada memiliki keterbatasan: (1) Terjadi **kehilangan informasi semantik dan struktural** kode (AST dan DFG) karena transformasi menjadi sekuens dan di-*embed* oleh *sequence encoders*; (2) Gagal mengeksplorasi secara memadai peran **pasangan kode yang relevan secara fungsional** (*functionally relevant code pairs*) dalam pembelajaran representasi.<br>• **Solusi:** Mengusulkan **RFMC-CS** (*Representation Fusion based Multi-View Momentum Contrastive Learning Framework for Code Search*). Kerangka kerja ini menggunakan *encoders* yang sesuai dengan karakteristik data (misalnya, **GCN** untuk struktur graf) dan **fusi fitur** multi-modal untuk mempertahankan informasi struktural. Selain itu, **Multi-View Momentum Contrastive Learning** dirancang untuk menangkap korelasi semantik antara pasangan kode yang relevan secara fungsional.<br><br>**Contoh Penerapan:**<br>• **Fusi Fitur:** Representasi dari **Code Text**, **AST**, dan **DFG** (tiga modalitas) untuk satu potongan kode digabungkan (menggunakan *Max Pooling* sebagai strategi optimal) untuk menghasilkan satu vektor kode akhir ($V_c$) yang lebih komprehensif.<br>• **Multi-View CL:** Menggunakan dua *view* kontrasif—*Unique-Instance* (antara deskripsi dan kode dalam satu sampel) dan *Cross-Instance* (antara sampel sumber dan sampel yang relevan secara semantik)—untuk menarik sampel semantik yang relevan agar berdekatan di ruang representasi.<br><br>**Metodologi:**<br>• **Arsitektur:** Model *agnostik*, dapat diintegrasikan dengan model pra-terlatih seperti **UniXcoder** (sebagai *Text Encoder* dan *Sequence Encoder*). Menggunakan **GCN + MLP** sebagai *Graph Encoder* untuk AST/DFG.<br>• **Fungsi Rugi:** Menggabungkan *Cross-Entropy Loss* ($\mathcal{L}_{CS}$) untuk tugas *Code Search* utama dan *Multi-View Momentum Contrastive Learning Loss* ($\mathcal{L}_{MMCL}$) sebagai tugas pembantu, dioptimalkan secara bersamaan (*joint learning*).<br>• **Momentum CL:** Menggunakan *Momentum Encoder* dan *Negative Sample Queue* untuk pembelajaran kontrasif berskala besar.<br><br>**Temuan Kunci:**<br>1. **Kinerja Terbaik:** RFMC-CS mengungguli semua *baseline* canggih, termasuk MoCoCS, dengan peningkatan MRR rata-rata sebesar 2.4.<br>2. **Portabilitas:** RFMC-CS secara signifikan meningkatkan kinerja model yang sudah ada (misalnya, MRR GraphCodeBERT meningkat 5.5 rata-rata ketika diintegrasikan dengan RFMC-CS).<br>3. **Fusi Optimal:** Strategi *Max Pooling* adalah strategi fusi fitur yang paling efektif, menunjukkan keunggulan dalam mengekstrak fitur paling menonjol dari modalitas yang berbeda.<br><br>**Kontribusi Utama:**<br>• Mengusulkan RFMC-CS, kerangka kerja *model-agnostic* yang dapat meningkatkan kinerja model representasi kode yang ada.<br>• Mendesain *Fusion Encoder* baru yang efektif mempertahankan informasi struktural (AST/DFG) dengan menggunakan *encoder* yang sesuai dengan karakteristik data.<br>• Merancang *Multi-View Momentum Contrastive Learning* (Unique- dan Cross-Instance CL) untuk sepenuhnya mengeksplorasi pasangan kode yang relevan secara semantik. |

## 1. Pendahuluan & Masalah

*Code Search* adalah aktivitas penting dalam rekayasa perangkat lunak yang bertujuan untuk menemukan potongan kode yang relevan dari *codebase* berdasarkan kueri bahasa alami. Dengan pesatnya perkembangan repositori kode, akurasi pencarian kode menjadi tantangan besar. Meskipun metode *Deep Learning* (DL) dan, khususnya, *Contrastive Learning* (CL) telah menunjukkan kinerja yang mengesankan, mereka masih memiliki dua keterbatasan utama dalam pembelajaran representasi multi-modal kode:

1.  **Kehilangan Informasi Struktural:** Metode yang ada (seperti GraphCodeBERT dan MoCoCS) sering kali mengubah informasi struktural kode seperti **Abstract Syntax Tree (AST)** dan **Data Flow Graph (DFG)** menjadi urutan (sekuens) dan meng-*embed*nya menggunakan *sequence encoders*. Proses ini mengakibatkan hilangnya informasi struktural dan semantik yang berharga.
2.  **Eksplorasi Pasangan Relevan yang Tidak Memadai:** Fenomena implementasi kode yang berbeda untuk fungsionalitas yang sama (*functionally similar code snippets*) umum terjadi. Namun, metode yang ada tidak sepenuhnya mengeksplorasi peran pasangan kode yang relevan secara semantik ini dalam mengoptimalkan pembelajaran representasi.

::: tip Solusi yang Diusulkan
Kami mengusulkan **RFMC-CS** (*Representation Fusion based Multi-View Momentum Contrastive Learning Framework for Code Search*). RFMC-CS mengatasi keterbatasan ini melalui: (1) **Representasi multi-modal dan fusi fitur** untuk mempertahankan informasi tekstual dan struktural; dan (2) **Multi-View Momentum Contrastive Learning** yang dirancang secara cermat untuk mempelajari korelasi antara modalitas yang berbeda dan antara sampel yang relevan secara semantik.
:::

## 2. Metodologi

RFMC-CS adalah kerangka kerja *joint learning* yang mengintegrasikan tugas utama *Code Search* dengan tugas pembantu *Multi-View Momentum Contrastive Learning* ($\mathcal{L}_{MMCL}$).

### A. Data Processing
*   **Identifikasi Pasangan Relevan Semantik:** Menggunakan model representasi teks pra-terlatih **BGE** untuk meng-*embed* deskripsi kode. Dua sampel dianggap sebagai pasangan yang relevan secara fungsional jika kesamaan kosinus deskripsi mereka melebihi ambang batas $t=0.85$.
*   **Parsing Kode:** Setiap potongan kode di-*parse* menjadi tiga modalitas: **Code Text** (teks sekuensial), **AST** (struktur pohon), dan **DFG** (graf aliran data).

### B. Data Embedding dan Fusion Encoder
Untuk mengatasi masalah kehilangan informasi struktural, RFMC-CS mengadopsi *encoders* yang sesuai dengan karakteristik data.
*   **Text Encoder:** Menggunakan model berbasis **BERT** (spesifik: **UniXcoder**) untuk meng-*embed* Code Description dan Code Text ($V_d, V_{ct}$).
*   **Fusion Encoder:** Dirancang untuk AST dan DFG. *Encoder* ini terdiri dari:
    *   **Sequence Encoder:** Meng-*embed* data sekuensial AST dan DFG (diperoleh melalui *pre-order traversal*) ($V_{as}, V_{ds}$).
    *   **Graph Encoder:** Menggunakan **Graph Convolutional Network (GCN)** dua lapis diikuti oleh **Multi-Layer Perceptron (MLP)** untuk menghasilkan representasi graf AST dan DFG ($V_{ag}, V_{dg}$).
    *   **Representation Fusion:** Menggabungkan representasi sekuens dan graf (misalnya, $V_{ast} = \text{Average Pooling}(V_{ag}, V_{as})$).
*   **Multi-modal Code Feature Fusion:** Tiga representasi kode ($V_{ct}, V_{ast}, V_{dfg}$) digabungkan untuk menghasilkan representasi kode akhir ($V_c$). Strategi **Max Pooling** diadopsi sebagai metode fusi yang optimal:
$$V_{c}=Max Pooling(V_{ct},V_{ast},V_{dfg})$$

### C. Multi-View Momentum Contrastive Learning
RFMC-CS menggunakan dua *view* kontrasif yang dioptimalkan dengan *Momentum Contrastive Learning* (MoCo) untuk stabilitas representasi negatif skala besar.
*   **Unique-Instance Contrastive View ($\mathcal{L}_{unique}$):** Mempelajari korelasi semantik antara modalitas yang berbeda (deskripsi dan kode) dalam **satu sampel** sumber.
*   **Cross-Instance Contrastive View ($\mathcal{L}_{cross}$):** Mempelajari korelasi semantik antara sampel sumber ($V_c, V_d$) dan **pasangan kode yang relevan secara semantik** ($V_{c}^{+}, V_{d}^{+}$).
$$\mathcal{L}_{MMCL}=\mathcal{L}_{unique}+\mathcal{L}_{cross}$$

$\mathcal{L}_{cross}$ (Contoh untuk Anchor $V_{c_i}$):
$$\mathcal{L}_{cross}=-log\frac{exp(V_{c_{i}}\cdot V_{d_{i}}^{+}/\tau)}{\sum_{j=0}^{M}exp(V_{c_{i}}\cdot V_{d_{j}}^{*}/\tau)}$$

$\theta_{m}=m\theta_{m}+(1-m)\theta_{g}$, di mana $m=0.999$ adalah koefisien momentum.

### D. Joint Learning
Tugas *Code Search* utama dioptimalkan dengan *Cross-Entropy Loss* ($\mathcal{L}_{CS}$), sementara tugas CL berfungsi sebagai pembantu.
$$\mathcal{L}_{joint}=\lambda_{1}\mathcal{L}_{MMCL}+\lambda_{2}\mathcal{L}_{CS}$$
Di mana $\lambda_{1}=0.2$ dan $\lambda_{2}=0.8$ adalah koefisien bobot optimal.

## 3. Detail Pengujian

### Dataset
Menggunakan *benchmark* **CodeSearchNet** yang mencakup enam bahasa pemrograman (Ruby, Javascript, Java, Go, PHP, dan Python).

### Baseline
Tujuh model *code search* canggih, termasuk model pra-terlatih berbasis BERT/Transformer dan model CL momentum: ROBERTa, CodeBERT, GraphCodeBERT, CodeT5, SYNCOBERT, UniXcoder, dan **MoCoCS** (sebagai *baseline* terdekat).

### Metrik Evaluasi
*   **Mean Reciprocal Rank (MRR):**
$$MRR=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{1}{Rank_{q}}$$
*   **Recall@K (R@K):** Mengukur proporsi hasil benar yang diambil dalam $K$ hasil teratas.
$$Recall@K=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\delta(Rank_{q}\le K)$$

## 4. Hasil Eksperimen

### Perbandingan Kinerja Utama (RQ-1)
RFMC-CS mengungguli semua *baseline* canggih secara konsisten di semua metrik dan bahasa.

| Model | Ruby | JavaScript | Go | Python | Java | PHP | Avg. (MRR) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| UniXcoder | 74.0 | 68.4 | 91.5 | 72.0 | 72.6 | 67.6 | 74.4 |
| MoCoCS | 76.2 | 69.7 | 92.0 | 73.4 | 73.9 | 68.9 | 75.7 |
| **RFMC-CS** | **79.2** | **73.1** | **92.6** | **75.4** | **76.1** | **72.3** | **78.1 (2.4 $\uparrow$)** |

RFMC-CS mencapai skor R@1, R@5, dan R@10 rata-rata masing-masing sebesar 0.695, 0.875, dan 0.916. Peningkatan 2.4 MRR rata-rata dibandingkan MoCoCS menunjukkan efektivitas kerangka kerja fusi dan *Multi-View CL* dalam menangkap representasi kode yang lebih komprehensif.

### Portabilitas Model (RQ-2)
RFMC-CS menunjukkan portabilitas yang baik, secara konsisten meningkatkan kinerja model pra-terlatih yang diintegrasikan.

| Model | Avg. MRR | Peningkatan MRR Rata-rata |
| :--- | :--- | :--- |
| GraphCodeBERT (Asli) | 71.3 | - |
| **RFMC-CS GraphCodeBERT** | **76.8** | **5.5** |

Peningkatan kinerja 5.5 MRR rata-rata pada GraphCodeBERT menunjukkan bahwa RFMC-CS efektif memperbaiki keterbatasan model yang ada (khususnya dalam menangani representasi graf yang diserialkan) dan menangkap relevansi semantik.

### Dampak Strategi Fusi Fitur (RQ-4)
Strategi fusi fitur kode multi-modal (Code Text, AST, DFG) memengaruhi kinerja secara signifikan.

| Strategi Fusi | Avg. MRR |
| :--- | :--- |
| Vector Sum | 76.1 |
| Average Pooling | 76.7 |
| **Max Pooling** | **78.1** |

Strategi **Max Pooling** mencapai kinerja terbaik. Ini menunjukkan bahwa strategi ini paling efektif dalam menangkap **fitur paling menonjol** dari setiap modalitas kode, yang sangat penting untuk representasi kode yang komprehensif.

### Studi Ablasi (RQ-3)
Setiap komponen RFMC-CS berkontribusi pada kinerja keseluruhan (diukur berdasarkan penurunan MRR rata-rata jika komponen dihilangkan).

| Ablasi | Avg. MRR |
| :--- | :--- |
| RFMC-CS (Lengkap) | 78.1 |
| -DFG (DFG di-*encode* sekuens) | 77.8 |
| -AST (AST di-*encode* sekuens) | 77.3 |
| -Cross (Tanpa $\mathcal{L}_{cross}$) | 76.0 |
| -Unique (Tanpa $\mathcal{L}_{unique}$) | 74.6 |

*   **Analisis:** Penghapusan *Unique-Instance CL* ($\mathcal{L}_{unique}$) menyebabkan penurunan terbesar (3.5 MRR), menegaskan peran penting CL dalam mengoptimalkan representasi multi-modal dalam satu sampel. Penghapusan *Cross-Instance CL* ($\mathcal{L}_{cross}$) juga menyebabkan penurunan signifikan (2.1 MRR), memvalidasi pentingnya mengeksplorasi pasangan kode yang relevan secara semantik.

## 5. Kesimpulan

RFMC-CS berhasil menyajikan kerangka kerja *code search* berbasis fusi representasi multi-modal dan *Multi-View Momentum Contrastive Learning*. Dengan menggunakan *encoders* yang sesuai dengan karakteristik data untuk AST dan DFG serta mengadopsi strategi fusi yang efektif (*Max Pooling*), RFMC-CS berhasil memitigasi masalah kehilangan informasi struktural. Selain itu, desain *Multi-View Contrastive Learning* (Unique- dan Cross-Instance) secara efektif memanfaatkan korelasi semantik internal dan antar sampel. Hasil eksperimen pada *benchmark* CodeSearchNet menunjukkan bahwa RFMC-CS mencapai kinerja *state-of-the-art* dan menunjukkan portabilitas yang kuat dalam meningkatkan model representasi kode yang sudah ada.

::: info Dampak Praktis
RFMC-CS menyediakan cara yang andal dan dapat ditingkatkan untuk meningkatkan akurasi *code search*. Dengan pembelajaran representasi kode yang lebih komprehensif dan efisien (mempertimbangkan teks, AST, dan DFG), kerangka kerja ini dapat secara langsung meningkatkan efisiensi dan relevansi pengambilan kode, yang krusial untuk kegiatan rekayasa perangkat lunak seperti penggunaan kembali kode.
:::